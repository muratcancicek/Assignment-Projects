########################################################################################
########################################################################################
########################################################################################
2017-04-30 23:34:51.979702: Running on MSI...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-04-30 23:35:11.082622: step 0, loss = 4.67 (7591.2 examples/sec; 0.017 sec/batch)
2017-04-30 23:35:14.880885: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-01 14:03:23.369124: Running on MSI...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-01 14:03:43.588935: step 0, loss = 4.67 (7318.6 examples/sec; 0.017 sec/batch)
2017-05-01 14:03:47.274226: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-01 14:07:30.386224: Running on MSI...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-01 14:07:49.082088: step 0, loss = 4.68 (7771.3 examples/sec; 0.016 sec/batch)
2017-05-01 14:08:28.672942: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-01 15:41:47.989052: Running on MSI...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-01 15:42:08.087093: step 0, loss = 4.68 (7200.1 examples/sec; 0.018 sec/batch)
2017-05-01 15:42:47.957178: DONE
########################################################################################
########################################################################################
########################################################################################
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 03:10:50.709811: step 0, loss = 4.68 (8012.4 examples/sec; 0.016 sec/batch)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 05:11:27.176241: step 0, loss = 6.38 (1982.8 examples/sec; 0.065 sec/batch)
########################################################################################
########################################################################################
########################################################################################
2017-05-02 19:42:16.698996: Running on MSI...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 19:42:26.526405: step 0, loss = 6.38 (1818.8 examples/sec; 0.070 sec/batch)
2017-05-02 19:44:14.946251: step 100, loss = 5.90 (118.1 examples/sec; 1.084 sec/batch)
2017-05-02 19:46:18.165279: step 200, loss = 5.10 (103.9 examples/sec; 1.232 sec/batch)
2017-05-02 19:48:03.199919: precision @ 1 = 0.545
2017-05-02 19:48:03.914295: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 19:49:23.382655: Running on MSI...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 19:51:44.222357: precision @ 1 = 0.566
2017-05-02 19:51:44.827254: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 23:10:34.805595: Running on MSI...
########################################################################################
########################################################################################
########################################################################################
2017-05-02 23:14:53.416338: Running on MSI...
########################################################################################
########################################################################################
########################################################################################
2017-05-02 23:16:05.473184: Running on MSI...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 23:16:14.502855: step 0, loss = 6.38 (1902.7 examples/sec; 0.067 sec/batch)
########################################################################################
########################################################################################
########################################################################################
2017-05-02 23:18:10.791801: Running on MSI...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 23:19:07.150263: precision @ 1 = 0.495
2017-05-02 23:19:07.848757: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 13:22:25.640494: Running on server...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 13:23:34.025582: precision @ 1 = 0.000
2017-05-02 13:23:34.447543: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 13:36:30.237930: Running on server...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 13:37:32.690747: precision @ 1 = 0.498
2017-05-02 13:37:33.090898: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 13:38:09.926342: Running on server...
########################################################################################
########################################################################################
########################################################################################
2017-05-02 13:39:30.727659: Running on server...
########################################################################################
########################################################################################
########################################################################################
2017-05-02 13:39:59.824929: Running on server...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 13:41:56.159177: precision @ 1 = 0.512
2017-05-02 13:41:56.551452: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 13:43:31.491927: Running on server...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 13:45:20.958808: precision @ 1 = 0.000
2017-05-02 13:45:21.373092: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 13:48:43.781418: Running on server...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 13:50:32.484337: precision @ 1 = 0.487
2017-05-02 13:50:32.883299: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 13:53:59.767160: Running on server...
########################################################################################
########################################################################################
########################################################################################
2017-05-02 13:54:29.556481: Running on server...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 14:50:37.834941: precision @ 1 = 0.834
2017-05-02 14:50:38.205392: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 16:33:44.146097: Running on server...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 16:34:14.374875: step 0, loss = 6.38 (12.4 examples/sec; 10.295 sec/batch)
2017-05-02 16:34:49.113811: step 100, loss = 5.64 (1429.9 examples/sec; 0.090 sec/batch)
2017-05-02 16:35:14.933199: step 200, loss = 4.78 (1252.8 examples/sec; 0.102 sec/batch)
2017-05-02 16:35:38.773353: step 300, loss = 4.65 (1268.5 examples/sec; 0.101 sec/batch)
2017-05-02 16:35:59.403723: step 400, loss = 4.35 (1201.6 examples/sec; 0.107 sec/batch)
2017-05-02 16:36:20.196845: step 500, loss = 3.86 (1295.0 examples/sec; 0.099 sec/batch)
2017-05-02 16:36:39.009702: step 600, loss = 3.71 (1431.1 examples/sec; 0.089 sec/batch)
2017-05-02 16:36:59.917474: step 700, loss = 3.27 (1318.8 examples/sec; 0.097 sec/batch)
2017-05-02 16:37:22.136216: step 800, loss = 3.04 (1358.8 examples/sec; 0.094 sec/batch)
2017-05-02 16:37:46.449561: step 900, loss = 2.99 (1377.9 examples/sec; 0.093 sec/batch)
2017-05-02 16:38:15.421375: precision @ 1 = 0.713
2017-05-02 16:38:15.933319: DONE
########################################################################################
########################################################################################
########################################################################################
The experiment details:
max_steps = 1000 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-02 17:31:56.498448: Running on server...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 17:32:30.506995: step 0, loss = 6.37 (10.6 examples/sec; 12.072 sec/batch)
2017-05-02 17:33:10.174777: step 100, loss = 5.51 (1112.8 examples/sec; 0.115 sec/batch)
2017-05-02 17:33:34.751237: step 200, loss = 5.03 (1362.7 examples/sec; 0.094 sec/batch)
2017-05-02 17:33:54.359336: step 300, loss = 4.62 (1323.7 examples/sec; 0.097 sec/batch)
2017-05-02 17:34:13.587034: step 400, loss = 4.30 (1388.9 examples/sec; 0.092 sec/batch)
2017-05-02 17:34:33.441458: step 500, loss = 3.97 (1386.1 examples/sec; 0.092 sec/batch)
2017-05-02 17:34:52.375089: step 600, loss = 3.54 (1453.1 examples/sec; 0.088 sec/batch)
2017-05-02 17:35:11.520342: step 700, loss = 3.48 (1278.9 examples/sec; 0.100 sec/batch)
2017-05-02 17:35:33.253571: step 800, loss = 3.34 (1445.3 examples/sec; 0.089 sec/batch)
2017-05-02 17:35:51.299611: step 900, loss = 2.84 (1471.6 examples/sec; 0.087 sec/batch)
2017-05-02 17:36:17.918064: precision @ 1 = 0.711
2017-05-02 17:36:18.330605: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 17:45:31.199255: Running on server...
The experiment details:
max_steps = 1000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 17:46:06.482917: step 0, loss = 6.38 (9.9 examples/sec; 12.885 sec/batch)
2017-05-02 17:46:27.050001: step 100, loss = 5.71 (1423.8 examples/sec; 0.090 sec/batch)
2017-05-02 17:46:47.448390: step 200, loss = 5.21 (1389.7 examples/sec; 0.092 sec/batch)
2017-05-02 17:47:05.692106: step 300, loss = 4.49 (1399.2 examples/sec; 0.091 sec/batch)
2017-05-02 17:47:23.638216: step 400, loss = 4.35 (1487.6 examples/sec; 0.086 sec/batch)
2017-05-02 17:47:42.062470: step 500, loss = 3.86 (1474.6 examples/sec; 0.087 sec/batch)
########################################################################################
########################################################################################
########################################################################################
2017-05-02 17:50:15.249141: Running on server...
The experiment details:
max_steps = 1000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 17:50:48.026697: step 0, loss = 6.38 (11.5 examples/sec; 11.083 sec/batch)
2017-05-02 17:51:11.178423: step 100, loss = 5.64 (1450.8 examples/sec; 0.088 sec/batch)
2017-05-02 17:51:30.233787: step 200, loss = 5.18 (1453.2 examples/sec; 0.088 sec/batch)
2017-05-02 17:51:49.429536: step 300, loss = 4.51 (1457.5 examples/sec; 0.088 sec/batch)
2017-05-02 17:52:07.644800: step 400, loss = 4.27 (1426.9 examples/sec; 0.090 sec/batch)
2017-05-02 17:52:27.556866: step 500, loss = 4.13 (1436.4 examples/sec; 0.089 sec/batch)
2017-05-02 17:52:53.431334: step 600, loss = 3.91 (1453.8 examples/sec; 0.088 sec/batch)
2017-05-02 17:53:12.830494: step 700, loss = 3.49 (1266.9 examples/sec; 0.101 sec/batch)
2017-05-02 17:53:31.149599: step 800, loss = 3.17 (1446.2 examples/sec; 0.089 sec/batch)
2017-05-02 17:53:49.069866: step 900, loss = 2.99 (1513.2 examples/sec; 0.085 sec/batch)
2017-05-02 17:54:13.430937: precision @ 1 = 0.710
2017-05-02 17:54:13.822117: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 17:58:43.667286: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 17:59:12.759130: step 0, loss = 6.38 (11.9 examples/sec; 10.756 sec/batch)
2017-05-02 17:59:41.542099: precision @ 1 = 0.446
2017-05-02 17:59:41.957548: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 17:59:42.022295: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-02 18:00:39.185265: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 18:01:15.921001: step 0, loss = 6.38 (8.9 examples/sec; 14.317 sec/batch)
2017-05-02 18:01:56.185569: precision @ 1 = 0.446
2017-05-02 18:01:57.050571: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 18:17:44.470974: Running on server...
The experiment details:
max_steps = 30000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-02 18:18:09.650383: step 0, loss = 6.37 (14.5 examples/sec; 8.802 sec/batch)
2017-05-02 18:18:29.276130: step 100, loss = 5.62 (1515.9 examples/sec; 0.084 sec/batch)
2017-05-02 18:18:46.677021: step 200, loss = 4.93 (1508.0 examples/sec; 0.085 sec/batch)
2017-05-02 18:19:04.087997: step 300, loss = 4.67 (1505.4 examples/sec; 0.085 sec/batch)
2017-05-02 18:19:21.195210: step 400, loss = 4.16 (1525.5 examples/sec; 0.084 sec/batch)
2017-05-02 18:19:38.585594: step 500, loss = 3.85 (1481.9 examples/sec; 0.086 sec/batch)
2017-05-02 18:19:55.776764: step 600, loss = 3.53 (1460.8 examples/sec; 0.088 sec/batch)
2017-05-02 18:20:14.028559: step 700, loss = 3.56 (1498.4 examples/sec; 0.085 sec/batch)
2017-05-02 18:20:32.181412: step 800, loss = 3.25 (1507.6 examples/sec; 0.085 sec/batch)
2017-05-02 18:20:49.636057: step 900, loss = 2.88 (1436.0 examples/sec; 0.089 sec/batch)
2017-05-02 18:21:07.140694: step 1000, loss = 2.87 (1514.2 examples/sec; 0.085 sec/batch)
2017-05-02 18:21:26.605593: step 1100, loss = 2.51 (476.3 examples/sec; 0.269 sec/batch)
2017-05-02 18:21:43.848308: step 1200, loss = 2.41 (1505.8 examples/sec; 0.085 sec/batch)
2017-05-02 18:22:01.567575: step 1300, loss = 2.13 (1464.1 examples/sec; 0.087 sec/batch)
2017-05-02 18:22:19.052845: step 1400, loss = 2.13 (1506.6 examples/sec; 0.085 sec/batch)
2017-05-02 18:22:37.700160: step 1500, loss = 2.17 (1431.9 examples/sec; 0.089 sec/batch)
2017-05-02 18:22:55.126680: step 1600, loss = 1.96 (1505.5 examples/sec; 0.085 sec/batch)
2017-05-02 18:23:12.911478: step 1700, loss = 1.89 (1392.8 examples/sec; 0.092 sec/batch)
2017-05-02 18:23:30.338358: step 1800, loss = 1.69 (1503.2 examples/sec; 0.085 sec/batch)
2017-05-02 18:23:47.984820: step 1900, loss = 1.64 (1506.9 examples/sec; 0.085 sec/batch)
2017-05-02 18:24:05.374922: step 2000, loss = 1.43 (1506.8 examples/sec; 0.085 sec/batch)
2017-05-02 18:24:24.677808: step 2100, loss = 1.56 (1491.1 examples/sec; 0.086 sec/batch)
2017-05-02 18:24:42.103722: step 2200, loss = 1.39 (1519.1 examples/sec; 0.084 sec/batch)
2017-05-02 18:24:59.442160: step 2300, loss = 1.17 (1492.1 examples/sec; 0.086 sec/batch)
2017-05-02 18:25:17.050851: step 2400, loss = 1.27 (1478.5 examples/sec; 0.087 sec/batch)
2017-05-02 18:25:34.731751: step 2500, loss = 1.17 (1531.8 examples/sec; 0.084 sec/batch)
2017-05-02 18:25:52.045027: step 2600, loss = 1.10 (1443.3 examples/sec; 0.089 sec/batch)
2017-05-02 18:26:09.913263: step 2700, loss = 0.96 (1474.6 examples/sec; 0.087 sec/batch)
2017-05-02 18:26:27.471754: step 2800, loss = 0.96 (1511.3 examples/sec; 0.085 sec/batch)
2017-05-02 18:26:44.964049: step 2900, loss = 0.90 (1491.2 examples/sec; 0.086 sec/batch)
2017-05-02 18:27:02.746464: step 3000, loss = 0.92 (1490.0 examples/sec; 0.086 sec/batch)
2017-05-02 18:27:22.314915: step 3100, loss = 0.91 (1540.9 examples/sec; 0.083 sec/batch)
2017-05-02 18:27:39.791499: step 3200, loss = 0.86 (1514.1 examples/sec; 0.085 sec/batch)
2017-05-02 18:27:57.821654: step 3300, loss = 0.94 (1477.9 examples/sec; 0.087 sec/batch)
2017-05-02 18:28:15.275126: step 3400, loss = 0.86 (1507.1 examples/sec; 0.085 sec/batch)
2017-05-02 18:28:32.697662: step 3500, loss = 0.77 (1479.2 examples/sec; 0.087 sec/batch)
2017-05-02 18:28:50.135750: step 3600, loss = 0.94 (1529.0 examples/sec; 0.084 sec/batch)
2017-05-02 18:29:07.664664: step 3700, loss = 0.82 (1466.9 examples/sec; 0.087 sec/batch)
2017-05-02 18:29:25.337218: step 3800, loss = 0.73 (1367.5 examples/sec; 0.094 sec/batch)
2017-05-02 18:29:42.958317: step 3900, loss = 0.68 (1465.6 examples/sec; 0.087 sec/batch)
2017-05-02 18:30:00.772204: step 4000, loss = 0.71 (1507.0 examples/sec; 0.085 sec/batch)
2017-05-02 18:30:20.193414: step 4100, loss = 0.94 (1487.9 examples/sec; 0.086 sec/batch)
2017-05-02 18:30:37.958400: step 4200, loss = 0.70 (1035.1 examples/sec; 0.124 sec/batch)
2017-05-02 18:30:55.555286: step 4300, loss = 0.58 (1518.7 examples/sec; 0.084 sec/batch)
2017-05-02 18:31:13.060451: step 4400, loss = 0.56 (1494.6 examples/sec; 0.086 sec/batch)
2017-05-02 18:31:30.545714: step 4500, loss = 0.65 (1471.5 examples/sec; 0.087 sec/batch)
2017-05-02 18:31:48.904718: step 4600, loss = 0.53 (1499.3 examples/sec; 0.085 sec/batch)
2017-05-02 18:32:06.706775: step 4700, loss = 0.46 (1522.6 examples/sec; 0.084 sec/batch)
2017-05-02 18:32:24.281454: step 4800, loss = 0.62 (1470.5 examples/sec; 0.087 sec/batch)
2017-05-02 18:32:42.161571: step 4900, loss = 0.51 (1480.0 examples/sec; 0.086 sec/batch)
2017-05-02 18:32:59.939388: step 5000, loss = 0.61 (1472.7 examples/sec; 0.087 sec/batch)
2017-05-02 18:33:19.270810: step 5100, loss = 0.56 (1512.8 examples/sec; 0.085 sec/batch)
2017-05-02 18:33:37.044476: step 5200, loss = 0.51 (1490.4 examples/sec; 0.086 sec/batch)
2017-05-02 18:33:54.593386: step 5300, loss = 0.49 (1487.5 examples/sec; 0.086 sec/batch)
2017-05-02 18:34:13.406068: step 5400, loss = 0.44 (1382.2 examples/sec; 0.093 sec/batch)
2017-05-02 18:34:30.918694: step 5500, loss = 0.57 (1484.1 examples/sec; 0.086 sec/batch)
2017-05-02 18:34:48.392447: step 5600, loss = 0.49 (1464.6 examples/sec; 0.087 sec/batch)
2017-05-02 18:35:05.878322: step 5700, loss = 0.44 (1510.8 examples/sec; 0.085 sec/batch)
2017-05-02 18:35:23.342209: step 5800, loss = 0.52 (1533.5 examples/sec; 0.083 sec/batch)
2017-05-02 18:35:40.737003: step 5900, loss = 0.43 (1478.7 examples/sec; 0.087 sec/batch)
2017-05-02 18:35:59.257812: step 6000, loss = 0.39 (1490.7 examples/sec; 0.086 sec/batch)
2017-05-02 18:36:19.932405: step 6100, loss = 0.63 (1448.9 examples/sec; 0.088 sec/batch)
2017-05-02 18:36:37.539974: step 6200, loss = 0.46 (1463.9 examples/sec; 0.087 sec/batch)
2017-05-02 18:36:55.027342: step 6300, loss = 1.11 (1513.6 examples/sec; 0.085 sec/batch)
2017-05-02 18:37:12.620446: step 6400, loss = 0.48 (1435.0 examples/sec; 0.089 sec/batch)
2017-05-02 18:37:30.256258: step 6500, loss = 0.43 (1466.4 examples/sec; 0.087 sec/batch)
2017-05-02 18:37:48.481925: step 6600, loss = 0.42 (1446.8 examples/sec; 0.088 sec/batch)
2017-05-02 18:38:06.351433: step 6700, loss = 0.41 (1486.3 examples/sec; 0.086 sec/batch)
2017-05-02 18:38:24.185703: step 6800, loss = 0.54 (1462.1 examples/sec; 0.088 sec/batch)
2017-05-02 18:38:41.892307: step 6900, loss = 0.42 (1468.0 examples/sec; 0.087 sec/batch)
2017-05-02 18:38:59.628980: step 7000, loss = 0.46 (1496.4 examples/sec; 0.086 sec/batch)
2017-05-02 18:39:18.859909: step 7100, loss = 0.41 (1513.6 examples/sec; 0.085 sec/batch)
2017-05-02 18:39:36.311547: step 7200, loss = 0.34 (1480.3 examples/sec; 0.086 sec/batch)
2017-05-02 18:39:53.808609: step 7300, loss = 0.40 (1490.6 examples/sec; 0.086 sec/batch)
2017-05-02 18:40:11.235237: step 7400, loss = 0.34 (1492.4 examples/sec; 0.086 sec/batch)
2017-05-02 18:40:29.179641: step 7500, loss = 0.33 (1473.0 examples/sec; 0.087 sec/batch)
2017-05-02 18:40:46.849693: step 7600, loss = 0.46 (1470.3 examples/sec; 0.087 sec/batch)
2017-05-02 18:41:05.014433: step 7700, loss = 0.47 (1451.6 examples/sec; 0.088 sec/batch)
2017-05-02 18:41:22.665599: step 7800, loss = 0.35 (1453.1 examples/sec; 0.088 sec/batch)
2017-05-02 18:41:40.239491: step 7900, loss = 1.75 (1415.8 examples/sec; 0.090 sec/batch)
2017-05-02 18:41:57.873170: step 8000, loss = 0.44 (1469.7 examples/sec; 0.087 sec/batch)
2017-05-02 18:42:19.276744: step 8100, loss = 0.39 (1437.0 examples/sec; 0.089 sec/batch)
2017-05-02 18:42:37.163847: step 8200, loss = 0.42 (1454.6 examples/sec; 0.088 sec/batch)
2017-05-02 18:42:55.021150: step 8300, loss = 0.41 (1488.5 examples/sec; 0.086 sec/batch)
2017-05-02 18:43:12.204493: step 8400, loss = 0.46 (1538.0 examples/sec; 0.083 sec/batch)
2017-05-02 18:43:29.514160: step 8500, loss = 0.40 (1527.3 examples/sec; 0.084 sec/batch)
2017-05-02 18:43:47.282228: step 8600, loss = 0.46 (1441.1 examples/sec; 0.089 sec/batch)
2017-05-02 18:44:04.644396: step 8700, loss = 0.44 (1499.9 examples/sec; 0.085 sec/batch)
2017-05-02 18:44:22.103160: step 8800, loss = 0.43 (1509.3 examples/sec; 0.085 sec/batch)
2017-05-02 18:44:39.678403: step 8900, loss = 0.40 (1476.2 examples/sec; 0.087 sec/batch)
2017-05-02 18:44:57.180880: step 9000, loss = 0.43 (1464.4 examples/sec; 0.087 sec/batch)
2017-05-02 18:45:16.103237: step 9100, loss = 0.40 (1465.4 examples/sec; 0.087 sec/batch)
2017-05-02 18:45:33.694017: step 9200, loss = 0.38 (1520.8 examples/sec; 0.084 sec/batch)
2017-05-02 18:45:51.112190: step 9300, loss = 0.38 (1480.7 examples/sec; 0.086 sec/batch)
2017-05-02 18:46:08.605784: step 9400, loss = 0.35 (1498.5 examples/sec; 0.085 sec/batch)
2017-05-02 18:46:26.219260: step 9500, loss = 0.43 (1423.1 examples/sec; 0.090 sec/batch)
2017-05-02 18:46:43.814697: step 9600, loss = 0.33 (1431.4 examples/sec; 0.089 sec/batch)
2017-05-02 18:47:01.252524: step 9700, loss = 0.37 (1482.1 examples/sec; 0.086 sec/batch)
2017-05-02 18:47:18.921002: step 9800, loss = 0.35 (1389.1 examples/sec; 0.092 sec/batch)
2017-05-02 18:47:36.361758: step 9900, loss = 0.37 (1473.4 examples/sec; 0.087 sec/batch)
2017-05-02 18:47:53.957981: step 10000, loss = 0.59 (1468.6 examples/sec; 0.087 sec/batch)
2017-05-02 18:48:13.168870: step 10100, loss = 0.39 (1492.0 examples/sec; 0.086 sec/batch)
2017-05-02 18:48:30.775244: step 10200, loss = 0.35 (1503.4 examples/sec; 0.085 sec/batch)
2017-05-02 18:48:48.338551: step 10300, loss = 0.41 (1486.3 examples/sec; 0.086 sec/batch)
2017-05-02 18:49:06.008107: step 10400, loss = 0.37 (1469.9 examples/sec; 0.087 sec/batch)
2017-05-02 18:49:23.472385: step 10500, loss = 0.34 (1489.5 examples/sec; 0.086 sec/batch)
2017-05-02 18:49:40.918897: step 10600, loss = 0.47 (1497.5 examples/sec; 0.085 sec/batch)
2017-05-02 18:49:58.334472: step 10700, loss = 0.37 (1519.7 examples/sec; 0.084 sec/batch)
2017-05-02 18:50:15.759204: step 10800, loss = 0.32 (1511.3 examples/sec; 0.085 sec/batch)
2017-05-02 18:50:33.226115: step 10900, loss = 0.43 (1480.4 examples/sec; 0.086 sec/batch)
2017-05-02 18:50:51.024537: step 11000, loss = 0.39 (1490.4 examples/sec; 0.086 sec/batch)
2017-05-02 18:51:10.162526: step 11100, loss = 0.37 (1483.3 examples/sec; 0.086 sec/batch)
2017-05-02 18:51:27.709181: step 11200, loss = 0.41 (1477.9 examples/sec; 0.087 sec/batch)
2017-05-02 18:51:45.200273: step 11300, loss = 0.39 (1491.6 examples/sec; 0.086 sec/batch)
2017-05-02 18:52:02.699287: step 11400, loss = 0.37 (1438.8 examples/sec; 0.089 sec/batch)
2017-05-02 18:52:20.389737: step 11500, loss = 0.47 (1481.1 examples/sec; 0.086 sec/batch)
2017-05-02 18:52:38.020897: step 11600, loss = 0.42 (1518.0 examples/sec; 0.084 sec/batch)
2017-05-02 18:52:55.755700: step 11700, loss = 0.36 (1356.2 examples/sec; 0.094 sec/batch)
2017-05-02 18:53:13.345455: step 11800, loss = 0.33 (1498.2 examples/sec; 0.085 sec/batch)
2017-05-02 18:53:30.880150: step 11900, loss = 0.42 (1480.6 examples/sec; 0.086 sec/batch)
2017-05-02 18:53:48.340382: step 12000, loss = 0.38 (1491.6 examples/sec; 0.086 sec/batch)
2017-05-02 18:54:07.494958: step 12100, loss = 0.32 (1457.7 examples/sec; 0.088 sec/batch)
2017-05-02 18:54:24.898706: step 12200, loss = 0.41 (1512.9 examples/sec; 0.085 sec/batch)
2017-05-02 18:54:42.518339: step 12300, loss = 0.36 (1483.2 examples/sec; 0.086 sec/batch)
2017-05-02 18:55:00.063674: step 12400, loss = 0.30 (1472.9 examples/sec; 0.087 sec/batch)
2017-05-02 18:55:17.535631: step 12500, loss = 0.35 (1473.2 examples/sec; 0.087 sec/batch)
2017-05-02 18:55:35.128185: step 12600, loss = 0.34 (1490.4 examples/sec; 0.086 sec/batch)
2017-05-02 18:55:52.546169: step 12700, loss = 0.53 (1495.7 examples/sec; 0.086 sec/batch)
2017-05-02 18:56:10.137206: step 12800, loss = 0.41 (1511.1 examples/sec; 0.085 sec/batch)
2017-05-02 18:56:27.714641: step 12900, loss = 0.70 (1432.8 examples/sec; 0.089 sec/batch)
2017-05-02 18:56:45.345258: step 13000, loss = 0.43 (1463.2 examples/sec; 0.087 sec/batch)
2017-05-02 18:57:04.552542: step 13100, loss = 0.50 (1466.3 examples/sec; 0.087 sec/batch)
2017-05-02 18:57:22.283365: step 13200, loss = 0.35 (1484.0 examples/sec; 0.086 sec/batch)
2017-05-02 18:57:39.843609: step 13300, loss = 0.43 (1460.2 examples/sec; 0.088 sec/batch)
2017-05-02 18:57:57.546242: step 13400, loss = 0.42 (1417.6 examples/sec; 0.090 sec/batch)
2017-05-02 18:58:15.165322: step 13500, loss = 0.44 (1487.5 examples/sec; 0.086 sec/batch)
2017-05-02 18:58:32.706169: step 13600, loss = 0.41 (1497.7 examples/sec; 0.085 sec/batch)
2017-05-02 18:58:50.245692: step 13700, loss = 0.35 (1508.1 examples/sec; 0.085 sec/batch)
2017-05-02 18:59:07.719432: step 13800, loss = 0.41 (1492.7 examples/sec; 0.086 sec/batch)
2017-05-02 18:59:25.140024: step 13900, loss = 0.37 (1529.6 examples/sec; 0.084 sec/batch)
2017-05-02 18:59:42.951909: step 14000, loss = 0.36 (1461.3 examples/sec; 0.088 sec/batch)
2017-05-02 19:00:02.209814: step 14100, loss = 0.42 (1461.9 examples/sec; 0.088 sec/batch)
2017-05-02 19:00:19.957586: step 14200, loss = 0.36 (1487.8 examples/sec; 0.086 sec/batch)
2017-05-02 19:00:37.779381: step 14300, loss = 0.48 (1502.7 examples/sec; 0.085 sec/batch)
2017-05-02 19:00:55.317083: step 14400, loss = 0.42 (1479.2 examples/sec; 0.087 sec/batch)
2017-05-02 19:01:12.807641: step 14500, loss = 0.31 (1462.5 examples/sec; 0.088 sec/batch)
2017-05-02 19:01:30.341507: step 14600, loss = 0.39 (1447.7 examples/sec; 0.088 sec/batch)
2017-05-02 19:01:48.007340: step 14700, loss = 0.42 (1450.5 examples/sec; 0.088 sec/batch)
2017-05-02 19:02:05.796259: step 14800, loss = 0.37 (1450.8 examples/sec; 0.088 sec/batch)
2017-05-02 19:02:23.404595: step 14900, loss = 0.30 (1492.5 examples/sec; 0.086 sec/batch)
2017-05-02 19:02:41.047996: step 15000, loss = 0.35 (1481.9 examples/sec; 0.086 sec/batch)
2017-05-02 19:03:02.008369: step 15100, loss = 0.35 (1499.4 examples/sec; 0.085 sec/batch)
2017-05-02 19:03:19.538124: step 15200, loss = 0.36 (1470.4 examples/sec; 0.087 sec/batch)
2017-05-02 19:03:37.046255: step 15300, loss = 0.37 (1534.8 examples/sec; 0.083 sec/batch)
2017-05-02 19:03:54.932137: step 15400, loss = 0.37 (1426.7 examples/sec; 0.090 sec/batch)
2017-05-02 19:04:12.498391: step 15500, loss = 0.41 (1518.9 examples/sec; 0.084 sec/batch)
2017-05-02 19:04:30.001789: step 15600, loss = 0.49 (1461.4 examples/sec; 0.088 sec/batch)
2017-05-02 19:04:47.458093: step 15700, loss = 0.44 (1485.4 examples/sec; 0.086 sec/batch)
2017-05-02 19:05:04.953351: step 15800, loss = 0.34 (1432.7 examples/sec; 0.089 sec/batch)
2017-05-02 19:05:22.449971: step 15900, loss = 0.35 (1476.8 examples/sec; 0.087 sec/batch)
2017-05-02 19:05:40.013330: step 16000, loss = 0.30 (1502.1 examples/sec; 0.085 sec/batch)
2017-05-02 19:05:59.042067: step 16100, loss = 0.36 (1441.3 examples/sec; 0.089 sec/batch)
2017-05-02 19:06:16.663428: step 16200, loss = 0.32 (1465.0 examples/sec; 0.087 sec/batch)
2017-05-02 19:06:34.994918: step 16300, loss = 0.58 (1501.6 examples/sec; 0.085 sec/batch)
2017-05-02 19:06:52.582933: step 16400, loss = 0.34 (1462.1 examples/sec; 0.088 sec/batch)
2017-05-02 19:07:10.345489: step 16500, loss = 0.46 (1476.1 examples/sec; 0.087 sec/batch)
2017-05-02 19:07:28.538790: step 16600, loss = 0.39 (1443.3 examples/sec; 0.089 sec/batch)
2017-05-02 19:07:46.259003: step 16700, loss = 0.33 (1454.3 examples/sec; 0.088 sec/batch)
2017-05-02 19:08:03.843245: step 16800, loss = 0.35 (1499.7 examples/sec; 0.085 sec/batch)
2017-05-02 19:08:21.582435: step 16900, loss = 0.41 (1385.7 examples/sec; 0.092 sec/batch)
2017-05-02 19:08:39.609675: step 17000, loss = 0.51 (1336.7 examples/sec; 0.096 sec/batch)
2017-05-02 19:08:59.686966: step 17100, loss = 0.33 (1425.5 examples/sec; 0.090 sec/batch)
2017-05-02 19:09:18.109851: step 17200, loss = 0.34 (1455.9 examples/sec; 0.088 sec/batch)
2017-05-02 19:09:36.768066: step 17300, loss = 0.32 (1461.0 examples/sec; 0.088 sec/batch)
2017-05-02 19:09:54.993777: step 17400, loss = 0.31 (1429.3 examples/sec; 0.090 sec/batch)
2017-05-02 19:10:13.112570: step 17500, loss = 0.36 (1444.4 examples/sec; 0.089 sec/batch)
2017-05-02 19:10:31.035481: step 17600, loss = 0.44 (1362.7 examples/sec; 0.094 sec/batch)
2017-05-02 19:10:49.445350: step 17700, loss = 0.29 (1452.7 examples/sec; 0.088 sec/batch)
2017-05-02 19:11:07.164353: step 17800, loss = 0.30 (1503.7 examples/sec; 0.085 sec/batch)
2017-05-02 19:11:24.963356: step 17900, loss = 0.39 (1416.2 examples/sec; 0.090 sec/batch)
2017-05-02 19:11:43.033899: step 18000, loss = 0.34 (1424.0 examples/sec; 0.090 sec/batch)
2017-05-02 19:12:02.383392: step 18100, loss = 0.35 (1499.8 examples/sec; 0.085 sec/batch)
2017-05-02 19:12:20.446696: step 18200, loss = 0.31 (1478.3 examples/sec; 0.087 sec/batch)
2017-05-02 19:12:38.608421: step 18300, loss = 0.28 (1386.4 examples/sec; 0.092 sec/batch)
2017-05-02 19:12:56.499342: step 18400, loss = 0.38 (1458.3 examples/sec; 0.088 sec/batch)
2017-05-02 19:13:14.464512: step 18500, loss = 0.35 (1412.2 examples/sec; 0.091 sec/batch)
2017-05-02 19:13:32.291663: step 18600, loss = 0.29 (1429.0 examples/sec; 0.090 sec/batch)
2017-05-02 19:13:50.120186: step 18700, loss = 0.39 (1474.8 examples/sec; 0.087 sec/batch)
2017-05-02 19:14:08.142327: step 18800, loss = 0.35 (1430.8 examples/sec; 0.089 sec/batch)
2017-05-02 19:14:26.365027: step 18900, loss = 0.32 (1416.7 examples/sec; 0.090 sec/batch)
2017-05-02 19:14:45.572758: step 19000, loss = 0.42 (1339.0 examples/sec; 0.096 sec/batch)
2017-05-02 19:15:05.424098: step 19100, loss = 0.43 (1362.7 examples/sec; 0.094 sec/batch)
2017-05-02 19:15:23.837732: step 19200, loss = 0.35 (1434.8 examples/sec; 0.089 sec/batch)
2017-05-02 19:15:42.500734: step 19300, loss = 0.38 (1341.4 examples/sec; 0.095 sec/batch)
2017-05-02 19:16:00.707296: step 19400, loss = 0.32 (1364.7 examples/sec; 0.094 sec/batch)
2017-05-02 19:16:19.518199: step 19500, loss = 0.36 (1391.7 examples/sec; 0.092 sec/batch)
2017-05-02 19:16:39.068137: step 19600, loss = 0.39 (1170.1 examples/sec; 0.109 sec/batch)
2017-05-02 19:16:56.897011: step 19700, loss = 0.35 (1453.3 examples/sec; 0.088 sec/batch)
2017-05-02 19:17:15.674760: step 19800, loss = 0.35 (1454.1 examples/sec; 0.088 sec/batch)
2017-05-02 19:17:33.826030: step 19900, loss = 0.30 (1470.1 examples/sec; 0.087 sec/batch)
2017-05-02 19:17:52.196728: step 20000, loss = 0.38 (1363.8 examples/sec; 0.094 sec/batch)
2017-05-02 19:18:12.524483: step 20100, loss = 0.38 (1389.8 examples/sec; 0.092 sec/batch)
2017-05-02 19:18:30.734670: step 20200, loss = 0.30 (1446.2 examples/sec; 0.089 sec/batch)
2017-05-02 19:18:49.244318: step 20300, loss = 0.33 (1340.2 examples/sec; 0.096 sec/batch)
2017-05-02 19:19:08.377790: step 20400, loss = 0.35 (1327.9 examples/sec; 0.096 sec/batch)
2017-05-02 19:19:26.790488: step 20500, loss = 0.35 (1488.1 examples/sec; 0.086 sec/batch)
2017-05-02 19:19:45.237230: step 20600, loss = 0.29 (1417.5 examples/sec; 0.090 sec/batch)
2017-05-02 19:20:03.878885: step 20700, loss = 0.32 (1394.9 examples/sec; 0.092 sec/batch)
2017-05-02 19:20:23.941247: step 20800, loss = 0.29 (1374.7 examples/sec; 0.093 sec/batch)
2017-05-02 19:20:43.356740: step 20900, loss = 0.36 (1526.0 examples/sec; 0.084 sec/batch)
2017-05-02 19:21:01.675827: step 21000, loss = 0.45 (1477.4 examples/sec; 0.087 sec/batch)
2017-05-02 19:21:23.742398: step 21100, loss = 0.55 (1486.5 examples/sec; 0.086 sec/batch)
2017-05-02 19:21:42.449329: step 21200, loss = 0.57 (1399.9 examples/sec; 0.091 sec/batch)
2017-05-02 19:22:00.511527: step 21300, loss = 0.41 (1466.4 examples/sec; 0.087 sec/batch)
2017-05-02 19:22:18.614471: step 21400, loss = 0.49 (1458.0 examples/sec; 0.088 sec/batch)
2017-05-02 19:22:39.361516: step 21500, loss = 0.50 (1455.4 examples/sec; 0.088 sec/batch)
2017-05-02 19:22:58.840931: step 21600, loss = 0.52 (1423.1 examples/sec; 0.090 sec/batch)
2017-05-02 19:23:18.064610: step 21700, loss = 0.41 (1455.2 examples/sec; 0.088 sec/batch)
2017-05-02 19:23:39.494070: step 21800, loss = 0.48 (3388.3 examples/sec; 0.038 sec/batch)
2017-05-02 19:23:58.993090: step 21900, loss = 0.41 (1438.9 examples/sec; 0.089 sec/batch)
2017-05-02 19:24:18.398755: step 22000, loss = 0.41 (1474.2 examples/sec; 0.087 sec/batch)
2017-05-02 19:24:38.792511: step 22100, loss = 0.47 (1435.0 examples/sec; 0.089 sec/batch)
2017-05-02 19:24:58.967042: step 22200, loss = 0.42 (1437.4 examples/sec; 0.089 sec/batch)
2017-05-02 19:25:18.655158: step 22300, loss = 0.37 (1428.0 examples/sec; 0.090 sec/batch)
2017-05-02 19:25:37.371493: step 22400, loss = 0.42 (1439.6 examples/sec; 0.089 sec/batch)
2017-05-02 19:25:56.138613: step 22500, loss = 0.45 (1425.2 examples/sec; 0.090 sec/batch)
2017-05-02 19:26:15.428069: step 22600, loss = 0.34 (1428.0 examples/sec; 0.090 sec/batch)
2017-05-02 19:26:35.268016: step 22700, loss = 0.40 (1471.1 examples/sec; 0.087 sec/batch)
2017-05-02 19:26:54.563911: step 22800, loss = 0.36 (1470.3 examples/sec; 0.087 sec/batch)
2017-05-02 19:27:13.194422: step 22900, loss = 0.53 (1512.5 examples/sec; 0.085 sec/batch)
2017-05-02 19:27:33.999811: step 23000, loss = 0.37 (1451.7 examples/sec; 0.088 sec/batch)
2017-05-02 19:27:56.804232: step 23100, loss = 0.44 (2730.9 examples/sec; 0.047 sec/batch)
2017-05-02 19:28:16.515597: step 23200, loss = 0.36 (1379.7 examples/sec; 0.093 sec/batch)
2017-05-02 19:28:36.943751: step 23300, loss = 0.39 (1473.8 examples/sec; 0.087 sec/batch)
2017-05-02 19:28:56.408942: step 23400, loss = 0.44 (1302.8 examples/sec; 0.098 sec/batch)
2017-05-02 19:29:14.876579: step 23500, loss = 0.34 (1388.4 examples/sec; 0.092 sec/batch)
2017-05-02 19:29:33.806582: step 23600, loss = 0.36 (1420.4 examples/sec; 0.090 sec/batch)
2017-05-02 19:29:52.324032: step 23700, loss = 0.34 (1783.9 examples/sec; 0.072 sec/batch)
2017-05-02 19:30:10.968760: step 23800, loss = 0.37 (1515.0 examples/sec; 0.084 sec/batch)
2017-05-02 19:30:29.064489: step 23900, loss = 0.36 (1404.6 examples/sec; 0.091 sec/batch)
2017-05-02 19:30:47.335530: step 24000, loss = 0.33 (1471.3 examples/sec; 0.087 sec/batch)
2017-05-02 19:31:07.387064: step 24100, loss = 0.35 (1500.5 examples/sec; 0.085 sec/batch)
2017-05-02 19:31:26.352003: step 24200, loss = 0.35 (1448.9 examples/sec; 0.088 sec/batch)
2017-05-02 19:31:44.566633: step 24300, loss = 0.40 (1467.6 examples/sec; 0.087 sec/batch)
2017-05-02 19:32:03.042462: step 24400, loss = 0.31 (1464.3 examples/sec; 0.087 sec/batch)
2017-05-02 19:32:21.053969: step 24500, loss = 0.45 (1509.4 examples/sec; 0.085 sec/batch)
2017-05-02 19:32:39.303010: step 24600, loss = 0.33 (1452.5 examples/sec; 0.088 sec/batch)
2017-05-02 19:32:57.239311: step 24700, loss = 0.30 (1466.7 examples/sec; 0.087 sec/batch)
2017-05-02 19:33:15.257511: step 24800, loss = 0.52 (1496.2 examples/sec; 0.086 sec/batch)
2017-05-02 19:33:33.179198: step 24900, loss = 0.39 (1399.8 examples/sec; 0.091 sec/batch)
2017-05-02 19:33:50.923114: step 25000, loss = 0.39 (1476.7 examples/sec; 0.087 sec/batch)
2017-05-02 19:34:10.406094: step 25100, loss = 0.36 (1488.8 examples/sec; 0.086 sec/batch)
2017-05-02 19:34:29.471843: step 25200, loss = 0.37 (1443.1 examples/sec; 0.089 sec/batch)
2017-05-02 19:34:47.716232: step 25300, loss = 0.31 (1077.4 examples/sec; 0.119 sec/batch)
2017-05-02 19:35:06.617739: step 25400, loss = 0.38 (1361.6 examples/sec; 0.094 sec/batch)
2017-05-02 19:35:25.294312: step 25500, loss = 0.32 (1456.6 examples/sec; 0.088 sec/batch)
2017-05-02 19:35:44.472570: step 25600, loss = 0.36 (1494.5 examples/sec; 0.086 sec/batch)
2017-05-02 19:36:02.596812: step 25700, loss = 0.37 (1484.9 examples/sec; 0.086 sec/batch)
2017-05-02 19:36:20.922565: step 25800, loss = 0.35 (1463.8 examples/sec; 0.087 sec/batch)
2017-05-02 19:36:39.107621: step 25900, loss = 0.36 (1479.7 examples/sec; 0.087 sec/batch)
2017-05-02 19:36:58.040363: step 26000, loss = 0.35 (1434.3 examples/sec; 0.089 sec/batch)
2017-05-02 19:37:18.175585: step 26100, loss = 0.39 (1410.2 examples/sec; 0.091 sec/batch)
2017-05-02 19:37:36.565564: step 26200, loss = 0.34 (1429.2 examples/sec; 0.090 sec/batch)
2017-05-02 19:37:55.132365: step 26300, loss = 0.32 (1634.4 examples/sec; 0.078 sec/batch)
2017-05-02 19:38:13.263245: step 26400, loss = 0.39 (1059.5 examples/sec; 0.121 sec/batch)
2017-05-02 19:38:31.294745: step 26500, loss = 0.28 (1350.5 examples/sec; 0.095 sec/batch)
2017-05-02 19:38:50.471828: step 26600, loss = 0.35 (1477.4 examples/sec; 0.087 sec/batch)
2017-05-02 19:39:09.409920: step 26700, loss = 0.29 (1440.0 examples/sec; 0.089 sec/batch)
2017-05-02 19:39:27.805426: step 26800, loss = 0.35 (1463.7 examples/sec; 0.087 sec/batch)
2017-05-02 19:39:46.368611: step 26900, loss = 0.31 (1451.6 examples/sec; 0.088 sec/batch)
2017-05-02 19:40:04.373904: step 27000, loss = 0.31 (1435.3 examples/sec; 0.089 sec/batch)
2017-05-02 19:40:23.941890: step 27100, loss = 0.41 (1437.9 examples/sec; 0.089 sec/batch)
2017-05-02 19:40:42.649431: step 27200, loss = 0.36 (1709.5 examples/sec; 0.075 sec/batch)
2017-05-02 19:41:00.727540: step 27300, loss = 0.32 (1436.0 examples/sec; 0.089 sec/batch)
2017-05-02 19:41:18.954181: step 27400, loss = 0.29 (1430.6 examples/sec; 0.089 sec/batch)
2017-05-02 19:41:37.557101: step 27500, loss = 0.34 (601.7 examples/sec; 0.213 sec/batch)
2017-05-02 19:41:55.594021: step 27600, loss = 0.43 (1412.4 examples/sec; 0.091 sec/batch)
2017-05-02 19:42:14.221796: step 27700, loss = 0.36 (1441.5 examples/sec; 0.089 sec/batch)
2017-05-02 19:42:32.411910: step 27800, loss = 0.35 (1405.2 examples/sec; 0.091 sec/batch)
2017-05-02 19:42:50.486484: step 27900, loss = 0.35 (1487.7 examples/sec; 0.086 sec/batch)
2017-05-02 19:43:08.803950: step 28000, loss = 0.37 (1454.8 examples/sec; 0.088 sec/batch)
2017-05-02 19:43:29.006027: step 28100, loss = 0.40 (1417.5 examples/sec; 0.090 sec/batch)
2017-05-02 19:43:47.729508: step 28200, loss = 0.32 (1433.1 examples/sec; 0.089 sec/batch)
2017-05-02 19:44:06.498220: step 28300, loss = 0.31 (1441.5 examples/sec; 0.089 sec/batch)
2017-05-02 19:44:24.973333: step 28400, loss = 0.35 (1471.0 examples/sec; 0.087 sec/batch)
2017-05-02 19:44:44.209580: step 28500, loss = 0.33 (1448.7 examples/sec; 0.088 sec/batch)
2017-05-02 19:45:02.517580: step 28600, loss = 0.32 (1415.1 examples/sec; 0.090 sec/batch)
2017-05-02 19:45:22.081939: step 28700, loss = 0.30 (1428.1 examples/sec; 0.090 sec/batch)
2017-05-02 19:45:40.661183: step 28800, loss = 0.28 (1429.3 examples/sec; 0.090 sec/batch)
2017-05-02 19:45:59.584009: step 28900, loss = 0.28 (1432.7 examples/sec; 0.089 sec/batch)
2017-05-02 19:46:17.758723: step 29000, loss = 0.31 (1465.0 examples/sec; 0.087 sec/batch)
2017-05-02 19:46:37.360546: step 29100, loss = 0.33 (1515.3 examples/sec; 0.084 sec/batch)
2017-05-02 19:46:56.190999: step 29200, loss = 0.35 (1466.8 examples/sec; 0.087 sec/batch)
2017-05-02 19:47:14.485961: step 29300, loss = 0.51 (1405.1 examples/sec; 0.091 sec/batch)
2017-05-02 19:47:33.094404: step 29400, loss = 0.36 (1450.3 examples/sec; 0.088 sec/batch)
2017-05-02 19:47:52.732181: step 29500, loss = 0.45 (1448.6 examples/sec; 0.088 sec/batch)
2017-05-02 19:48:11.134463: step 29600, loss = 0.36 (1425.5 examples/sec; 0.090 sec/batch)
2017-05-02 19:48:29.940185: step 29700, loss = 0.35 (1417.4 examples/sec; 0.090 sec/batch)
2017-05-02 19:48:49.019701: step 29800, loss = 0.32 (1462.7 examples/sec; 0.088 sec/batch)
2017-05-02 19:49:07.870342: step 29900, loss = 0.35 (1487.0 examples/sec; 0.086 sec/batch)
2017-05-02 19:49:29.605143: precision @ 1 = 0.828
2017-05-02 19:49:30.002464: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-04 15:27:55.319481: Running on server...
The experiment details:
max_steps = 30000 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-04 15:29:28.270118: Running on server...
The experiment details:
max_steps = 30000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-04 15:32:21.192801: Running on server...
The experiment details:
max_steps = 30000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-04 15:32:37.506947: step 0, loss = 6.39 (23.5 examples/sec; 5.438 sec/batch)
2017-05-04 15:33:46.752164: step 100, loss = 5.47 (379.4 examples/sec; 0.337 sec/batch)
2017-05-04 15:34:51.384072: step 200, loss = 5.11 (407.0 examples/sec; 0.314 sec/batch)
2017-05-04 15:35:56.324246: step 300, loss = 4.48 (365.6 examples/sec; 0.350 sec/batch)
2017-05-04 15:37:02.308163: step 400, loss = 4.42 (355.6 examples/sec; 0.360 sec/batch)
2017-05-04 15:38:06.766475: step 500, loss = 3.76 (358.8 examples/sec; 0.357 sec/batch)
########################################################################################
########################################################################################
########################################################################################
2017-05-04 15:54:41.232254: Running on server...
The experiment details:
max_steps = 30000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-04 15:54:56.279781: step 0, loss = 6.37 (34.2 examples/sec; 3.738 sec/batch)
########################################################################################
########################################################################################
########################################################################################
2017-05-04 18:04:58.192638: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-04 18:05:16.219195: step 0, loss = 6.38 (30.7 examples/sec; 4.172 sec/batch)
2017-05-04 18:06:07.799099: step 100, loss = 5.65 (560.7 examples/sec; 0.228 sec/batch)
2017-05-04 18:06:52.800191: step 200, loss = 5.15 (584.1 examples/sec; 0.219 sec/batch)
2017-05-04 18:07:45.775962: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-04 18:21:50.823812: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-04 18:22:06.352270: step 0, loss = 6.38 (32.9 examples/sec; 3.892 sec/batch)
2017-05-04 18:23:32.955750: step 100, loss = 6.27 (582.6 examples/sec; 0.220 sec/batch)
2017-05-04 18:24:28.498689: step 200, loss = 4.96 (330.7 examples/sec; 0.387 sec/batch)
2017-05-04 18:25:38.203079: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-05 05:11:09.077603: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-05 05:15:23.137523: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-05 05:17:23.667890: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-05 05:20:43.348450: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-05 05:21:22.899434: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-05 05:22:41.916198: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-05 05:23:42.231484: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-05 05:28:00.132401: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-05 05:28:15.008402: step 0, loss = 6.39 (38.0 examples/sec; 3.366 sec/batch)
2017-05-05 05:28:56.969274: step 100, loss = 5.49 (635.4 examples/sec; 0.201 sec/batch)
2017-05-05 05:29:37.349513: step 200, loss = 5.10 (643.8 examples/sec; 0.199 sec/batch)
2017-05-05 05:30:19.921523: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-05 05:33:58.522844: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-05 05:34:23.025541: step 0, loss = 6.38 (14.1 examples/sec; 9.104 sec/batch)
2017-05-05 05:34:41.851379: step 100, loss = 5.44 (1533.1 examples/sec; 0.083 sec/batch)
2017-05-05 05:34:58.932237: step 200, loss = 5.06 (1515.3 examples/sec; 0.084 sec/batch)
2017-05-05 05:35:18.475877: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-05 06:48:02.677543: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-05 08:00:08.044298: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-05 08:01:50.482709: Running on server...
The experiment details:
max_steps = 300 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-05 08:02:10.850287: step 0, loss = 6.38 (16.4 examples/sec; 7.794 sec/batch)
2017-05-05 08:02:29.547910: step 100, loss = 5.62 (1540.5 examples/sec; 0.083 sec/batch)
2017-05-05 08:02:46.396116: step 200, loss = 5.04 (1508.4 examples/sec; 0.085 sec/batch)
########################################################################################
########################################################################################
########################################################################################
2017-05-05 08:05:01.365308: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-05 08:05:24.228249: step 0, loss = 6.39 (15.3 examples/sec; 8.368 sec/batch)
2017-05-05 08:05:30.971510: precision @ 1 = 0.229
2017-05-05 08:05:31.362618: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-05 08:25:08.174037: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-05 08:27:51.445085: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-05 08:28:12.265474: step 0, loss = 6.37 (16.3 examples/sec; 7.858 sec/batch)
2017-05-05 08:28:18.602107: precision @ 1 = 0.129
2017-05-05 08:28:18.829956: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-05 08:30:55.925526: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-05 08:31:16.683638: step 0, loss = 6.38 (16.1 examples/sec; 7.950 sec/batch)
2017-05-05 08:31:22.778469: precision @ 1 = 0.159
2017-05-05 08:31:23.005261: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-05 12:28:32.922085: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-05 12:28:53.584858: step 0, loss = 6.39 (16.6 examples/sec; 7.689 sec/batch)
2017-05-05 12:29:00.272211: precision @ 1 = 0.158
2017-05-05 12:29:01.288800: DONE
########################################################################################
########################################################################################
########################################################################################
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-05 14:39:05.871238: Running on server...
The experiment details:
max_steps = 30000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-05 14:39:28.706775: step 0, loss = 6.38 (15.3 examples/sec; 8.379 sec/batch)
2017-05-05 14:39:44.783964: step 100, loss = 5.55 (1765.6 examples/sec; 0.072 sec/batch)
2017-05-05 14:39:59.572611: step 200, loss = 5.06 (1720.8 examples/sec; 0.074 sec/batch)
2017-05-05 14:40:14.389180: step 300, loss = 4.73 (1783.0 examples/sec; 0.072 sec/batch)
2017-05-05 14:40:29.263731: step 400, loss = 4.45 (1713.2 examples/sec; 0.075 sec/batch)
2017-05-05 14:40:44.101340: step 500, loss = 4.10 (1772.8 examples/sec; 0.072 sec/batch)
2017-05-05 14:40:58.955501: step 600, loss = 3.69 (1707.1 examples/sec; 0.075 sec/batch)
########################################################################################
########################################################################################
########################################################################################
2017-05-05 14:41:28.558576: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-05 14:41:49.363749: step 0, loss = 6.38 (16.6 examples/sec; 7.726 sec/batch)
2017-05-05 14:41:55.844095: precision @ 1 = 0.151
2017-05-05 14:41:56.084779: DONE
########################################################################################
########################################################################################
########################################################################################
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-06 03:00:40.892519: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 03:01:05.673525: step 0, loss = 6.38 (15.4 examples/sec; 8.313 sec/batch)
2017-05-06 03:01:11.699825: precision @ 1 = 0.231
2017-05-06 03:01:11.975903: DONE
########################################################################################
########################################################################################
########################################################################################
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-06 03:15:44.585966: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 03:16:09.283549: step 0, loss = 6.38 (15.2 examples/sec; 8.415 sec/batch)
2017-05-06 03:16:15.128308: precision @ 1 = 0.183
2017-05-06 03:16:15.363658: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 03:24:11.158403: Running on server...
The experiment details:
max_steps = 30000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 03:24:35.522398: step 0, loss = 6.37 (15.4 examples/sec; 8.327 sec/batch)
2017-05-06 03:24:55.447786: step 100, loss = 5.70 (1517.9 examples/sec; 0.084 sec/batch)
2017-05-06 03:25:12.552273: step 200, loss = 4.96 (1531.8 examples/sec; 0.084 sec/batch)
2017-05-06 03:25:29.674169: step 300, loss = 4.91 (1525.5 examples/sec; 0.084 sec/batch)
2017-05-06 03:25:46.754378: step 400, loss = 4.20 (1371.9 examples/sec; 0.093 sec/batch)
2017-05-06 03:26:03.827820: step 500, loss = 3.88 (1521.7 examples/sec; 0.084 sec/batch)
2017-05-06 03:26:20.893637: step 600, loss = 3.65 (1514.5 examples/sec; 0.085 sec/batch)
2017-05-06 03:26:37.979644: step 700, loss = 3.30 (1541.6 examples/sec; 0.083 sec/batch)
2017-05-06 03:26:55.041914: step 800, loss = 3.14 (1496.1 examples/sec; 0.086 sec/batch)
2017-05-06 03:27:12.157129: step 900, loss = 2.87 (1522.2 examples/sec; 0.084 sec/batch)
2017-05-06 03:27:29.219873: step 1000, loss = 2.60 (1546.9 examples/sec; 0.083 sec/batch)
2017-05-06 03:27:47.615227: step 1100, loss = 2.48 (1534.9 examples/sec; 0.083 sec/batch)
2017-05-06 03:28:04.735429: step 1200, loss = 2.44 (1392.9 examples/sec; 0.092 sec/batch)
2017-05-06 03:28:21.810860: step 1300, loss = 2.25 (1489.5 examples/sec; 0.086 sec/batch)
2017-05-06 03:28:38.874157: step 1400, loss = 2.35 (1536.4 examples/sec; 0.083 sec/batch)
2017-05-06 03:28:55.952617: step 1500, loss = 2.01 (1519.0 examples/sec; 0.084 sec/batch)
2017-05-06 03:29:13.048300: step 1600, loss = 1.83 (1540.9 examples/sec; 0.083 sec/batch)
2017-05-06 03:29:30.119148: step 1700, loss = 1.95 (1502.7 examples/sec; 0.085 sec/batch)
2017-05-06 03:29:47.196252: step 1800, loss = 1.67 (1509.4 examples/sec; 0.085 sec/batch)
2017-05-06 03:30:04.279597: step 1900, loss = 1.56 (1485.2 examples/sec; 0.086 sec/batch)
2017-05-06 03:30:21.387832: step 2000, loss = 1.52 (1539.9 examples/sec; 0.083 sec/batch)
2017-05-06 03:30:39.826470: step 2100, loss = 1.99 (1530.7 examples/sec; 0.084 sec/batch)
2017-05-06 03:30:57.001952: step 2200, loss = 1.26 (1501.4 examples/sec; 0.085 sec/batch)
2017-05-06 03:31:14.099177: step 2300, loss = 1.17 (1536.5 examples/sec; 0.083 sec/batch)
2017-05-06 03:31:31.197149: step 2400, loss = 1.41 (1498.6 examples/sec; 0.085 sec/batch)
2017-05-06 03:31:48.315813: step 2500, loss = 1.24 (1481.2 examples/sec; 0.086 sec/batch)
2017-05-06 03:32:05.503048: step 2600, loss = 1.05 (1496.9 examples/sec; 0.086 sec/batch)
2017-05-06 03:32:22.586565: step 2700, loss = 1.04 (1491.2 examples/sec; 0.086 sec/batch)
2017-05-06 03:32:39.663913: step 2800, loss = 1.01 (1545.0 examples/sec; 0.083 sec/batch)
2017-05-06 03:32:56.735148: step 2900, loss = 0.94 (1508.0 examples/sec; 0.085 sec/batch)
2017-05-06 03:33:13.817258: step 3000, loss = 1.32 (1530.7 examples/sec; 0.084 sec/batch)
2017-05-06 03:33:32.242256: step 3100, loss = 0.88 (1488.8 examples/sec; 0.086 sec/batch)
2017-05-06 03:33:49.325780: step 3200, loss = 0.81 (1525.0 examples/sec; 0.084 sec/batch)
2017-05-06 03:34:06.389275: step 3300, loss = 1.00 (1534.0 examples/sec; 0.083 sec/batch)
2017-05-06 03:34:23.464614: step 3400, loss = 0.77 (1520.1 examples/sec; 0.084 sec/batch)
2017-05-06 03:34:40.539346: step 3500, loss = 0.75 (1511.1 examples/sec; 0.085 sec/batch)
2017-05-06 03:34:57.620175: step 3600, loss = 0.64 (1547.7 examples/sec; 0.083 sec/batch)
2017-05-06 03:35:14.698984: step 3700, loss = 0.76 (1507.8 examples/sec; 0.085 sec/batch)
2017-05-06 03:35:31.804360: step 3800, loss = 0.69 (1516.2 examples/sec; 0.084 sec/batch)
2017-05-06 03:35:48.931194: step 3900, loss = 0.80 (1543.3 examples/sec; 0.083 sec/batch)
2017-05-06 03:36:06.100287: step 4000, loss = 0.68 (1528.1 examples/sec; 0.084 sec/batch)
2017-05-06 03:36:24.553386: step 4100, loss = 0.68 (1522.2 examples/sec; 0.084 sec/batch)
2017-05-06 03:36:41.735390: step 4200, loss = 0.66 (1537.0 examples/sec; 0.083 sec/batch)
2017-05-06 03:36:58.840075: step 4300, loss = 0.58 (1534.1 examples/sec; 0.083 sec/batch)
2017-05-06 03:37:16.043830: step 4400, loss = 0.66 (1525.2 examples/sec; 0.084 sec/batch)
2017-05-06 03:37:33.144203: step 4500, loss = 0.63 (1534.4 examples/sec; 0.083 sec/batch)
2017-05-06 03:37:50.273974: step 4600, loss = 0.61 (1531.6 examples/sec; 0.084 sec/batch)
2017-05-06 03:38:07.457821: step 4700, loss = 0.59 (1531.8 examples/sec; 0.084 sec/batch)
2017-05-06 03:38:24.568549: step 4800, loss = 0.56 (1504.7 examples/sec; 0.085 sec/batch)
2017-05-06 03:38:41.766350: step 4900, loss = 0.52 (1412.7 examples/sec; 0.091 sec/batch)
2017-05-06 03:38:58.885456: step 5000, loss = 0.60 (1503.0 examples/sec; 0.085 sec/batch)
2017-05-06 03:39:17.314352: step 5100, loss = 0.47 (1571.5 examples/sec; 0.081 sec/batch)
2017-05-06 03:39:34.530290: step 5200, loss = 0.49 (1528.9 examples/sec; 0.084 sec/batch)
2017-05-06 03:39:51.703140: step 5300, loss = 0.46 (1535.7 examples/sec; 0.083 sec/batch)
2017-05-06 03:40:08.864551: step 5400, loss = 0.44 (1521.0 examples/sec; 0.084 sec/batch)
2017-05-06 03:40:26.106556: step 5500, loss = 0.54 (1453.7 examples/sec; 0.088 sec/batch)
2017-05-06 03:40:43.341919: step 5600, loss = 0.54 (1519.6 examples/sec; 0.084 sec/batch)
2017-05-06 03:41:00.592320: step 5700, loss = 0.45 (1478.7 examples/sec; 0.087 sec/batch)
2017-05-06 03:41:17.825703: step 5800, loss = 0.44 (1517.3 examples/sec; 0.084 sec/batch)
2017-05-06 03:41:35.021986: step 5900, loss = 0.64 (1515.9 examples/sec; 0.084 sec/batch)
2017-05-06 03:41:52.172596: step 6000, loss = 0.48 (1516.9 examples/sec; 0.084 sec/batch)
2017-05-06 03:42:10.579390: step 6100, loss = 0.47 (1531.4 examples/sec; 0.084 sec/batch)
2017-05-06 03:42:27.815143: step 6200, loss = 0.43 (1530.5 examples/sec; 0.084 sec/batch)
2017-05-06 03:42:44.969624: step 6300, loss = 0.56 (1479.7 examples/sec; 0.087 sec/batch)
########################################################################################
########################################################################################
########################################################################################
2017-05-06 03:45:02.496969: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 03:45:23.500964: step 0, loss = 6.38 (16.6 examples/sec; 7.717 sec/batch)
2017-05-06 03:45:30.045663: precision @ 1 = 0.189
2017-05-06 03:45:30.278521: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 04:38:00.763874: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Number of hidden parameters of conv1: 2432
Number of hidden parameters of conv2: 51264
Number of hidden parameters of local3: 1573248
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 1702794
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Number of hidden parameters of conv1: 2432
Number of hidden parameters of conv2: 51264
Number of hidden parameters of local3: 1573248
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 1702794
2017-05-06 04:38:24.430194: step 0, loss = 6.38 (15.3 examples/sec; 8.365 sec/batch)
Number of hidden parameters of conv1: 2432
Number of hidden parameters of conv2: 51264
Number of hidden parameters of local3: 1573248
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 1702794
Evaluation results:
2017-05-06 04:38:30.544127: Total Predictions = 1024
2017-05-06 04:38:30.553391: Correct Predictions = 126
2017-05-06 04:38:30.563941: Wrong Predictions = 898
2017-05-06 04:38:30.575084: precision @ 1 = 0.123
2017-05-06 04:38:30.782233: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 04:39:47.880547: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Number of hidden parameters of conv1: 896
Number of hidden parameters of conv2: 51264
Number of hidden parameters of local3: 1573248
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 1701258
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Number of hidden parameters of conv1: 896
Number of hidden parameters of conv2: 51264
Number of hidden parameters of local3: 1573248
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 1701258
2017-05-06 04:40:08.677058: step 0, loss = 6.38 (16.2 examples/sec; 7.882 sec/batch)
Number of hidden parameters of conv1: 896
Number of hidden parameters of conv2: 51264
Number of hidden parameters of local3: 1573248
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 1701258
Evaluation results:
2017-05-06 04:40:15.077228: Total Predictions = 1024
2017-05-06 04:40:15.085067: Correct Predictions = 184
2017-05-06 04:40:15.093210: Wrong Predictions = 840
2017-05-06 04:40:15.101206: precision @ 1 = 0.180
2017-05-06 04:40:15.326650: DONE
########################################################################################
########################################################################################
########################################################################################
Number of hidden parameters of conv1: 896
Number of hidden parameters of conv2: 51264
Number of hidden parameters of local3: 147840
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 275850
Number of hidden parameters of conv1: 896
Number of hidden parameters of conv2: 51264
Number of hidden parameters of local3: 147840
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 275850
########################################################################################
########################################################################################
########################################################################################
2017-05-06 04:53:28.941588: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 04:53:49.460756: step 0, loss = 6.38 (16.6 examples/sec; 7.719 sec/batch)
Evaluation results:
2017-05-06 04:53:55.551054: Total Predictions = 1024
2017-05-06 04:53:55.557673: Correct Predictions = 125
2017-05-06 04:53:55.566454: Wrong Predictions = 899
2017-05-06 04:53:55.573311: precision @ 1 = 0.122
2017-05-06 04:53:55.774691: DONE
########################################################################################
########################################################################################
########################################################################################
Number of hidden parameters of conv1: 1792
Number of hidden parameters of conv2: 102464
Number of hidden parameters of local3: 147840
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 327946
Number of hidden parameters of conv1: 1792
Number of hidden parameters of conv2: 204928
Number of hidden parameters of local3: 147840
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 430410
########################################################################################
########################################################################################
########################################################################################
2017-05-06 04:56:00.791206: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 04:56:22.772179: step 0, loss = 10.27 (15.1 examples/sec; 8.457 sec/batch)
Evaluation results:
2017-05-06 04:56:29.652982: Total Predictions = 1024
2017-05-06 04:56:29.666123: Correct Predictions = 227
2017-05-06 04:56:29.679720: Wrong Predictions = 797
2017-05-06 04:56:29.688107: precision @ 1 = 0.222
2017-05-06 04:56:30.050833: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [3, 3, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 384  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 1792
Number of hidden parameters of conv2: 204928
Number of hidden parameters of local3: 147840
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 430410
########################################################################################
########################################################################################
########################################################################################
2017-05-06 05:10:33.745760: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 05:10:54.262434: step 0, loss = 10.27 (17.0 examples/sec; 7.547 sec/batch)
Evaluation results:
2017-05-06 05:11:01.089945: Total Predictions = 1024
2017-05-06 05:11:01.095895: Correct Predictions = 163
2017-05-06 05:11:01.102314: Wrong Predictions = 861
2017-05-06 05:11:01.108698: precision @ 1 = 0.159
2017-05-06 05:11:01.472038: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [3, 3, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 384  | local3OutputDepth: 768
local4InputDepth: 768  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 1792
Number of hidden parameters of conv2: 204928
Number of hidden parameters of local3: 295680
Number of hidden parameters of local4: 147648
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 651978
Network summary:
conv1Shape: [3, 3, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 384  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 1792
Number of hidden parameters of conv2: 204928
Number of hidden parameters of local3: 147840
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 430410
########################################################################################
########################################################################################
########################################################################################
2017-05-06 05:13:33.481494: Running on server...
The experiment details:
max_steps = 1000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 05:13:54.253448: step 0, loss = 10.28 (16.7 examples/sec; 7.660 sec/batch)
2017-05-06 05:14:15.509998: step 100, loss = 9.07 (1303.8 examples/sec; 0.098 sec/batch)
2017-05-06 05:14:39.413816: step 200, loss = 8.67 (1331.5 examples/sec; 0.096 sec/batch)
2017-05-06 05:14:59.257208: step 300, loss = 7.77 (1327.7 examples/sec; 0.096 sec/batch)
2017-05-06 05:15:19.047048: step 400, loss = 7.25 (1333.1 examples/sec; 0.096 sec/batch)
2017-05-06 05:15:38.835037: step 500, loss = 6.82 (1301.0 examples/sec; 0.098 sec/batch)
2017-05-06 05:16:03.012721: step 600, loss = 6.21 (1338.6 examples/sec; 0.096 sec/batch)
2017-05-06 05:16:22.769840: step 700, loss = 5.56 (1311.8 examples/sec; 0.098 sec/batch)
2017-05-06 05:16:43.896609: step 800, loss = 5.40 (1259.0 examples/sec; 0.102 sec/batch)
2017-05-06 05:17:04.015154: step 900, loss = 5.00 (1308.7 examples/sec; 0.098 sec/batch)
Evaluation results:
2017-05-06 05:17:28.341723: Total Predictions = 1024
2017-05-06 05:17:28.350941: Correct Predictions = 711
2017-05-06 05:17:28.358815: Wrong Predictions = 313
2017-05-06 05:17:28.368494: precision @ 1 = 0.694
2017-05-06 05:17:28.725636: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 05:20:37.629658: Running on server...
The experiment details:
max_steps = 4000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 05:21:03.312783: step 0, loss = 10.28 (12.5 examples/sec; 10.261 sec/batch)
2017-05-06 05:21:24.767219: step 100, loss = 9.07 (1279.0 examples/sec; 0.100 sec/batch)
2017-05-06 05:21:44.548738: step 200, loss = 8.50 (1316.2 examples/sec; 0.097 sec/batch)
2017-05-06 05:22:05.408034: step 300, loss = 7.86 (1318.2 examples/sec; 0.097 sec/batch)
2017-05-06 05:22:25.192726: step 400, loss = 7.34 (1322.5 examples/sec; 0.097 sec/batch)
2017-05-06 05:22:44.894839: step 500, loss = 6.44 (1322.3 examples/sec; 0.097 sec/batch)
2017-05-06 05:23:04.652071: step 600, loss = 6.19 (1326.4 examples/sec; 0.097 sec/batch)
2017-05-06 05:23:24.389363: step 700, loss = 5.56 (1222.5 examples/sec; 0.105 sec/batch)
2017-05-06 05:23:47.087676: step 800, loss = 5.45 (1327.4 examples/sec; 0.096 sec/batch)
2017-05-06 05:24:06.829623: step 900, loss = 4.92 (1262.2 examples/sec; 0.101 sec/batch)
2017-05-06 05:24:26.558771: step 1000, loss = 4.58 (1321.9 examples/sec; 0.097 sec/batch)
2017-05-06 05:24:47.511441: step 1100, loss = 4.38 (1319.5 examples/sec; 0.097 sec/batch)
2017-05-06 05:25:07.255013: step 1200, loss = 4.22 (1296.0 examples/sec; 0.099 sec/batch)
2017-05-06 05:25:31.948879: step 1300, loss = 3.73 (1319.2 examples/sec; 0.097 sec/batch)
2017-05-06 05:25:53.349751: step 1400, loss = 3.36 (1361.9 examples/sec; 0.094 sec/batch)
2017-05-06 05:26:15.883314: step 1500, loss = 3.14 (1328.3 examples/sec; 0.096 sec/batch)
2017-05-06 05:26:39.914647: step 1600, loss = 3.08 (1337.8 examples/sec; 0.096 sec/batch)
2017-05-06 05:26:59.689280: step 1700, loss = 2.92 (1325.3 examples/sec; 0.097 sec/batch)
2017-05-06 05:27:19.405027: step 1800, loss = 2.77 (1307.5 examples/sec; 0.098 sec/batch)
2017-05-06 05:27:39.151103: step 1900, loss = 2.51 (1328.5 examples/sec; 0.096 sec/batch)
2017-05-06 05:27:58.900511: step 2000, loss = 2.29 (1330.4 examples/sec; 0.096 sec/batch)
2017-05-06 05:28:20.443044: step 2100, loss = 2.16 (1298.2 examples/sec; 0.099 sec/batch)
2017-05-06 05:28:42.609356: step 2200, loss = 2.06 (1328.1 examples/sec; 0.096 sec/batch)
2017-05-06 05:29:03.348807: step 2300, loss = 1.87 (223.1 examples/sec; 0.574 sec/batch)
2017-05-06 05:29:26.126846: step 2400, loss = 1.93 (1295.8 examples/sec; 0.099 sec/batch)
2017-05-06 05:29:45.911712: step 2500, loss = 1.80 (1269.1 examples/sec; 0.101 sec/batch)
2017-05-06 05:30:15.865749: step 2600, loss = 1.57 (1319.9 examples/sec; 0.097 sec/batch)
2017-05-06 05:30:50.866291: step 2700, loss = 1.53 (1132.0 examples/sec; 0.113 sec/batch)
2017-05-06 05:31:13.085583: step 2800, loss = 1.37 (1309.8 examples/sec; 0.098 sec/batch)
2017-05-06 05:31:32.839624: step 2900, loss = 1.27 (1326.6 examples/sec; 0.096 sec/batch)
2017-05-06 05:31:52.567144: step 3000, loss = 1.35 (1333.0 examples/sec; 0.096 sec/batch)
2017-05-06 05:32:13.821877: step 3100, loss = 1.32 (1333.4 examples/sec; 0.096 sec/batch)
2017-05-06 05:32:33.595946: step 3200, loss = 1.32 (1318.2 examples/sec; 0.097 sec/batch)
2017-05-06 05:32:53.391983: step 3300, loss = 1.15 (1305.3 examples/sec; 0.098 sec/batch)
2017-05-06 05:33:13.217718: step 3400, loss = 1.08 (1287.7 examples/sec; 0.099 sec/batch)
2017-05-06 05:33:33.012048: step 3500, loss = 1.08 (1311.8 examples/sec; 0.098 sec/batch)
2017-05-06 05:33:52.805668: step 3600, loss = 1.00 (1308.1 examples/sec; 0.098 sec/batch)
2017-05-06 05:34:12.589351: step 3700, loss = 0.92 (1305.5 examples/sec; 0.098 sec/batch)
2017-05-06 05:34:32.413867: step 3800, loss = 0.84 (1395.1 examples/sec; 0.092 sec/batch)
2017-05-06 05:34:52.189158: step 3900, loss = 1.05 (1321.3 examples/sec; 0.097 sec/batch)
Evaluation results:
2017-05-06 05:35:15.308766: Total Predictions = 1024
2017-05-06 05:35:15.315709: Correct Predictions = 821
2017-05-06 05:35:15.322752: Wrong Predictions = 203
2017-05-06 05:35:15.328866: precision @ 1 = 0.802
2017-05-06 05:35:15.800302: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 384  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 147840
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 302410
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 384  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 147840
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 302410
########################################################################################
########################################################################################
########################################################################################
2017-05-06 05:43:59.492485: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-06 05:57:38.198102: Running on server...
The experiment details:
max_steps = 30000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 384  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 147840
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 302410
########################################################################################
########################################################################################
########################################################################################
2017-05-06 05:59:20.161644: Running on server...
The experiment details:
max_steps = 30000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3300682
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:01:43.396430: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3300682
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:04:06.247239: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 0
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
2017-05-06 06:04:40.900405: step 0, loss = 10.27 (729.8 examples/sec; 0.175 sec/batch)
local3InputDepth: 8192  | local3OutputDepth: 384
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3300682
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:08:59.986651: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
2017-05-06 06:09:22.829189: step 0, loss = 10.28 (15.9 examples/sec; 8.047 sec/batch)
local3InputDepth: 8192  | local3OutputDepth: 384
Evaluation results:
2017-05-06 06:09:29.625926: Total Predictions = 1024
2017-05-06 06:09:29.639124: Correct Predictions = 188
2017-05-06 06:09:29.645442: Wrong Predictions = 836
2017-05-06 06:09:29.651969: precision @ 1 = 0.184
2017-05-06 06:09:30.026550: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:12:20.606502: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
2017-05-06 06:12:41.377016: step 0, loss = 10.27 (16.1 examples/sec; 7.966 sec/batch)
local3InputDepth: 8192  | local3OutputDepth: 384
Evaluation results:
2017-05-06 06:12:48.135161: Total Predictions = 1024
2017-05-06 06:12:48.152295: Correct Predictions = 193
2017-05-06 06:12:48.159719: Wrong Predictions = 831
2017-05-06 06:12:48.166384: precision @ 1 = 0.188
2017-05-06 06:12:48.532660: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3300682
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3300682
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:17:43.820815: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3300682
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:18:13.453243: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
2017-05-06 06:18:35.346724: step 0, loss = 10.26 (15.1 examples/sec; 8.492 sec/batch)
local3InputDepth: 8192  | local3OutputDepth: 384
Evaluation results:
2017-05-06 06:18:42.384536: Total Predictions = 1024
2017-05-06 06:18:42.392218: Correct Predictions = 146
2017-05-06 06:18:42.398863: Wrong Predictions = 878
2017-05-06 06:18:42.406506: precision @ 1 = 0.143
2017-05-06 06:18:42.787808: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3300682
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:18:53.907879: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3300682
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:19:44.064801: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
2017-05-06 06:20:08.459960: step 0, loss = 10.28 (15.9 examples/sec; 8.050 sec/batch)
local3InputDepth: 8192  | local3OutputDepth: 384
Evaluation results:
2017-05-06 06:20:14.980212: Total Predictions = 1024
2017-05-06 06:20:14.986877: Correct Predictions = 160
2017-05-06 06:20:14.993811: Wrong Predictions = 864
2017-05-06 06:20:15.000366: precision @ 1 = 0.156
2017-05-06 06:20:15.370333: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [5, 5, 3, 64]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 64, 128]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 4864
Number of hidden parameters of conv2: 73856
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3300682
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:20:50.604240: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 8192  | local3OutputDepth: 384
Network summary:
conv1Shape: [5, 5, 3, 32]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 32, 64]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 2432
Number of hidden parameters of conv2: 18496
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3242890
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:22:32.127957: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384
2017-05-06 06:22:52.658848: step 0, loss = 6.38 (16.7 examples/sec; 7.680 sec/batch)
local3InputDepth: 4096  | local3OutputDepth: 384
Evaluation results:
2017-05-06 06:22:58.542087: Total Predictions = 1024
2017-05-06 06:22:58.550506: Correct Predictions = 164
2017-05-06 06:22:58.559030: Wrong Predictions = 860
2017-05-06 06:22:58.567960: precision @ 1 = 0.160
2017-05-06 06:22:58.770578: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [5, 5, 3, 32]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 32, 64]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 2432
Number of hidden parameters of conv2: 18496
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3242890
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:31:07.701223: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384
2017-05-06 06:31:30.915765: step 0, loss = 6.37 (15.4 examples/sec; 8.337 sec/batch)
local3InputDepth: 4096  | local3OutputDepth: 384
Evaluation results:
2017-05-06 06:31:36.641091: Total Predictions = 1024
2017-05-06 06:31:36.647901: Correct Predictions = 92
2017-05-06 06:31:36.654678: Wrong Predictions = 932
2017-05-06 06:31:36.662769: precision @ 1 = 0.090
2017-05-06 06:31:36.869550: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [5, 5, 3, 32]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 32, 64]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 2432
Number of hidden parameters of conv2: 18496
Number of hidden parameters of local3: 3146112
Number of hidden parameters of local4: 73920
Number of hidden parameters of softmax: 1930
Total number of hidden parameters: 3242890
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:36:36.065638: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384
2017-05-06 06:36:58.879079: step 0, loss = 6.38 (15.1 examples/sec; 8.479 sec/batch)
local3InputDepth: 4096  | local3OutputDepth: 384
Evaluation results:
2017-05-06 06:37:04.614365: Total Predictions = 1024
2017-05-06 06:37:04.621001: Correct Predictions = 128
2017-05-06 06:37:04.627236: Wrong Predictions = 896
2017-05-06 06:37:04.634165: precision @ 1 = 0.125
2017-05-06 06:37:04.840675: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [5, 5, 3, 32]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 32, 64]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 8192  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 2400
Number of hidden parameters of conv1Biases: 32
Number of hidden parameters of conv2: 18432
Number of hidden parameters of conv2Biases: 64
Number of hidden parameters of local3: 3145728
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 73728
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 3242890
Network summary:
conv1Shape: [5, 5, 3, 32]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 32, 64]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 4096  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 2400
Number of hidden parameters of conv1Biases: 32
Number of hidden parameters of conv2: 18432
Number of hidden parameters of conv2Biases: 64
Number of hidden parameters of local3: 1572864
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 73728
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 1670026
########################################################################################
########################################################################################
########################################################################################
2017-05-06 06:58:44.699465: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384
2017-05-06 06:59:05.462878: step 0, loss = 6.37 (16.1 examples/sec; 7.948 sec/batch)
local3InputDepth: 4096  | local3OutputDepth: 384
Evaluation results:
2017-05-06 06:59:11.815690: Total Predictions = 1024
2017-05-06 06:59:11.822945: Correct Predictions = 140
2017-05-06 06:59:11.829586: Wrong Predictions = 884
2017-05-06 06:59:11.845663: precision @ 1 = 0.137
2017-05-06 06:59:12.055966: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [5, 5, 3, 32]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 32, 64]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 4096  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 2400
Number of hidden parameters of conv1Biases: 32
Number of hidden parameters of conv2: 18432
Number of hidden parameters of conv2Biases: 64
Number of hidden parameters of local3: 1572864
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 73728
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 1670026
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:04:52.750422: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384 (128, 4096)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384 (128, 4096)
2017-05-06 07:05:13.738170: step 0, loss = 6.38 (16.0 examples/sec; 7.995 sec/batch)
local3InputDepth: 4096  | local3OutputDepth: 384 (128, 4096)
Evaluation results:
2017-05-06 07:05:19.690125: Total Predictions = 1024
2017-05-06 07:05:19.700096: Correct Predictions = 117
2017-05-06 07:05:19.708054: Wrong Predictions = 907
2017-05-06 07:05:19.715906: precision @ 1 = 0.114
2017-05-06 07:05:19.918027: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [3, 3, 3, 32]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 32, 64]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 4096  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 864
Number of hidden parameters of conv1Biases: 32
Number of hidden parameters of conv2: 18432
Number of hidden parameters of conv2Biases: 64
Number of hidden parameters of local3: 1572864
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 73728
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 1668490
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:09:39.720679: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384 (128, 4096)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 4096  | local3OutputDepth: 384 (128, 4096)
2017-05-06 07:10:00.793159: step 0, loss = 6.38 (16.0 examples/sec; 8.007 sec/batch)
local3InputDepth: 4096  | local3OutputDepth: 384 (128, 4096)
Evaluation results:
2017-05-06 07:10:06.809796: Total Predictions = 1024
2017-05-06 07:10:06.818063: Correct Predictions = 120
2017-05-06 07:10:06.826424: Wrong Predictions = 904
2017-05-06 07:10:06.833174: precision @ 1 = 0.117
2017-05-06 07:10:07.874667: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [3, 3, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 4096  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 108
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 360
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 1572864
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 73728
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 1649580
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:12:06.730556: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 640  | local3OutputDepth: 384 (128, 640)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 640  | local3OutputDepth: 384 (128, 640)
2017-05-06 07:12:27.971007: step 0, loss = 3.09 (15.8 examples/sec; 8.096 sec/batch)
local3InputDepth: 640  | local3OutputDepth: 384 (128, 640)
Evaluation results:
2017-05-06 07:12:33.517821: Total Predictions = 1024
2017-05-06 07:12:33.525807: Correct Predictions = 162
2017-05-06 07:12:33.533785: Wrong Predictions = 862
2017-05-06 07:12:33.542031: precision @ 1 = 0.158
2017-05-06 07:12:33.605156: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [3, 3, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: [3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10]  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 108
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 360
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: [3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10, 3, 3, 4, 10]
Number of hidden parameters of local3Biases: 384
Network summary:
conv1Shape: [3, 3, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 108
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 360
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 245760
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 73728
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 322476
Network summary:
conv1Shape: [3, 3, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 108
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 245760
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 73728
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 322276
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:15:43.889352: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 640  | local3OutputDepth: 384 (128, 640)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 640  | local3OutputDepth: 384 (128, 640)
2017-05-06 07:16:04.810506: step 0, loss = 3.09 (16.6 examples/sec; 7.733 sec/batch)
local3InputDepth: 640  | local3OutputDepth: 384 (128, 640)
Evaluation results:
2017-05-06 07:16:10.340646: Total Predictions = 1024
2017-05-06 07:16:10.347373: Correct Predictions = 105
2017-05-06 07:16:10.353932: Wrong Predictions = 919
2017-05-06 07:16:10.360522: precision @ 1 = 0.103
2017-05-06 07:16:10.422826: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [3, 3, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 108
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 245760
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 73728
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 322276
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:16:23.641688: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 640  | local3OutputDepth: 384 (128, 640)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 640  | local3OutputDepth: 384 (128, 640)
2017-05-06 07:16:44.352207: step 0, loss = 3.09 (16.7 examples/sec; 7.680 sec/batch)
local3InputDepth: 640  | local3OutputDepth: 384 (128, 640)
Evaluation results:
2017-05-06 07:16:49.933807: Total Predictions = 1024
2017-05-06 07:16:49.942310: Correct Predictions = 104
2017-05-06 07:16:49.949456: Wrong Predictions = 920
2017-05-06 07:16:49.958394: precision @ 1 = 0.102
2017-05-06 07:16:50.025931: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [3, 3, 3, 16]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 32]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 2048  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 432
Number of hidden parameters of conv1Biases: 16
Number of hidden parameters of conv2: 512
Number of hidden parameters of conv2Biases: 32
Number of hidden parameters of local3: 786432
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 73728
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 863658
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:17:15.612074: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Network summary:
conv1Shape: [3, 3, 3, 16]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 16, 32]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 2048  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 432
Number of hidden parameters of conv1Biases: 16
Number of hidden parameters of conv2: 2048
Number of hidden parameters of conv2Biases: 32
Number of hidden parameters of local3: 786432
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 73728
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 865194
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:18:57.336346: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 2048  | local3OutputDepth: 384 (128, 2048)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 2048  | local3OutputDepth: 384 (128, 2048)
2017-05-06 07:19:18.320014: step 0, loss = 4.43 (16.4 examples/sec; 7.818 sec/batch)
local3InputDepth: 2048  | local3OutputDepth: 384 (128, 2048)
Evaluation results:
2017-05-06 07:19:26.190573: Total Predictions = 1024
2017-05-06 07:19:26.198727: Correct Predictions = 110
2017-05-06 07:19:26.207231: Wrong Predictions = 914
2017-05-06 07:19:26.214679: precision @ 1 = 0.107
2017-05-06 07:19:26.336365: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [3, 3, 3, 16]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 16, 16]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 1024  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 432
Number of hidden parameters of conv1Biases: 16
Number of hidden parameters of conv2: 1024
Number of hidden parameters of conv2Biases: 16
Number of hidden parameters of local3: 393216
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 73728
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 470938
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:21:22.119180: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 1024  | local3OutputDepth: 384 (128, 1024)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 1024  | local3OutputDepth: 384 (128, 1024)
2017-05-06 07:22:43.291283: step 0, loss = 3.46 (3.4 examples/sec; 37.997 sec/batch)
local3InputDepth: 1024  | local3OutputDepth: 384 (128, 1024)
Evaluation results:
2017-05-06 07:22:49.272812: Total Predictions = 1024
2017-05-06 07:22:49.280630: Correct Predictions = 107
2017-05-06 07:22:49.288197: Wrong Predictions = 917
2017-05-06 07:22:49.296679: precision @ 1 = 0.104
2017-05-06 07:22:49.420302: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [3, 3, 3, 16]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 16, 16]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 1024  | local3OutputDepth: 1024
local4InputDepth: 1024  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 432
Number of hidden parameters of conv1Biases: 16
Number of hidden parameters of conv2: 1024
Number of hidden parameters of conv2Biases: 16
Number of hidden parameters of local3: 1048576
Number of hidden parameters of local3Biases: 1024
Number of hidden parameters of local4: 196608
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 1249818
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:24:05.130188: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 1024  | local3OutputDepth: 1024 (128, 1024)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 1024  | local3OutputDepth: 1024 (128, 1024)
2017-05-06 07:24:26.638589: step 0, loss = 5.38 (16.1 examples/sec; 7.960 sec/batch)
local3InputDepth: 1024  | local3OutputDepth: 1024 (128, 1024)
Evaluation results:
2017-05-06 07:24:32.475403: Total Predictions = 1024
2017-05-06 07:24:32.483926: Correct Predictions = 109
2017-05-06 07:24:32.491771: Wrong Predictions = 915
2017-05-06 07:24:32.499695: precision @ 1 = 0.106
2017-05-06 07:24:32.645549: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [5, 5, 3, 16]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 16, 32]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 2048  | local3OutputDepth: 2048
local4InputDepth: 2048  | local4OutputDepth: 192
softmax_linearInput: 192

Number of hidden parameters of conv1: 1200
Number of hidden parameters of conv1Biases: 16
Number of hidden parameters of conv2: 12800
Number of hidden parameters of conv2Biases: 32
Number of hidden parameters of local3: 4194304
Number of hidden parameters of local3Biases: 2048
Number of hidden parameters of local4: 393216
Number of hidden parameters of local4Biases: 192
Number of hidden parameters of softmax: 1920
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 4605738
Network summary:
conv1Shape: [5, 5, 3, 16]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 16, 32]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 2048  | local3OutputDepth: 2048
local4InputDepth: 2048  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 1200
Number of hidden parameters of conv1Biases: 16
Number of hidden parameters of conv2: 12800
Number of hidden parameters of conv2Biases: 32
Number of hidden parameters of local3: 4194304
Number of hidden parameters of local3Biases: 2048
Number of hidden parameters of local4: 131072
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 4342186
Network summary:
conv1Shape: [5, 5, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 4, 16]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 1024  | local3OutputDepth: 1024
local4InputDepth: 1024  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 300
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 1600
Number of hidden parameters of conv2Biases: 16
Number of hidden parameters of local3: 1048576
Number of hidden parameters of local3Biases: 1024
Number of hidden parameters of local4: 65536
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 1117770
Network summary:
conv1Shape: [5, 5, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 4, 16]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 1024  | local3OutputDepth: 1024
local4InputDepth: 1024  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 300
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 1600
Number of hidden parameters of conv2Biases: 16
Number of hidden parameters of local3: 1048576
Number of hidden parameters of local3Biases: 1024
Number of hidden parameters of local4: 65536
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 1117770
Network summary:
conv1Shape: [5, 5, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 4, 16]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 1024  | local3OutputDepth: 1024
local4InputDepth: 1024  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 300
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 576
Number of hidden parameters of conv2Biases: 16
Number of hidden parameters of local3: 1048576
Number of hidden parameters of local3Biases: 1024
Number of hidden parameters of local4: 65536
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 1116746
Network summary:
conv1Shape: [3, 3, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 4, 16]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 1024  | local3OutputDepth: 1024
local4InputDepth: 1024  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 108
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 576
Number of hidden parameters of conv2Biases: 16
Number of hidden parameters of local3: 1048576
Number of hidden parameters of local3Biases: 1024
Number of hidden parameters of local4: 65536
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 1116554
Network summary:
conv1Shape: [3, 3, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 4, 6]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 384  | local3OutputDepth: 384
local4InputDepth: 384  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 108
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 216
Number of hidden parameters of conv2Biases: 6
Number of hidden parameters of local3: 147456
Number of hidden parameters of local3Biases: 384
Number of hidden parameters of local4: 24576
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 173464
Network summary:
conv1Shape: [3, 3, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 4, 16]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 1024  | local3OutputDepth: 1024
local4InputDepth: 1024  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 108
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 576
Number of hidden parameters of conv2Biases: 16
Number of hidden parameters of local3: 1048576
Number of hidden parameters of local3Biases: 1024
Number of hidden parameters of local4: 65536
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 1116554
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:32:23.927611: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 1024  | local3OutputDepth: 1024 (128, 1024)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 1024  | local3OutputDepth: 1024 (128, 1024)
2017-05-06 07:32:45.889949: step 0, loss = 5.06 (16.2 examples/sec; 7.923 sec/batch)
local3InputDepth: 1024  | local3OutputDepth: 1024 (128, 1024)
Evaluation results:
2017-05-06 07:32:54.009965: Total Predictions = 1024
2017-05-06 07:32:54.017839: Correct Predictions = 95
2017-05-06 07:32:54.024043: Wrong Predictions = 929
2017-05-06 07:32:54.030323: precision @ 1 = 0.093
2017-05-06 07:32:54.094247: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [3, 3, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [3, 3, 4, 8]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 512  | local3OutputDepth: 512
local4InputDepth: 512  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 108
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 288
Number of hidden parameters of conv2Biases: 8
Number of hidden parameters of local3: 262144
Number of hidden parameters of local3Biases: 512
Number of hidden parameters of local4: 32768
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 296546
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:33:01.625049: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 512  | local3OutputDepth: 512 (128, 512)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 512  | local3OutputDepth: 512 (128, 512)
2017-05-06 07:33:23.084358: step 0, loss = 3.03 (16.3 examples/sec; 7.849 sec/batch)
local3InputDepth: 512  | local3OutputDepth: 512 (128, 512)
Evaluation results:
2017-05-06 07:33:28.832604: Total Predictions = 1024
2017-05-06 07:33:28.852790: Correct Predictions = 110
2017-05-06 07:33:28.862862: Wrong Predictions = 914
2017-05-06 07:33:28.877477: precision @ 1 = 0.107
2017-05-06 07:33:28.939047: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 8]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 512  | local3OutputDepth: 512
local4InputDepth: 512  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 128
Number of hidden parameters of conv2Biases: 8
Number of hidden parameters of local3: 262144
Number of hidden parameters of local3Biases: 512
Number of hidden parameters of local4: 32768
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 296326
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:34:18.368913: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 512  | local3OutputDepth: 512 (128, 512)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 512  | local3OutputDepth: 512 (128, 512)
2017-05-06 07:34:39.488517: step 0, loss = 3.03 (15.9 examples/sec; 8.045 sec/batch)
local3InputDepth: 512  | local3OutputDepth: 512 (128, 512)
Evaluation results:
2017-05-06 07:34:45.116743: Total Predictions = 1024
2017-05-06 07:34:45.123632: Correct Predictions = 102
2017-05-06 07:34:45.130015: Wrong Predictions = 922
2017-05-06 07:34:45.136684: precision @ 1 = 0.100
2017-05-06 07:34:45.203918: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:35:02.806373: Running on server...
The experiment details:
max_steps = 10 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 640  | local3OutputDepth: 640 (128, 640)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 640  | local3OutputDepth: 640 (128, 640)
2017-05-06 07:35:25.953778: step 0, loss = 3.42 (15.0 examples/sec; 8.533 sec/batch)
local3InputDepth: 640  | local3OutputDepth: 640 (128, 640)
Evaluation results:
2017-05-06 07:35:31.825258: Total Predictions = 1024
2017-05-06 07:35:31.834623: Correct Predictions = 110
2017-05-06 07:35:31.844244: Wrong Predictions = 914
2017-05-06 07:35:31.855263: precision @ 1 = 0.107
2017-05-06 07:35:31.910195: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 07:36:16.559719: Running on server...
The experiment details:
max_steps = 4000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 640  | local3OutputDepth: 640 (128, 640)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
local3InputDepth: 640  | local3OutputDepth: 640 (128, 640)
2017-05-06 07:36:38.020791: step 0, loss = 3.42 (16.3 examples/sec; 7.838 sec/batch)
2017-05-06 07:36:50.364378: step 100, loss = 3.33 (2326.5 examples/sec; 0.055 sec/batch)
2017-05-06 07:37:01.486676: step 200, loss = 3.25 (2452.4 examples/sec; 0.052 sec/batch)
2017-05-06 07:37:12.617229: step 300, loss = 3.11 (2355.5 examples/sec; 0.054 sec/batch)
2017-05-06 07:37:23.756607: step 400, loss = 2.77 (2364.8 examples/sec; 0.054 sec/batch)
2017-05-06 07:37:34.923864: step 500, loss = 2.56 (2453.1 examples/sec; 0.052 sec/batch)
2017-05-06 07:37:46.072453: step 600, loss = 2.49 (2430.3 examples/sec; 0.053 sec/batch)
2017-05-06 07:37:57.158197: step 700, loss = 2.24 (2425.0 examples/sec; 0.053 sec/batch)
2017-05-06 07:38:08.237591: step 800, loss = 2.18 (2320.0 examples/sec; 0.055 sec/batch)
2017-05-06 07:38:19.353378: step 900, loss = 2.19 (2218.0 examples/sec; 0.058 sec/batch)
2017-05-06 07:38:30.471288: step 1000, loss = 2.08 (2383.4 examples/sec; 0.054 sec/batch)
2017-05-06 07:38:43.233239: step 1100, loss = 1.84 (2279.8 examples/sec; 0.056 sec/batch)
2017-05-06 07:38:54.365851: step 1200, loss = 1.86 (2483.6 examples/sec; 0.052 sec/batch)
2017-05-06 07:39:06.817261: step 1300, loss = 1.68 (2327.6 examples/sec; 0.055 sec/batch)
2017-05-06 07:39:20.007390: step 1400, loss = 1.98 (2347.9 examples/sec; 0.055 sec/batch)
2017-05-06 07:39:31.196121: step 1500, loss = 1.74 (2270.2 examples/sec; 0.056 sec/batch)
2017-05-06 07:39:42.372333: step 1600, loss = 1.82 (2332.9 examples/sec; 0.055 sec/batch)
2017-05-06 07:39:54.188438: step 1700, loss = 1.64 (2320.9 examples/sec; 0.055 sec/batch)
2017-05-06 07:40:05.396618: step 1800, loss = 1.59 (2298.7 examples/sec; 0.056 sec/batch)
2017-05-06 07:40:16.631801: step 1900, loss = 1.57 (2451.5 examples/sec; 0.052 sec/batch)
2017-05-06 07:40:27.782265: step 2000, loss = 1.76 (2508.9 examples/sec; 0.051 sec/batch)
2017-05-06 07:40:39.927714: step 2100, loss = 1.55 (2300.0 examples/sec; 0.056 sec/batch)
2017-05-06 07:40:51.110175: step 2200, loss = 1.41 (2238.7 examples/sec; 0.057 sec/batch)
2017-05-06 07:41:02.235215: step 2300, loss = 1.45 (2308.4 examples/sec; 0.055 sec/batch)
2017-05-06 07:41:13.362725: step 2400, loss = 1.36 (2455.9 examples/sec; 0.052 sec/batch)
2017-05-06 07:41:24.518605: step 2500, loss = 1.10 (2404.4 examples/sec; 0.053 sec/batch)
2017-05-06 07:41:35.667900: step 2600, loss = 1.39 (2227.2 examples/sec; 0.057 sec/batch)
2017-05-06 07:41:46.856220: step 2700, loss = 1.41 (2367.0 examples/sec; 0.054 sec/batch)
2017-05-06 07:41:58.075557: step 2800, loss = 1.42 (2294.0 examples/sec; 0.056 sec/batch)
2017-05-06 07:42:09.289064: step 2900, loss = 1.53 (2293.2 examples/sec; 0.056 sec/batch)
2017-05-06 07:42:20.454109: step 3000, loss = 1.10 (2450.0 examples/sec; 0.052 sec/batch)
2017-05-06 07:42:32.648030: step 3100, loss = 1.24 (2355.0 examples/sec; 0.054 sec/batch)
2017-05-06 07:42:43.866135: step 3200, loss = 1.16 (2278.9 examples/sec; 0.056 sec/batch)
2017-05-06 07:42:55.110855: step 3300, loss = 1.26 (2298.0 examples/sec; 0.056 sec/batch)
2017-05-06 07:43:06.325069: step 3400, loss = 1.11 (2397.6 examples/sec; 0.053 sec/batch)
2017-05-06 07:43:17.515225: step 3500, loss = 1.23 (2280.7 examples/sec; 0.056 sec/batch)
2017-05-06 07:43:28.688504: step 3600, loss = 1.11 (2457.1 examples/sec; 0.052 sec/batch)
2017-05-06 07:43:39.875295: step 3700, loss = 1.05 (2352.1 examples/sec; 0.054 sec/batch)
2017-05-06 07:43:51.051435: step 3800, loss = 1.07 (2274.9 examples/sec; 0.056 sec/batch)
2017-05-06 07:44:02.265056: step 3900, loss = 1.17 (2270.9 examples/sec; 0.056 sec/batch)
local3InputDepth: 640  | local3OutputDepth: 640 (128, 640)
Evaluation results:
2017-05-06 07:44:16.817533: Total Predictions = 1024
2017-05-06 07:44:16.826063: Correct Predictions = 706
2017-05-06 07:44:16.834331: Wrong Predictions = 318
2017-05-06 07:44:16.842618: precision @ 1 = 0.689
2017-05-06 07:44:16.912707: DONE
########################################################################################
########################################################################################
########################################################################################
Network summary:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 08:41:58.217594: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 08:42:53.954232: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 08:44:02.888455: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 08:44:50.815616: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 0
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 08:45:14.055959: step 0, loss = 3.56 (986.0 examples/sec; 0.130 sec/batch)
########################################################################################
########################################################################################
########################################################################################
2017-05-06 08:48:57.041925: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 0
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 08:49:06.644328: step 0, loss = 3.56 (1505.7 examples/sec; 0.085 sec/batch)
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 08:50:04.344082: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 08:50:29.005901: step 0, loss = 5.72 (16.3 examples/sec; 7.836 sec/batch)
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 08:57:47.611215: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 08:58:11.229943: step 0, loss = 5.72 (15.3 examples/sec; 8.364 sec/batch)
Evaluation results:
2017-05-06 08:58:19.923464: Total Predictions = 1024
2017-05-06 08:58:19.930865: Correct Predictions = 92
2017-05-06 08:58:19.937344: Wrong Predictions = 932
2017-05-06 08:58:19.943780: precision @ 1 = 0.090
2017-05-06 08:58:20.006295: DONE
########################################################################################
########################################################################################
########################################################################################
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 09:13:11.681892: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 0
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 09:16:14.099085: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 0
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 09:18:52.495199: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 0
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 09:38:45.208351: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 0
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 09:39:00.586114: step 0, loss = 3.56 (1162.5 examples/sec; 0.110 sec/batch)
Evaluation results:
2017-05-06 09:39:04.960147: Total Predictions = 1024
2017-05-06 09:39:04.969071: Correct Predictions = 188
2017-05-06 09:39:04.976431: Wrong Predictions = 836
2017-05-06 09:39:04.984731: precision @ 1 = 0.184
2017-05-06 09:39:05.054260: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 09:40:06.712222: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 09:40:28.638858: step 0, loss = 5.72 (15.5 examples/sec; 8.252 sec/batch)
Evaluation results:
2017-05-06 09:40:38.551648: Total Predictions = 1024
2017-05-06 09:40:38.560564: Correct Predictions = 100
2017-05-06 09:40:38.569193: Wrong Predictions = 924
2017-05-06 09:40:38.577031: precision @ 1 = 0.098
2017-05-06 09:40:38.639190: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:03:26.742229: Running on server...
The experiment details:
max_steps = 40 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:10:27.247437: Running on server...
The experiment details:
max_steps = 400 log_frequency = 100 num_gpus = 2
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:12:57.864763: Running on server...
The experiment details:
max_steps = 400 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 10:13:18.898883: step 0, loss = 5.72 (16.5 examples/sec; 7.758 sec/batch)
2017-05-06 10:13:31.038481: step 100, loss = 5.63 (2342.1 examples/sec; 0.055 sec/batch)
2017-05-06 10:13:41.788823: step 200, loss = 5.12 (2503.2 examples/sec; 0.051 sec/batch)
2017-05-06 10:13:52.520017: step 300, loss = 4.39 (2440.0 examples/sec; 0.052 sec/batch)
2017-05-06 10:14:05.730265: DONE
########################################################################################
########################################################################################
########################################################################################
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:14:37.154964: Running on server...
The experiment details:
max_steps = 400 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:14:39.545459: Running on server...
The experiment details:
max_steps = 400 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:15:37.995120: Running on server...
The experiment details:
max_steps = 400 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:15:51.278875: Running on server...
The experiment details:
max_steps = 400 log_frequency = 100 num_gpus = 2
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:17:07.426899: Running on server...
The experiment details:
max_steps = 400 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 10:17:32.075172: step 0, loss = 5.72 (15.9 examples/sec; 8.068 sec/batch)
2017-05-06 10:17:44.160718: step 100, loss = 5.63 (2323.8 examples/sec; 0.055 sec/batch)
2017-05-06 10:17:55.020917: step 200, loss = 5.27 (2312.5 examples/sec; 0.055 sec/batch)
2017-05-06 10:18:05.909581: step 300, loss = 4.33 (2379.5 examples/sec; 0.054 sec/batch)
Evaluation results:
2017-05-06 10:18:23.501901: Total Predictions = 10112
2017-05-06 10:18:23.509152: Correct Predictions = 4382
2017-05-06 10:18:23.516647: Wrong Predictions = 5730
2017-05-06 10:18:23.527513: precision @ 1 = 0.433
2017-05-06 10:18:23.600455: DONE
########################################################################################
########################################################################################
########################################################################################
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:22:39.103400: Running on server...
The experiment details:
max_steps = 10000 log_frequency = 100 num_gpus = 2
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:23:12.179061: Running on server...
The experiment details:
max_steps = 10000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 10:23:34.804127: step 0, loss = 5.72 (14.9 examples/sec; 8.567 sec/batch)
2017-05-06 10:23:48.139478: step 100, loss = 5.64 (2136.1 examples/sec; 0.060 sec/batch)
2017-05-06 10:23:59.885178: step 200, loss = 4.79 (2188.1 examples/sec; 0.058 sec/batch)
2017-05-06 10:24:11.667006: step 300, loss = 4.43 (2137.9 examples/sec; 0.060 sec/batch)
2017-05-06 10:24:23.483127: step 400, loss = 4.28 (2358.2 examples/sec; 0.054 sec/batch)
2017-05-06 10:24:35.314237: step 500, loss = 4.17 (2217.6 examples/sec; 0.058 sec/batch)
2017-05-06 10:24:47.012029: step 600, loss = 3.90 (2223.0 examples/sec; 0.058 sec/batch)
2017-05-06 10:24:58.764054: step 700, loss = 3.36 (2246.2 examples/sec; 0.057 sec/batch)
2017-05-06 10:25:10.809879: step 800, loss = 3.62 (2051.6 examples/sec; 0.062 sec/batch)
2017-05-06 10:25:22.716624: step 900, loss = 3.53 (2044.9 examples/sec; 0.063 sec/batch)
2017-05-06 10:25:34.462945: step 1000, loss = 3.58 (2424.2 examples/sec; 0.053 sec/batch)
2017-05-06 10:25:47.384786: step 1100, loss = 3.30 (2306.8 examples/sec; 0.055 sec/batch)
2017-05-06 10:25:58.914212: step 1200, loss = 3.01 (2368.8 examples/sec; 0.054 sec/batch)
2017-05-06 10:26:10.997030: step 1300, loss = 2.92 (2030.8 examples/sec; 0.063 sec/batch)
2017-05-06 10:26:23.923231: step 1400, loss = 2.77 (1989.1 examples/sec; 0.064 sec/batch)
2017-05-06 10:26:36.799411: step 1500, loss = 2.77 (2054.1 examples/sec; 0.062 sec/batch)
2017-05-06 10:26:49.575823: step 1600, loss = 2.35 (1940.5 examples/sec; 0.066 sec/batch)
2017-05-06 10:27:02.732675: step 1700, loss = 2.42 (2101.7 examples/sec; 0.061 sec/batch)
2017-05-06 10:27:15.965047: step 1800, loss = 2.50 (1941.1 examples/sec; 0.066 sec/batch)
2017-05-06 10:27:28.456641: step 1900, loss = 2.79 (2191.6 examples/sec; 0.058 sec/batch)
2017-05-06 10:27:40.209020: step 2000, loss = 2.63 (2036.8 examples/sec; 0.063 sec/batch)
2017-05-06 10:27:53.985132: step 2100, loss = 2.33 (2268.1 examples/sec; 0.056 sec/batch)
2017-05-06 10:28:06.029056: step 2200, loss = 2.70 (2348.9 examples/sec; 0.054 sec/batch)
2017-05-06 10:28:17.573586: step 2300, loss = 2.26 (2300.8 examples/sec; 0.056 sec/batch)
2017-05-06 10:28:29.020377: step 2400, loss = 2.66 (2218.1 examples/sec; 0.058 sec/batch)
2017-05-06 10:28:40.414813: step 2500, loss = 2.29 (2257.5 examples/sec; 0.057 sec/batch)
2017-05-06 10:28:51.670053: step 2600, loss = 2.13 (2299.6 examples/sec; 0.056 sec/batch)
2017-05-06 10:29:03.024539: step 2700, loss = 1.94 (2259.3 examples/sec; 0.057 sec/batch)
2017-05-06 10:29:14.507848: step 2800, loss = 2.32 (2210.9 examples/sec; 0.058 sec/batch)
2017-05-06 10:29:26.202175: step 2900, loss = 2.10 (2446.1 examples/sec; 0.052 sec/batch)
2017-05-06 10:29:37.547974: step 3000, loss = 2.09 (2320.9 examples/sec; 0.055 sec/batch)
2017-05-06 10:29:50.066135: step 3100, loss = 2.37 (2368.0 examples/sec; 0.054 sec/batch)
2017-05-06 10:30:01.316832: step 3200, loss = 2.03 (2330.3 examples/sec; 0.055 sec/batch)
2017-05-06 10:30:12.579522: step 3300, loss = 2.01 (2319.6 examples/sec; 0.055 sec/batch)
2017-05-06 10:30:23.956400: step 3400, loss = 2.03 (2248.2 examples/sec; 0.057 sec/batch)
2017-05-06 10:30:35.186229: step 3500, loss = 2.10 (2206.0 examples/sec; 0.058 sec/batch)
2017-05-06 10:30:46.490925: step 3600, loss = 1.95 (2389.6 examples/sec; 0.054 sec/batch)
2017-05-06 10:30:57.797074: step 3700, loss = 2.03 (2368.7 examples/sec; 0.054 sec/batch)
2017-05-06 10:31:09.102125: step 3800, loss = 2.38 (2260.8 examples/sec; 0.057 sec/batch)
2017-05-06 10:31:20.344946: step 3900, loss = 1.84 (2424.3 examples/sec; 0.053 sec/batch)
2017-05-06 10:31:31.580706: step 4000, loss = 1.79 (2315.7 examples/sec; 0.055 sec/batch)
2017-05-06 10:31:44.109220: step 4100, loss = 2.11 (2316.6 examples/sec; 0.055 sec/batch)
2017-05-06 10:31:55.300092: step 4200, loss = 1.92 (2164.4 examples/sec; 0.059 sec/batch)
2017-05-06 10:32:06.474418: step 4300, loss = 1.90 (2252.4 examples/sec; 0.057 sec/batch)
2017-05-06 10:32:17.672161: step 4400, loss = 1.91 (2251.2 examples/sec; 0.057 sec/batch)
2017-05-06 10:32:28.867229: step 4500, loss = 1.99 (2158.9 examples/sec; 0.059 sec/batch)
2017-05-06 10:32:40.015012: step 4600, loss = 1.94 (2335.1 examples/sec; 0.055 sec/batch)
2017-05-06 10:32:51.188273: step 4700, loss = 2.09 (2278.4 examples/sec; 0.056 sec/batch)
2017-05-06 10:33:02.409564: step 4800, loss = 1.97 (2292.9 examples/sec; 0.056 sec/batch)
2017-05-06 10:33:13.571375: step 4900, loss = 1.75 (2365.7 examples/sec; 0.054 sec/batch)
2017-05-06 10:33:24.756779: step 5000, loss = 1.83 (2312.6 examples/sec; 0.055 sec/batch)
2017-05-06 10:33:37.192161: step 5100, loss = 1.87 (2354.9 examples/sec; 0.054 sec/batch)
2017-05-06 10:33:48.340677: step 5200, loss = 1.74 (2410.6 examples/sec; 0.053 sec/batch)
2017-05-06 10:33:59.608125: step 5300, loss = 1.69 (2168.1 examples/sec; 0.059 sec/batch)
2017-05-06 10:34:10.888050: step 5400, loss = 1.61 (2403.2 examples/sec; 0.053 sec/batch)
2017-05-06 10:34:22.157067: step 5500, loss = 1.94 (2275.0 examples/sec; 0.056 sec/batch)
2017-05-06 10:34:33.363142: step 5600, loss = 1.81 (2326.0 examples/sec; 0.055 sec/batch)
2017-05-06 10:34:44.592390: step 5700, loss = 2.29 (2260.9 examples/sec; 0.057 sec/batch)
2017-05-06 10:34:55.884322: step 5800, loss = 1.75 (2291.8 examples/sec; 0.056 sec/batch)
2017-05-06 10:35:07.189837: step 5900, loss = 1.86 (2354.4 examples/sec; 0.054 sec/batch)
2017-05-06 10:35:18.471810: step 6000, loss = 2.07 (2282.7 examples/sec; 0.056 sec/batch)
2017-05-06 10:35:31.024544: step 6100, loss = 1.97 (2158.1 examples/sec; 0.059 sec/batch)
2017-05-06 10:35:42.385700: step 6200, loss = 1.92 (2192.9 examples/sec; 0.058 sec/batch)
2017-05-06 10:35:53.619697: step 6300, loss = 2.02 (2252.8 examples/sec; 0.057 sec/batch)
2017-05-06 10:36:04.918681: step 6400, loss = 2.03 (2278.6 examples/sec; 0.056 sec/batch)
2017-05-06 10:36:16.215106: step 6500, loss = 1.87 (2368.4 examples/sec; 0.054 sec/batch)
2017-05-06 10:36:27.510829: step 6600, loss = 1.59 (2357.9 examples/sec; 0.054 sec/batch)
2017-05-06 10:36:38.772875: step 6700, loss = 1.57 (2253.7 examples/sec; 0.057 sec/batch)
2017-05-06 10:36:50.044678: step 6800, loss = 2.25 (2280.8 examples/sec; 0.056 sec/batch)
2017-05-06 10:37:01.410298: step 6900, loss = 1.72 (2221.8 examples/sec; 0.058 sec/batch)
2017-05-06 10:37:12.744404: step 7000, loss = 1.78 (2316.5 examples/sec; 0.055 sec/batch)
2017-05-06 10:37:25.262172: step 7100, loss = 1.85 (2068.6 examples/sec; 0.062 sec/batch)
2017-05-06 10:37:36.580079: step 7200, loss = 1.76 (2172.4 examples/sec; 0.059 sec/batch)
2017-05-06 10:37:47.937238: step 7300, loss = 1.68 (2239.3 examples/sec; 0.057 sec/batch)
2017-05-06 10:37:59.281554: step 7400, loss = 1.74 (2436.0 examples/sec; 0.053 sec/batch)
2017-05-06 10:38:10.642797: step 7500, loss = 1.58 (2282.3 examples/sec; 0.056 sec/batch)
2017-05-06 10:38:21.946933: step 7600, loss = 1.51 (2362.9 examples/sec; 0.054 sec/batch)
2017-05-06 10:38:33.276380: step 7700, loss = 1.83 (2398.3 examples/sec; 0.053 sec/batch)
2017-05-06 10:38:44.616648: step 7800, loss = 1.60 (2114.7 examples/sec; 0.061 sec/batch)
2017-05-06 10:38:56.010480: step 7900, loss = 1.56 (2256.6 examples/sec; 0.057 sec/batch)
2017-05-06 10:39:07.356368: step 8000, loss = 1.97 (2202.3 examples/sec; 0.058 sec/batch)
2017-05-06 10:39:20.358503: step 8100, loss = 1.54 (2244.4 examples/sec; 0.057 sec/batch)
2017-05-06 10:39:31.965166: step 8200, loss = 1.93 (2236.5 examples/sec; 0.057 sec/batch)
2017-05-06 10:39:43.515604: step 8300, loss = 1.96 (2479.9 examples/sec; 0.052 sec/batch)
2017-05-06 10:39:55.140213: step 8400, loss = 1.82 (2257.6 examples/sec; 0.057 sec/batch)
2017-05-06 10:40:06.735355: step 8500, loss = 1.56 (2212.2 examples/sec; 0.058 sec/batch)
2017-05-06 10:40:18.413739: step 8600, loss = 1.89 (2247.7 examples/sec; 0.057 sec/batch)
2017-05-06 10:40:30.096727: step 8700, loss = 1.71 (2200.4 examples/sec; 0.058 sec/batch)
2017-05-06 10:40:41.835007: step 8800, loss = 1.91 (2244.4 examples/sec; 0.057 sec/batch)
2017-05-06 10:40:53.536696: step 8900, loss = 1.93 (2381.1 examples/sec; 0.054 sec/batch)
2017-05-06 10:41:05.137512: step 9000, loss = 2.10 (2247.6 examples/sec; 0.057 sec/batch)
2017-05-06 10:41:17.969151: step 9100, loss = 1.45 (2197.9 examples/sec; 0.058 sec/batch)
2017-05-06 10:41:29.632738: step 9200, loss = 2.08 (2276.9 examples/sec; 0.056 sec/batch)
2017-05-06 10:41:41.869739: step 9300, loss = 1.81 (1935.0 examples/sec; 0.066 sec/batch)
2017-05-06 10:41:55.079752: step 9400, loss = 1.48 (1993.4 examples/sec; 0.064 sec/batch)
2017-05-06 10:42:08.237413: step 9500, loss = 2.02 (1983.0 examples/sec; 0.065 sec/batch)
2017-05-06 10:42:21.436378: step 9600, loss = 1.74 (1927.5 examples/sec; 0.066 sec/batch)
2017-05-06 10:42:34.998608: step 9700, loss = 1.66 (2021.1 examples/sec; 0.063 sec/batch)
2017-05-06 10:42:48.110601: step 9800, loss = 2.01 (2028.2 examples/sec; 0.063 sec/batch)
2017-05-06 10:43:01.341310: step 9900, loss = 2.15 (1981.9 examples/sec; 0.065 sec/batch)
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:45:46.377585: Running on server...
The experiment details:
max_steps = 10000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 10:47:02.485169: Running on server...
The experiment details:
max_steps = 10000 log_frequency = 100 num_gpus = 2
2017-05-06 10:47:04.039076: DONE
########################################################################################
########################################################################################
########################################################################################
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:48:17.357492: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:48:22.193864: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:54:10.000109: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2

Successfully downloaded cifar-10-binary.tar.gz 170052171 bytes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 10:55:01.126034: step 0, loss = 5.72 (16.3 examples/sec; 7.858 sec/batch)
Evaluation results:
2017-05-06 10:55:19.933807: Total Predictions = 10112
2017-05-06 10:55:19.941395: Correct Predictions = 1381
2017-05-06 10:55:19.948395: Wrong Predictions = 8731
2017-05-06 10:55:19.955080: precision @ 1 = 0.137
2017-05-06 10:55:20.024331: DONE
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:56:35.436319: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:57:02.694050: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:57:46.246451: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 10:58:08.181773: step 0, loss = 5.72 (15.5 examples/sec; 8.278 sec/batch)
Evaluation results:
2017-05-06 10:58:27.581012: Total Predictions = 10112
2017-05-06 10:58:27.589516: Correct Predictions = 1152
2017-05-06 10:58:27.598642: Wrong Predictions = 8960
2017-05-06 10:58:27.606066: precision @ 1 = 0.114
2017-05-06 10:58:27.670321: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:58:27.738511: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 10:58:49.596033: step 0, loss = 5.72 (15.5 examples/sec; 8.235 sec/batch)
2017-05-06 10:59:03.509495: DONE
########################################################################################
########################################################################################
########################################################################################
2017-05-06 10:59:58.460801: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
Evaluation results:
2017-05-06 11:00:03.949548: Total Predictions = 10112
2017-05-06 11:00:03.958729: Correct Predictions = 1008
2017-05-06 11:00:03.966218: Wrong Predictions = 9104
2017-05-06 11:00:03.974437: precision @ 1 = 0.100
2017-05-06 11:00:04.038820: DONE
########################################################################################
########################################################################################
########################################################################################
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
########################################################################################
########################################################################################
########################################################################################
2017-05-06 11:04:24.996621: Running on server...
The experiment details:
max_steps = 1000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 11:04:49.649964: step 0, loss = 5.72 (15.4 examples/sec; 8.319 sec/batch)
2017-05-06 11:05:01.739694: step 100, loss = 5.63 (2391.7 examples/sec; 0.054 sec/batch)
2017-05-06 11:05:12.556814: step 200, loss = 4.74 (2392.4 examples/sec; 0.054 sec/batch)
2017-05-06 11:05:23.379784: step 300, loss = 4.40 (2311.9 examples/sec; 0.055 sec/batch)
2017-05-06 11:05:34.187436: step 400, loss = 4.18 (2383.2 examples/sec; 0.054 sec/batch)
2017-05-06 11:05:45.078030: step 500, loss = 4.32 (2279.9 examples/sec; 0.056 sec/batch)
2017-05-06 11:05:55.900601: step 600, loss = 4.13 (2369.8 examples/sec; 0.054 sec/batch)
2017-05-06 11:06:06.786774: step 700, loss = 3.19 (2090.0 examples/sec; 0.061 sec/batch)
2017-05-06 11:06:17.748715: step 800, loss = 3.40 (2359.5 examples/sec; 0.054 sec/batch)
2017-05-06 11:06:28.656236: step 900, loss = 3.31 (2398.5 examples/sec; 0.053 sec/batch)
Evaluation results:
2017-05-06 11:06:45.955059: Total Predictions = 10112
2017-05-06 11:06:45.961681: Correct Predictions = 5544
2017-05-06 11:06:45.969118: Wrong Predictions = 4568
2017-05-06 11:06:45.976810: precision @ 1 = 0.548
2017-05-06 11:06:46.063472: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 11:10:26.611843: Running on server...
The experiment details:
max_steps = 1000 log_frequency = 100 num_gpus = 2
Evaluation results:
2017-05-06 11:10:31.806294: Total Predictions = 10112
2017-05-06 11:10:31.814594: Correct Predictions = 5545
2017-05-06 11:10:31.822645: Wrong Predictions = 4567
2017-05-06 11:10:31.830522: precision @ 1 = 0.548
2017-05-06 11:10:31.894911: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 11:11:42.096409: Running on server...
The experiment details:
max_steps = 15000 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 11:12:03.407998: step 0, loss = 5.72 (15.8 examples/sec; 8.103 sec/batch)
2017-05-06 11:12:15.647536: step 100, loss = 5.62 (2493.8 examples/sec; 0.051 sec/batch)
2017-05-06 11:12:26.567917: step 200, loss = 4.88 (2468.5 examples/sec; 0.052 sec/batch)
2017-05-06 11:12:37.481831: step 300, loss = 4.22 (2368.2 examples/sec; 0.054 sec/batch)
2017-05-06 11:12:48.395451: step 400, loss = 4.21 (2494.0 examples/sec; 0.051 sec/batch)
2017-05-06 11:12:59.330326: step 500, loss = 3.79 (2435.7 examples/sec; 0.053 sec/batch)
2017-05-06 11:13:10.243357: step 600, loss = 4.00 (2387.0 examples/sec; 0.054 sec/batch)
2017-05-06 11:13:21.173649: step 700, loss = 3.82 (2384.1 examples/sec; 0.054 sec/batch)
2017-05-06 11:13:32.118813: step 800, loss = 3.78 (2363.7 examples/sec; 0.054 sec/batch)
2017-05-06 11:13:43.012659: step 900, loss = 3.60 (2366.1 examples/sec; 0.054 sec/batch)
2017-05-06 11:13:53.937309: step 1000, loss = 3.21 (2344.8 examples/sec; 0.055 sec/batch)
2017-05-06 11:14:06.225270: step 1100, loss = 3.39 (2425.7 examples/sec; 0.053 sec/batch)
2017-05-06 11:14:17.173157: step 1200, loss = 3.45 (2442.2 examples/sec; 0.052 sec/batch)
2017-05-06 11:14:28.109131: step 1300, loss = 3.42 (2478.3 examples/sec; 0.052 sec/batch)
2017-05-06 11:14:39.072173: step 1400, loss = 2.86 (2314.5 examples/sec; 0.055 sec/batch)
2017-05-06 11:14:50.023947: step 1500, loss = 3.03 (2311.9 examples/sec; 0.055 sec/batch)
2017-05-06 11:15:00.952594: step 1600, loss = 2.80 (2184.2 examples/sec; 0.059 sec/batch)
2017-05-06 11:15:11.917513: step 1700, loss = 3.39 (2418.1 examples/sec; 0.053 sec/batch)
2017-05-06 11:15:22.899673: step 1800, loss = 2.76 (2423.7 examples/sec; 0.053 sec/batch)
2017-05-06 11:15:33.904890: step 1900, loss = 2.91 (2418.6 examples/sec; 0.053 sec/batch)
2017-05-06 11:15:44.993104: step 2000, loss = 2.69 (2214.5 examples/sec; 0.058 sec/batch)
2017-05-06 11:15:57.271545: step 2100, loss = 2.42 (2124.0 examples/sec; 0.060 sec/batch)
2017-05-06 11:16:08.260832: step 2200, loss = 2.33 (2094.2 examples/sec; 0.061 sec/batch)
2017-05-06 11:16:19.256730: step 2300, loss = 2.74 (2285.8 examples/sec; 0.056 sec/batch)
2017-05-06 11:16:30.270933: step 2400, loss = 2.05 (2406.5 examples/sec; 0.053 sec/batch)
2017-05-06 11:16:41.299608: step 2500, loss = 2.51 (2334.7 examples/sec; 0.055 sec/batch)
2017-05-06 11:16:52.317211: step 2600, loss = 2.47 (2463.9 examples/sec; 0.052 sec/batch)
2017-05-06 11:17:03.332147: step 2700, loss = 2.65 (2362.4 examples/sec; 0.054 sec/batch)
2017-05-06 11:17:14.370923: step 2800, loss = 2.35 (2249.7 examples/sec; 0.057 sec/batch)
2017-05-06 11:17:25.399969: step 2900, loss = 2.45 (2197.5 examples/sec; 0.058 sec/batch)
2017-05-06 11:17:36.421519: step 3000, loss = 2.39 (2280.9 examples/sec; 0.056 sec/batch)
2017-05-06 11:17:48.645974: step 3100, loss = 1.59 (2406.0 examples/sec; 0.053 sec/batch)
2017-05-06 11:17:59.644815: step 3200, loss = 2.10 (2642.5 examples/sec; 0.048 sec/batch)
2017-05-06 11:18:10.724387: step 3300, loss = 2.21 (2335.6 examples/sec; 0.055 sec/batch)
2017-05-06 11:18:21.754336: step 3400, loss = 2.31 (2368.8 examples/sec; 0.054 sec/batch)
2017-05-06 11:18:32.842656: step 3500, loss = 2.19 (2237.8 examples/sec; 0.057 sec/batch)
2017-05-06 11:18:43.821740: step 3600, loss = 1.89 (2334.5 examples/sec; 0.055 sec/batch)
2017-05-06 11:18:54.875538: step 3700, loss = 2.32 (2407.8 examples/sec; 0.053 sec/batch)
2017-05-06 11:19:05.903502: step 3800, loss = 2.10 (2438.3 examples/sec; 0.052 sec/batch)
2017-05-06 11:19:16.981558: step 3900, loss = 1.57 (2190.7 examples/sec; 0.058 sec/batch)
2017-05-06 11:19:27.994666: step 4000, loss = 1.74 (2409.0 examples/sec; 0.053 sec/batch)
2017-05-06 11:19:40.279356: step 4100, loss = 2.01 (2296.4 examples/sec; 0.056 sec/batch)
2017-05-06 11:19:51.340279: step 4200, loss = 2.11 (2222.1 examples/sec; 0.058 sec/batch)
2017-05-06 11:20:02.420783: step 4300, loss = 2.10 (2392.9 examples/sec; 0.053 sec/batch)
2017-05-06 11:20:13.462879: step 4400, loss = 1.81 (2305.8 examples/sec; 0.056 sec/batch)
2017-05-06 11:20:24.579212: step 4500, loss = 2.14 (2363.8 examples/sec; 0.054 sec/batch)
2017-05-06 11:20:35.729573: step 4600, loss = 1.74 (2341.5 examples/sec; 0.055 sec/batch)
2017-05-06 11:20:46.936772: step 4700, loss = 1.96 (2338.0 examples/sec; 0.055 sec/batch)
Summary of Network 1:
conv1Shape: [4, 4, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 192
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452280
2017-05-06 11:20:58.104988: step 4800, loss = 1.90 (2461.7 examples/sec; 0.052 sec/batch)
2017-05-06 11:21:09.244039: step 4900, loss = 1.92 (2318.1 examples/sec; 0.055 sec/batch)
2017-05-06 11:21:20.382627: step 5000, loss = 1.68 (2127.3 examples/sec; 0.060 sec/batch)
2017-05-06 11:21:32.926217: step 5100, loss = 1.72 (2001.1 examples/sec; 0.064 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 5]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 5, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 375
Number of hidden parameters of conv1Biases: 5
Number of hidden parameters of conv2: 1250
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 453554
2017-05-06 11:21:44.047168: step 5200, loss = 1.76 (2476.6 examples/sec; 0.052 sec/batch)
2017-05-06 11:21:55.196899: step 5300, loss = 1.75 (2037.3 examples/sec; 0.063 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 5]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 5, 12]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 768  | local3OutputDepth: 768
local4InputDepth: 768  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 375
Number of hidden parameters of conv1Biases: 5
Number of hidden parameters of conv2: 1500
Number of hidden parameters of conv2Biases: 12
Number of hidden parameters of local3: 589824
Number of hidden parameters of local3Biases: 768
Number of hidden parameters of local4: 49152
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 642350
2017-05-06 11:22:06.340346: step 5400, loss = 1.97 (2355.2 examples/sec; 0.054 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 5]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 5, 11]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 704  | local3OutputDepth: 704
local4InputDepth: 704  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 375
Number of hidden parameters of conv1Biases: 5
Number of hidden parameters of conv2: 1375
Number of hidden parameters of conv2Biases: 11
Number of hidden parameters of local3: 495616
Number of hidden parameters of local3Biases: 704
Number of hidden parameters of local4: 45056
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 543856
2017-05-06 11:22:17.459090: step 5500, loss = 1.71 (2291.9 examples/sec; 0.056 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 5]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 5, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 375
Number of hidden parameters of conv1Biases: 5
Number of hidden parameters of conv2: 1250
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 453554
2017-05-06 11:22:28.572388: step 5600, loss = 1.89 (2359.1 examples/sec; 0.054 sec/batch)
2017-05-06 11:22:39.727554: step 5700, loss = 2.05 (2416.4 examples/sec; 0.053 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 5]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 5, 12]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 768  | local3OutputDepth: 768
local4InputDepth: 768  | local4OutputDepth: 32
softmax_linearInput: 32

Number of hidden parameters of conv1: 375
Number of hidden parameters of conv1Biases: 5
Number of hidden parameters of conv2: 1500
Number of hidden parameters of conv2Biases: 12
Number of hidden parameters of local3: 589824
Number of hidden parameters of local3Biases: 768
Number of hidden parameters of local4: 24576
Number of hidden parameters of local4Biases: 32
Number of hidden parameters of softmax: 320
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 617422
2017-05-06 11:22:51.031959: step 5800, loss = 1.83 (2246.6 examples/sec; 0.057 sec/batch)
2017-05-06 11:23:02.287814: step 5900, loss = 1.66 (2400.9 examples/sec; 0.053 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 32
softmax_linearInput: 32

Number of hidden parameters of conv1: 300
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 1000
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 20480
Number of hidden parameters of local4Biases: 32
Number of hidden parameters of softmax: 320
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 432396
2017-05-06 11:23:13.512171: step 6000, loss = 1.71 (2378.6 examples/sec; 0.054 sec/batch)
2017-05-06 11:23:26.041361: step 6100, loss = 2.26 (2284.2 examples/sec; 0.056 sec/batch)
2017-05-06 11:23:37.243510: step 6200, loss = 1.78 (2316.7 examples/sec; 0.055 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 6]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 6, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 32
softmax_linearInput: 32

Number of hidden parameters of conv1: 450
Number of hidden parameters of conv1Biases: 6
Number of hidden parameters of conv2: 1500
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 20480
Number of hidden parameters of local4Biases: 32
Number of hidden parameters of softmax: 320
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 433048
2017-05-06 11:23:48.426901: step 6300, loss = 1.62 (2414.7 examples/sec; 0.053 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 6]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 6, 12]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 768  | local3OutputDepth: 768
local4InputDepth: 768  | local4OutputDepth: 32
softmax_linearInput: 32

Number of hidden parameters of conv1: 450
Number of hidden parameters of conv1Biases: 6
Number of hidden parameters of conv2: 1800
Number of hidden parameters of conv2Biases: 12
Number of hidden parameters of local3: 589824
Number of hidden parameters of local3Biases: 768
Number of hidden parameters of local4: 24576
Number of hidden parameters of local4Biases: 32
Number of hidden parameters of softmax: 320
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 617798
2017-05-06 11:23:59.720884: step 6400, loss = 1.55 (2287.2 examples/sec; 0.056 sec/batch)
2017-05-06 11:24:10.985067: step 6500, loss = 1.48 (2304.1 examples/sec; 0.056 sec/batch)
2017-05-06 11:24:22.201963: step 6600, loss = 1.49 (2453.4 examples/sec; 0.052 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 6]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 6, 11]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 704  | local3OutputDepth: 704
local4InputDepth: 704  | local4OutputDepth: 32
softmax_linearInput: 32

Number of hidden parameters of conv1: 450
Number of hidden parameters of conv1Biases: 6
Number of hidden parameters of conv2: 1650
Number of hidden parameters of conv2Biases: 11
Number of hidden parameters of local3: 495616
Number of hidden parameters of local3Biases: 704
Number of hidden parameters of local4: 22528
Number of hidden parameters of local4Biases: 32
Number of hidden parameters of softmax: 320
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 521327
2017-05-06 11:24:33.462589: step 6700, loss = 1.83 (2134.2 examples/sec; 0.060 sec/batch)
2017-05-06 11:24:44.718923: step 6800, loss = 1.67 (2357.3 examples/sec; 0.054 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 6]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 6, 11]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 704  | local3OutputDepth: 704
local4InputDepth: 704  | local4OutputDepth: 32
softmax_linearInput: 32

Number of hidden parameters of conv1: 450
Number of hidden parameters of conv1Biases: 6
Number of hidden parameters of conv2: 1650
Number of hidden parameters of conv2Biases: 11
Number of hidden parameters of local3: 495616
Number of hidden parameters of local3Biases: 704
Number of hidden parameters of local4: 22528
Number of hidden parameters of local4Biases: 32
Number of hidden parameters of softmax: 320
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 521327
2017-05-06 11:24:55.959463: step 6900, loss = 1.98 (2323.4 examples/sec; 0.055 sec/batch)
2017-05-06 11:25:07.424936: step 7000, loss = 2.01 (2063.0 examples/sec; 0.062 sec/batch)
2017-05-06 11:25:22.480187: step 7100, loss = 1.87 (2100.0 examples/sec; 0.061 sec/batch)
2017-05-06 11:25:36.904371: step 7200, loss = 2.14 (1841.3 examples/sec; 0.070 sec/batch)
2017-05-06 11:25:51.156417: step 7300, loss = 1.24 (2164.2 examples/sec; 0.059 sec/batch)
2017-05-06 11:26:03.454267: step 7400, loss = 1.65 (1285.3 examples/sec; 0.100 sec/batch)
2017-05-06 11:26:14.882625: step 7500, loss = 1.56 (2413.6 examples/sec; 0.053 sec/batch)
2017-05-06 11:26:26.047970: step 7600, loss = 1.81 (2358.9 examples/sec; 0.054 sec/batch)
2017-05-06 11:26:37.155390: step 7700, loss = 1.54 (2409.4 examples/sec; 0.053 sec/batch)
2017-05-06 11:26:48.244779: step 7800, loss = 1.63 (2433.5 examples/sec; 0.053 sec/batch)
2017-05-06 11:26:59.454686: step 7900, loss = 1.92 (2315.2 examples/sec; 0.055 sec/batch)
2017-05-06 11:27:10.698878: step 8000, loss = 1.64 (2572.7 examples/sec; 0.050 sec/batch)
2017-05-06 11:27:23.164011: step 8100, loss = 1.37 (2268.4 examples/sec; 0.056 sec/batch)
2017-05-06 11:27:34.421342: step 8200, loss = 1.92 (2205.4 examples/sec; 0.058 sec/batch)
2017-05-06 11:27:45.671815: step 8300, loss = 1.48 (2232.7 examples/sec; 0.057 sec/batch)
2017-05-06 11:27:56.944288: step 8400, loss = 1.99 (2375.2 examples/sec; 0.054 sec/batch)
2017-05-06 11:28:08.237059: step 8500, loss = 1.82 (2350.8 examples/sec; 0.054 sec/batch)
2017-05-06 11:28:19.467697: step 8600, loss = 1.64 (2326.7 examples/sec; 0.055 sec/batch)
2017-05-06 11:28:30.730759: step 8700, loss = 1.73 (2267.7 examples/sec; 0.056 sec/batch)
2017-05-06 11:28:42.019488: step 8800, loss = 1.83 (2422.1 examples/sec; 0.053 sec/batch)
2017-05-06 11:28:53.270586: step 8900, loss = 2.20 (2379.9 examples/sec; 0.054 sec/batch)
2017-05-06 11:29:04.504637: step 9000, loss = 1.55 (2368.6 examples/sec; 0.054 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 6]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 6, 10]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 32
softmax_linearInput: 32

Number of hidden parameters of conv1: 450
Number of hidden parameters of conv1Biases: 6
Number of hidden parameters of conv2: 1500
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 20480
Number of hidden parameters of local4Biases: 32
Number of hidden parameters of softmax: 320
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 433048
2017-05-06 11:29:17.114763: step 9100, loss = 2.02 (2305.5 examples/sec; 0.056 sec/batch)
2017-05-06 11:29:28.232168: step 9200, loss = 1.94 (2580.0 examples/sec; 0.050 sec/batch)
2017-05-06 11:29:39.494541: step 9300, loss = 1.86 (2490.4 examples/sec; 0.051 sec/batch)
2017-05-06 11:29:50.758571: step 9400, loss = 1.71 (2370.5 examples/sec; 0.054 sec/batch)
2017-05-06 11:30:02.031920: step 9500, loss = 1.91 (2294.7 examples/sec; 0.056 sec/batch)
2017-05-06 11:30:13.210797: step 9600, loss = 1.63 (2268.5 examples/sec; 0.056 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 6]
pool1ksize: [1, 3, 3, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 6, 10]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 32
softmax_linearInput: 32

Number of hidden parameters of conv1: 450
Number of hidden parameters of conv1Biases: 6
Number of hidden parameters of conv2: 1500
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 20480
Number of hidden parameters of local4Biases: 32
Number of hidden parameters of softmax: 320
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 433048
2017-05-06 11:30:24.475507: step 9700, loss = 1.55 (2303.9 examples/sec; 0.056 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 6]
pool1ksize: [1, 3, 3, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 6, 10]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 450
Number of hidden parameters of conv1Biases: 6
Number of hidden parameters of conv2: 1500
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 453880
2017-05-06 11:30:35.740593: step 9800, loss = 1.99 (2385.5 examples/sec; 0.054 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 6]
pool1ksize: [1, 3, 3, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 6, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 450
Number of hidden parameters of conv1Biases: 6
Number of hidden parameters of conv2: 1500
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 453880
2017-05-06 11:30:47.046963: step 9900, loss = 1.74 (2011.9 examples/sec; 0.064 sec/batch)
2017-05-06 11:30:58.288355: step 10000, loss = 1.36 (2233.0 examples/sec; 0.057 sec/batch)
2017-05-06 11:31:10.908379: step 10100, loss = 1.69 (2257.7 examples/sec; 0.057 sec/batch)
2017-05-06 11:31:22.149532: step 10200, loss = 1.66 (2201.4 examples/sec; 0.058 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 6]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 6, 12]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 768  | local3OutputDepth: 768
local4InputDepth: 768  | local4OutputDepth: 16
softmax_linearInput: 16

Number of hidden parameters of conv1: 450
Number of hidden parameters of conv1Biases: 6
Number of hidden parameters of conv2: 1800
Number of hidden parameters of conv2Biases: 12
Number of hidden parameters of local3: 589824
Number of hidden parameters of local3Biases: 768
Number of hidden parameters of local4: 12288
Number of hidden parameters of local4Biases: 16
Number of hidden parameters of softmax: 160
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 605334
2017-05-06 11:31:33.422551: step 10300, loss = 1.63 (2246.8 examples/sec; 0.057 sec/batch)
2017-05-06 11:31:44.660101: step 10400, loss = 1.78 (2339.6 examples/sec; 0.055 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 4]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 4, 12]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 768  | local3OutputDepth: 768
local4InputDepth: 768  | local4OutputDepth: 16
softmax_linearInput: 16

Number of hidden parameters of conv1: 300
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 1200
Number of hidden parameters of conv2Biases: 12
Number of hidden parameters of local3: 589824
Number of hidden parameters of local3Biases: 768
Number of hidden parameters of local4: 12288
Number of hidden parameters of local4Biases: 16
Number of hidden parameters of softmax: 160
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 604582
Summary of Network 1:
conv1Shape: [5, 5, 3, 2]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 2, 12]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 768  | local3OutputDepth: 768
local4InputDepth: 768  | local4OutputDepth: 16
softmax_linearInput: 16

Number of hidden parameters of conv1: 150
Number of hidden parameters of conv1Biases: 2
Number of hidden parameters of conv2: 600
Number of hidden parameters of conv2Biases: 12
Number of hidden parameters of local3: 589824
Number of hidden parameters of local3Biases: 768
Number of hidden parameters of local4: 12288
Number of hidden parameters of local4Biases: 16
Number of hidden parameters of softmax: 160
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 603830
2017-05-06 11:31:55.970747: step 10500, loss = 1.76 (2024.1 examples/sec; 0.063 sec/batch)
2017-05-06 11:32:07.219740: step 10600, loss = 1.46 (2361.2 examples/sec; 0.054 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 2]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 2, 12]
pool2ksize: [1, 7, 7, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 768  | local3OutputDepth: 768
local4InputDepth: 768  | local4OutputDepth: 16
softmax_linearInput: 16

Number of hidden parameters of conv1: 150
Number of hidden parameters of conv1Biases: 2
Number of hidden parameters of conv2: 600
Number of hidden parameters of conv2Biases: 12
Number of hidden parameters of local3: 589824
Number of hidden parameters of local3Biases: 768
Number of hidden parameters of local4: 12288
Number of hidden parameters of local4Biases: 16
Number of hidden parameters of softmax: 160
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 603830
2017-05-06 11:32:18.494326: step 10700, loss = 1.62 (2453.0 examples/sec; 0.052 sec/batch)
2017-05-06 11:32:29.749217: step 10800, loss = 1.53 (2246.1 examples/sec; 0.057 sec/batch)
2017-05-06 11:32:41.010494: step 10900, loss = 1.50 (2224.0 examples/sec; 0.058 sec/batch)
Summary of Network 1:
conv1Shape: [5, 5, 3, 8]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 8, 10]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 16
softmax_linearInput: 16

Number of hidden parameters of conv1: 600
Number of hidden parameters of conv1Biases: 8
Number of hidden parameters of conv2: 2000
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 10240
Number of hidden parameters of local4Biases: 16
Number of hidden parameters of softmax: 160
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 423284
2017-05-06 11:32:52.306910: step 11000, loss = 1.64 (2428.8 examples/sec; 0.053 sec/batch)
2017-05-06 11:33:04.864229: step 11100, loss = 1.57 (2199.1 examples/sec; 0.058 sec/batch)
2017-05-06 11:33:16.176608: step 11200, loss = 1.69 (2312.7 examples/sec; 0.055 sec/batch)
2017-05-06 11:33:27.322474: step 11300, loss = 1.59 (2040.3 examples/sec; 0.063 sec/batch)
2017-05-06 11:33:38.565278: step 11400, loss = 1.48 (2329.6 examples/sec; 0.055 sec/batch)
2017-05-06 11:33:49.862310: step 11500, loss = 1.74 (2315.1 examples/sec; 0.055 sec/batch)
2017-05-06 11:34:01.180982: step 11600, loss = 1.50 (2434.1 examples/sec; 0.053 sec/batch)
2017-05-06 11:34:12.507859: step 11700, loss = 1.65 (2286.7 examples/sec; 0.056 sec/batch)
2017-05-06 11:34:23.834529: step 11800, loss = 1.34 (2240.2 examples/sec; 0.057 sec/batch)
2017-05-06 11:34:35.140796: step 11900, loss = 1.83 (2338.3 examples/sec; 0.055 sec/batch)
2017-05-06 11:34:46.510894: step 12000, loss = 1.73 (1958.8 examples/sec; 0.065 sec/batch)
2017-05-06 11:34:59.173209: step 12100, loss = 1.48 (2224.2 examples/sec; 0.058 sec/batch)
2017-05-06 11:35:10.501982: step 12200, loss = 1.49 (2388.9 examples/sec; 0.054 sec/batch)
2017-05-06 11:35:21.837428: step 12300, loss = 1.55 (2280.5 examples/sec; 0.056 sec/batch)
2017-05-06 11:35:33.182265: step 12400, loss = 1.73 (2031.0 examples/sec; 0.063 sec/batch)
2017-05-06 11:35:44.536733: step 12500, loss = 1.78 (2180.7 examples/sec; 0.059 sec/batch)
2017-05-06 11:35:55.932820: step 12600, loss = 1.68 (2322.0 examples/sec; 0.055 sec/batch)
2017-05-06 11:36:07.276025: step 12700, loss = 1.83 (2211.2 examples/sec; 0.058 sec/batch)
2017-05-06 11:36:18.585678: step 12800, loss = 1.70 (2284.5 examples/sec; 0.056 sec/batch)
2017-05-06 11:36:29.942189: step 12900, loss = 1.45 (2086.9 examples/sec; 0.061 sec/batch)
2017-05-06 11:36:41.302181: step 13000, loss = 1.52 (2388.8 examples/sec; 0.054 sec/batch)
2017-05-06 11:36:53.969401: step 13100, loss = 1.55 (2285.4 examples/sec; 0.056 sec/batch)
2017-05-06 11:37:05.325023: step 13200, loss = 1.63 (2280.0 examples/sec; 0.056 sec/batch)
2017-05-06 11:37:16.672731: step 13300, loss = 1.50 (2078.1 examples/sec; 0.062 sec/batch)
2017-05-06 11:37:28.077146: step 13400, loss = 1.42 (2278.9 examples/sec; 0.056 sec/batch)
2017-05-06 11:37:39.461381: step 13500, loss = 1.66 (2129.9 examples/sec; 0.060 sec/batch)
2017-05-06 11:37:50.813651: step 13600, loss = 1.57 (2217.7 examples/sec; 0.058 sec/batch)
2017-05-06 11:38:02.156377: step 13700, loss = 1.63 (2286.1 examples/sec; 0.056 sec/batch)
2017-05-06 11:38:13.531912: step 13800, loss = 1.58 (2194.7 examples/sec; 0.058 sec/batch)
2017-05-06 11:38:24.913519: step 13900, loss = 1.61 (2375.1 examples/sec; 0.054 sec/batch)
2017-05-06 11:38:36.285691: step 14000, loss = 1.50 (2264.7 examples/sec; 0.057 sec/batch)
2017-05-06 11:38:49.115098: step 14100, loss = 1.79 (2434.0 examples/sec; 0.053 sec/batch)
2017-05-06 11:39:00.448404: step 14200, loss = 1.56 (2255.9 examples/sec; 0.057 sec/batch)
2017-05-06 11:39:11.852896: step 14300, loss = 1.96 (2195.1 examples/sec; 0.058 sec/batch)
2017-05-06 11:39:23.271685: step 14400, loss = 1.62 (2291.0 examples/sec; 0.056 sec/batch)
2017-05-06 11:39:34.650600: step 14500, loss = 1.89 (2091.6 examples/sec; 0.061 sec/batch)
2017-05-06 11:39:46.007383: step 14600, loss = 1.34 (2393.6 examples/sec; 0.053 sec/batch)
2017-05-06 11:39:57.436240: step 14700, loss = 1.54 (2320.7 examples/sec; 0.055 sec/batch)
2017-05-06 11:40:08.788409: step 14800, loss = 1.90 (2312.4 examples/sec; 0.055 sec/batch)
2017-05-06 11:40:20.220081: step 14900, loss = 1.75 (2334.4 examples/sec; 0.055 sec/batch)
Evaluation results:
2017-05-06 11:40:38.253048: Total Predictions = 10112
2017-05-06 11:40:38.260270: Correct Predictions = 6705
2017-05-06 11:40:38.268610: Wrong Predictions = 3407
2017-05-06 11:40:38.275789: precision @ 1 = 0.663
2017-05-06 11:40:38.341099: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 11:50:13.041539: Running on server...
The experiment details:
max_steps = 15000 log_frequency = 100 num_gpus = 2
Evaluation results:
2017-05-06 11:50:18.362908: Total Predictions = 10112
2017-05-06 11:50:18.370946: Correct Predictions = 6705
2017-05-06 11:50:18.379221: Wrong Predictions = 3407
2017-05-06 11:50:18.387966: precision @ 1 = 0.663
2017-05-06 11:50:18.456702: DONE
########################################################################################
########################################################################################
########################################################################################
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
Summary of Network 1:
conv1Shape: [2, 2, 3, 4]
pool1ksize: [1, 2, 2, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [2, 2, 4, 10]
pool2ksize: [1, 2, 2, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 64
softmax_linearInput: 64

Number of hidden parameters of conv1: 48
Number of hidden parameters of conv1Biases: 4
Number of hidden parameters of conv2: 160
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 40960
Number of hidden parameters of local4Biases: 64
Number of hidden parameters of softmax: 640
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 452136
Summary of Network 1:
conv1Shape: [5, 5, 3, 8]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 8, 10]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 16
softmax_linearInput: 16

Number of hidden parameters of conv1: 600
Number of hidden parameters of conv1Biases: 8
Number of hidden parameters of conv2: 2000
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 10240
Number of hidden parameters of local4Biases: 16
Number of hidden parameters of softmax: 160
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 423284
Summary of Network 1:
conv1Shape: [5, 5, 3, 8]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 8, 10]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 16
softmax_linearInput: 16

Number of hidden parameters of conv1: 600
Number of hidden parameters of conv1Biases: 8
Number of hidden parameters of conv2: 2000
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 10240
Number of hidden parameters of local4Biases: 16
Number of hidden parameters of softmax: 160
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 423284
########################################################################################
########################################################################################
########################################################################################
2017-05-06 12:28:39.121950: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Summary of Network 1:
conv1Shape: [5, 5, 3, 8]
pool1ksize: [1, 4, 4, 1]  | pool1strides: [1, 2, 2, 1]  | pool1padding: SAME
conv2Shape: [5, 5, 8, 10]
pool2ksize: [1, 3, 3, 1]  | pool2strides: [1, 2, 2, 1]  | pool2padding: SAME
local3InputDepth: 640  | local3OutputDepth: 640
local4InputDepth: 640  | local4OutputDepth: 16
softmax_linearInput: 16

Number of hidden parameters of conv1: 600
Number of hidden parameters of conv1Biases: 8
Number of hidden parameters of conv2: 2000
Number of hidden parameters of conv2Biases: 10
Number of hidden parameters of local3: 409600
Number of hidden parameters of local3Biases: 640
Number of hidden parameters of local4: 10240
Number of hidden parameters of local4Biases: 16
Number of hidden parameters of softmax: 160
Number of hidden parameters of softmaxBiases: 10
Total number of hidden parameters: 423284
########################################################################################
########################################################################################
########################################################################################
2017-05-06 12:32:38.181842: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 12:33:02.958534: step 0, loss = 5.64 (15.5 examples/sec; 8.245 sec/batch)
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Evaluation results:
2017-05-06 12:33:43.425917: Total Predictions = 10112
2017-05-06 12:33:43.434316: Correct Predictions = 2567
2017-05-06 12:33:43.441462: Wrong Predictions = 7545
2017-05-06 12:33:43.448371: precision @ 1 = 0.254
2017-05-06 12:33:43.646723: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 12:36:27.237204: Running on server...
The experiment details:
max_steps = 100 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Evaluation results:
2017-05-06 12:36:53.291183: Total Predictions = 10112
2017-05-06 12:36:53.300647: Correct Predictions = 2604
2017-05-06 12:36:53.310898: Wrong Predictions = 7508
2017-05-06 12:36:53.319626: precision @ 1 = 0.258
2017-05-06 12:36:53.517710: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 12:48:06.414714: Running on server...
The experiment details:
network = 1 max_steps = 30000 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-06 13:05:53.445453: Running on server...
The experiment details:
network = 1 max_steps = 30000 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-06 13:09:09.304815: Running on server...
The experiment details:
network = 1 max_steps = 30000 log_frequency = 100 num_gpus = 2
2017-05-06 13:09:10.001502: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-06 13:12:55.677389: Running on server...
The experiment details:
network = 1 max_steps = 30000 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-06 13:13:40.332596: Running on server...
The experiment details:
network = 1 max_steps = 30000 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-06 13:16:16.579241: Running on server...
The experiment details:
network = 1 max_steps = 100 log_frequency = 100 num_gpus = 2
########################################################################################
########################################################################################
########################################################################################
2017-05-06 13:17:05.862358: Running on server...
The experiment details:
network = 1 max_steps = 100 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-06 13:17:27.078381: step 0, loss = 5.72 (16.7 examples/sec; 7.685 sec/batch)
Evaluation results:
2017-05-06 13:17:48.124538: Total Predictions = 10112
2017-05-06 13:17:48.131970: Correct Predictions = 1121
2017-05-06 13:17:48.139130: Wrong Predictions = 8991
2017-05-06 13:17:48.147244: precision @ 1 = 0.111
2017-05-06 13:17:48.233311: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-18 01:59:50.694028: Running on UCSC:citrisdense...
The experiment details:
network = 1 max_steps = 400 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-18 02:04:51.045728: Running on UCSC:citrisdense...
The experiment details:
network = 1 max_steps = 400 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
########################################################################################
########################################################################################
########################################################################################
2017-05-18 02:06:06.056712: Running on UCSC:citrisdense...
The experiment details:
network = 1 max_steps = 400 log_frequency = 100 num_gpus = 2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-05-18 02:06:32.361476: step 0, loss = 5.72 (14.5 examples/sec; 8.808 sec/batch)
2017-05-18 02:06:44.595786: step 100, loss = 5.64 (2388.5 examples/sec; 0.054 sec/batch)
2017-05-18 02:06:55.538897: step 200, loss = 5.20 (2499.9 examples/sec; 0.051 sec/batch)
2017-05-18 02:07:06.442470: step 300, loss = 4.74 (2395.1 examples/sec; 0.053 sec/batch)
Evaluation results:
2017-05-18 02:07:21.309524: Total Predictions = 1024
2017-05-18 02:07:21.317232: Correct Predictions = 124
2017-05-18 02:07:21.324630: Wrong Predictions = 900
2017-05-18 02:07:21.333994: precision @ 1 = 0.121
2017-05-18 02:07:21.642897: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-27 23:28:30.312858: Running on MSI...
########################################################################################
########################################################################################
########################################################################################
2017-05-27 23:29:10.949356: Running on MSI...
########################################################################################
########################################################################################
########################################################################################
2017-05-27 23:30:47.880930: Running on MSI...
########################################################################################
########################################################################################
########################################################################################
2017-05-27 23:36:56.685919: Running on MSI...
########################################################################################
########################################################################################
########################################################################################
2017-05-27 23:39:19.089753: Running on MSI...
########################################################################################
########################################################################################
########################################################################################
2017-05-27 23:39:51.082513: Running on MSI...
########################################################################################
########################################################################################
########################################################################################
2017-05-27 23:40:20.555021: Running on MSI...
Epoch: 1 Learning rate: 1.000
0.004 perplexity: 5728.078 speed: 5866 wps
0.104 perplexity: 852.251 speed: 11826 wps
########################################################################################
########################################################################################
########################################################################################
2017-05-27 13:49:33.318676: Running on UCSC:citrisdense...
Epoch: 1 Learning rate: 1.000
0.004 perplexity: 5503.288 speed: 3803 wps
0.104 perplexity: 838.582 speed: 8659 wps
########################################################################################
########################################################################################
########################################################################################
2017-05-27 13:51:49.955712: Running on UCSC:citrisdense...
Epoch: 1 Learning rate: 1.000
0.004 perplexity: 5363.747 speed: 5049 wps
0.104 perplexity: 829.547 speed: 8681 wps
0.204 perplexity: 619.735 speed: 8851 wps
0.304 perplexity: 502.695 speed: 8894 wps
0.404 perplexity: 434.809 speed: 8972 wps
0.504 perplexity: 390.058 speed: 8980 wps
0.604 perplexity: 351.503 speed: 8995 wps
0.703 perplexity: 325.113 speed: 9009 wps
0.803 perplexity: 304.009 speed: 9015 wps
0.903 perplexity: 284.650 speed: 9011 wps
Epoch: 1 Train Perplexity: 270.147
Epoch: 1 Valid Perplexity: 180.951
Epoch: 2 Learning rate: 1.000
0.004 perplexity: 215.232 speed: 8673 wps
0.104 perplexity: 151.138 speed: 9052 wps
0.204 perplexity: 158.347 speed: 9049 wps
0.304 perplexity: 153.429 speed: 9075 wps
0.404 perplexity: 150.500 speed: 9066 wps
0.504 perplexity: 148.092 speed: 9057 wps
0.604 perplexity: 143.459 speed: 9054 wps
0.703 perplexity: 141.293 speed: 9064 wps
0.803 perplexity: 139.303 speed: 9065 wps
0.903 perplexity: 135.654 speed: 9068 wps
Epoch: 2 Train Perplexity: 133.605
Epoch: 2 Valid Perplexity: 144.421
Epoch: 3 Learning rate: 1.000
0.004 perplexity: 146.811 speed: 9037 wps
0.104 perplexity: 104.901 speed: 9174 wps
0.204 perplexity: 114.117 speed: 9147 wps
0.304 perplexity: 111.392 speed: 9152 wps
0.404 perplexity: 110.443 speed: 9157 wps
0.504 perplexity: 109.657 speed: 9137 wps
0.604 perplexity: 107.104 speed: 9120 wps
0.703 perplexity: 106.469 speed: 9104 wps
0.803 perplexity: 105.832 speed: 9102 wps
0.903 perplexity: 103.590 speed: 9102 wps
Epoch: 3 Train Perplexity: 102.659
Epoch: 3 Valid Perplexity: 132.945
Epoch: 4 Learning rate: 1.000
0.004 perplexity: 115.831 speed: 9006 wps
0.104 perplexity: 84.987 speed: 8990 wps
0.204 perplexity: 93.663 speed: 9039 wps
0.304 perplexity: 91.546 speed: 9070 wps
0.404 perplexity: 91.079 speed: 9073 wps
0.504 perplexity: 90.718 speed: 9079 wps
0.604 perplexity: 88.938 speed: 9092 wps
0.703 perplexity: 88.771 speed: 9092 wps
0.803 perplexity: 88.503 speed: 9088 wps
0.903 perplexity: 86.872 speed: 9086 wps
Epoch: 4 Train Perplexity: 86.340
Epoch: 4 Valid Perplexity: 128.697
Epoch: 5 Learning rate: 0.500
0.004 perplexity: 99.755 speed: 8833 wps
0.104 perplexity: 71.262 speed: 9058 wps
0.204 perplexity: 77.369 speed: 9076 wps
0.304 perplexity: 74.561 speed: 9052 wps
0.404 perplexity: 73.493 speed: 9043 wps
0.504 perplexity: 72.581 speed: 9054 wps
0.604 perplexity: 70.481 speed: 9053 wps
0.703 perplexity: 69.723 speed: 9071 wps
0.803 perplexity: 68.897 speed: 9062 wps
0.903 perplexity: 67.017 speed: 9066 wps
Epoch: 5 Train Perplexity: 66.031
Epoch: 5 Valid Perplexity: 119.970
Epoch: 6 Learning rate: 0.250
0.004 perplexity: 81.798 speed: 9358 wps
0.104 perplexity: 58.748 speed: 8922 wps
0.204 perplexity: 64.080 speed: 8982 wps
0.304 perplexity: 61.629 speed: 8991 wps
0.404 perplexity: 60.671 speed: 8991 wps
0.504 perplexity: 59.825 speed: 9000 wps
0.604 perplexity: 57.981 speed: 8998 wps
0.703 perplexity: 57.255 speed: 9000 wps
0.803 perplexity: 56.444 speed: 8998 wps
0.903 perplexity: 54.736 speed: 9008 wps
Epoch: 6 Train Perplexity: 53.773
Epoch: 6 Valid Perplexity: 119.478
Epoch: 7 Learning rate: 0.125
0.004 perplexity: 72.464 speed: 9118 wps
0.104 perplexity: 52.191 speed: 9012 wps
0.204 perplexity: 57.000 speed: 9105 wps
0.304 perplexity: 54.785 speed: 9087 wps
0.404 perplexity: 53.912 speed: 9096 wps
0.504 perplexity: 53.114 speed: 9098 wps
0.604 perplexity: 51.449 speed: 9083 wps
0.703 perplexity: 50.756 speed: 9091 wps
0.803 perplexity: 49.972 speed: 9077 wps
0.903 perplexity: 48.386 speed: 9069 wps
Epoch: 7 Train Perplexity: 47.465
Epoch: 7 Valid Perplexity: 120.416
Epoch: 8 Learning rate: 0.062
0.004 perplexity: 67.817 speed: 9020 wps
0.104 perplexity: 48.815 speed: 8916 wps
0.204 perplexity: 53.381 speed: 9008 wps
0.304 perplexity: 51.296 speed: 9049 wps
0.404 perplexity: 50.481 speed: 9075 wps
0.504 perplexity: 49.715 speed: 9070 wps
0.604 perplexity: 48.137 speed: 9074 wps
0.703 perplexity: 47.457 speed: 9070 wps
0.803 perplexity: 46.687 speed: 9064 wps
0.903 perplexity: 45.167 speed: 9103 wps
Epoch: 8 Train Perplexity: 44.271
Epoch: 8 Valid Perplexity: 121.109
Epoch: 9 Learning rate: 0.031
0.004 perplexity: 65.377 speed: 9239 wps
0.104 perplexity: 47.016 speed: 9042 wps
0.204 perplexity: 51.482 speed: 9043 wps
0.304 perplexity: 49.461 speed: 9041 wps
0.404 perplexity: 48.677 speed: 9083 wps
0.504 perplexity: 47.934 speed: 9091 wps
0.604 perplexity: 46.401 speed: 9092 wps
0.703 perplexity: 45.733 speed: 9090 wps
0.803 perplexity: 44.971 speed: 9092 wps
0.903 perplexity: 43.478 speed: 9090 wps
Epoch: 9 Train Perplexity: 42.597
Epoch: 9 Valid Perplexity: 121.323
Epoch: 10 Learning rate: 0.016
0.004 perplexity: 64.007 speed: 8883 wps
0.104 perplexity: 46.029 speed: 9076 wps
0.204 perplexity: 50.451 speed: 9112 wps
0.304 perplexity: 48.465 speed: 9115 wps
0.404 perplexity: 47.691 speed: 9087 wps
0.504 perplexity: 46.957 speed: 9085 wps
0.604 perplexity: 45.446 speed: 9086 wps
0.703 perplexity: 44.786 speed: 9092 wps
0.803 perplexity: 44.033 speed: 9085 wps
0.903 perplexity: 42.554 speed: 9094 wps
Epoch: 10 Train Perplexity: 41.681
Epoch: 10 Valid Perplexity: 121.069
Epoch: 11 Learning rate: 0.008
0.004 perplexity: 63.270 speed: 9058 wps
0.104 perplexity: 45.464 speed: 8955 wps
0.204 perplexity: 49.865 speed: 9048 wps
0.304 perplexity: 47.904 speed: 9058 wps
0.404 perplexity: 47.138 speed: 9045 wps
0.504 perplexity: 46.413 speed: 9043 wps
0.604 perplexity: 44.914 speed: 9049 wps
0.703 perplexity: 44.257 speed: 9033 wps
0.803 perplexity: 43.511 speed: 9042 wps
0.903 perplexity: 42.044 speed: 9044 wps
Epoch: 11 Train Perplexity: 41.176
Epoch: 11 Valid Perplexity: 120.615
Epoch: 12 Learning rate: 0.004
0.004 perplexity: 62.825 speed: 9344 wps
0.104 perplexity: 45.127 speed: 9089 wps
0.204 perplexity: 49.516 speed: 9052 wps
0.304 perplexity: 47.577 speed: 9057 wps
0.404 perplexity: 46.822 speed: 9102 wps
0.504 perplexity: 46.105 speed: 9105 wps
0.604 perplexity: 44.616 speed: 9115 wps
0.703 perplexity: 43.963 speed: 9113 wps
0.803 perplexity: 43.221 speed: 9126 wps
0.903 perplexity: 41.762 speed: 9120 wps
Epoch: 12 Train Perplexity: 40.899
Epoch: 12 Valid Perplexity: 120.236
Epoch: 13 Learning rate: 0.002
0.004 perplexity: 62.547 speed: 9115 wps
0.104 perplexity: 44.929 speed: 9011 wps
0.204 perplexity: 49.312 speed: 9048 wps
0.304 perplexity: 47.389 speed: 9036 wps
0.404 perplexity: 46.643 speed: 9076 wps
0.504 perplexity: 45.934 speed: 9124 wps
0.604 perplexity: 44.452 speed: 9139 wps
0.703 perplexity: 43.803 speed: 9134 wps
0.803 perplexity: 43.064 speed: 9169 wps
0.903 perplexity: 41.610 speed: 9174 wps
Epoch: 13 Train Perplexity: 40.750
Epoch: 13 Valid Perplexity: 120.019
Test Perplexity: 114.096
2017-05-27 14:17:08.520197: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-27 15:02:49.766511: Running on UCSC:citrisdense...
########################################################################################
########################################################################################
########################################################################################
2017-05-27 15:08:20.415600: Running on UCSC:citrisdense...
########################################################################################
########################################################################################
########################################################################################
2017-05-27 15:12:03.393815: Running on UCSC:citrisdense...
########################################################################################
########################################################################################
########################################################################################
2017-05-27 15:18:25.023333: Running on UCSC:citrisdense...
########################################################################################
########################################################################################
########################################################################################
2017-05-27 15:24:26.373821: Running on UCSC:citrisdense...
########################################################################################
########################################################################################
########################################################################################
2017-05-27 15:25:38.697510: Running on UCSC:citrisdense...
Distinct terms: 10000
########################################################################################
########################################################################################
########################################################################################
2017-05-27 15:29:22.506239: Running on UCSC:citrisdense...
Distinct terms: 10000
Seed: make america
Sample: weil injured perception demand joan unwelcome recover prepaid arrest doubtful waves pentagon sport dillon procedural
Epoch: 1 Learning rate: 1.000
0.004 perplexity: 9393.383 speed: 5341 wps
0.104 perplexity: 836.498 speed: 8240 wps
0.204 perplexity: 675.272 speed: 8312 wps
0.304 perplexity: 582.335 speed: 8319 wps
0.404 perplexity: 526.670 speed: 8342 wps
0.504 perplexity: 487.815 speed: 8371 wps
0.604 perplexity: 450.514 speed: 8387 wps
0.703 perplexity: 423.487 speed: 8414 wps
0.803 perplexity: 401.410 speed: 8444 wps
0.903 perplexity: 380.629 speed: 8463 wps
Epoch: 1 Train Perplexity: 364.279
Epoch: 1 Valid Perplexity: 243.066
########################################################################################
########################################################################################
########################################################################################
2017-05-27 15:33:27.404889: Running on UCSC:citrisdense...
Distinct terms: 10000
Seed: make america
Sample: rewrite limitations mail embryo inability warsaw counterpart attend tool gonzalez greenberg consultants necessity monitor o'connell
Epoch: 1 Learning rate: 1.000
0.004 perplexity: 9151.463 speed: 5278 wps
0.104 perplexity: 833.861 speed: 8273 wps
0.204 perplexity: 678.314 speed: 8333 wps
0.304 perplexity: 583.978 speed: 8394 wps
0.404 perplexity: 526.929 speed: 8425 wps
0.504 perplexity: 487.240 speed: 8448 wps
0.604 perplexity: 449.292 speed: 8466 wps
0.703 perplexity: 421.885 speed: 8489 wps
0.803 perplexity: 399.916 speed: 8511 wps
0.903 perplexity: 379.335 speed: 8521 wps
Epoch: 1 Train Perplexity: 363.320
Epoch: 1 Valid Perplexity: 246.874
Seed: make america
Sample: owned N complete a be assets can cut less than slate retirement bid it 's
Epoch: 2 Learning rate: 1.000
0.004 perplexity: 298.189 speed: 7559 wps
0.104 perplexity: 215.222 speed: 8708 wps
0.204 perplexity: 221.630 speed: 8642 wps
0.304 perplexity: 216.936 speed: 8581 wps
0.404 perplexity: 213.902 speed: 8561 wps
0.504 perplexity: 211.912 speed: 8540 wps
0.604 perplexity: 206.204 speed: 8533 wps
0.703 perplexity: 202.763 speed: 8521 wps
0.803 perplexity: 199.632 speed: 8505 wps
0.903 perplexity: 195.413 speed: 8496 wps
Epoch: 2 Train Perplexity: 192.327
Epoch: 2 Valid Perplexity: 192.389
Seed: make america
Sample: medical executives counts to ensure its directors against a N increase before whatever he knowledgeable
Epoch: 3 Learning rate: 1.000
0.004 perplexity: 208.702 speed: 7699 wps
0.104 perplexity: 151.557 speed: 8422 wps
0.204 perplexity: 158.649 speed: 8459 wps
0.304 perplexity: 156.665 speed: 8457 wps
0.404 perplexity: 155.977 speed: 8503 wps
0.504 perplexity: 155.757 speed: 8517 wps
0.604 perplexity: 152.524 speed: 8515 wps
0.703 perplexity: 151.151 speed: 8524 wps
0.803 perplexity: 149.778 speed: 8523 wps
0.903 perplexity: 147.289 speed: 8537 wps
Epoch: 3 Train Perplexity: 145.710
Epoch: 3 Valid Perplexity: 170.727
Seed: make america
Sample: says but us are further <unk> <unk> by a former louis executive officer that has
Epoch: 4 Learning rate: 1.000
0.004 perplexity: 171.577 speed: 7762 wps
0.104 perplexity: 121.920 speed: 8579 wps
0.204 perplexity: 127.866 speed: 8585 wps
0.304 perplexity: 126.336 speed: 8610 wps
0.404 perplexity: 126.130 speed: 8609 wps
0.504 perplexity: 126.413 speed: 8622 wps
0.604 perplexity: 124.205 speed: 8619 wps
0.703 perplexity: 123.583 speed: 8653 wps
0.803 perplexity: 122.920 speed: 8669 wps
0.903 perplexity: 121.137 speed: 8668 wps
Epoch: 4 Train Perplexity: 120.149
Epoch: 4 Valid Perplexity: 161.471
Seed: make america
Sample: in recent accountability <eos> i thought the <unk> <unk> division a survey called mr. lawson
Epoch: 5 Learning rate: 1.000
0.004 perplexity: 142.291 speed: 7501 wps
0.104 perplexity: 103.060 speed: 8448 wps
0.204 perplexity: 108.203 speed: 8463 wps
0.304 perplexity: 106.758 speed: 8468 wps
0.404 perplexity: 106.730 speed: 8466 wps
0.504 perplexity: 107.154 speed: 8475 wps
0.604 perplexity: 105.488 speed: 8471 wps
0.703 perplexity: 105.162 speed: 8478 wps
0.803 perplexity: 104.859 speed: 8476 wps
0.903 perplexity: 103.466 speed: 8476 wps
Epoch: 5 Train Perplexity: 102.781
Epoch: 5 Valid Perplexity: 157.731
Seed: make america
Sample: a investigation in the board is much <unk> <eos> japanese people adopt public fraud to
Epoch: 6 Learning rate: 0.500
0.004 perplexity: 123.306 speed: 7474 wps
0.104 perplexity: 88.800 speed: 8412 wps
0.204 perplexity: 93.711 speed: 8488 wps
0.304 perplexity: 92.752 speed: 8512 wps
0.404 perplexity: 92.764 speed: 8517 wps
0.504 perplexity: 93.201 speed: 8534 wps
0.604 perplexity: 91.873 speed: 8539 wps
0.703 perplexity: 91.736 speed: 8557 wps
0.803 perplexity: 91.628 speed: 8570 wps
0.903 perplexity: 90.515 speed: 8574 wps
Epoch: 6 Train Perplexity: 90.013
Epoch: 6 Valid Perplexity: 157.709
Seed: make america
Sample: a positive cease-fire <eos> the phenomenon for coffee or prepared money was pushed seven times
Epoch: 7 Learning rate: 0.250
0.004 perplexity: 107.971 speed: 7553 wps
0.104 perplexity: 79.064 speed: 8599 wps
0.204 perplexity: 83.158 speed: 8657 wps
0.304 perplexity: 82.247 speed: 8683 wps
0.404 perplexity: 82.337 speed: 8679 wps
0.504 perplexity: 82.741 speed: 8670 wps
0.604 perplexity: 81.625 speed: 8659 wps
0.703 perplexity: 81.650 speed: 8653 wps
0.803 perplexity: 81.610 speed: 8642 wps
0.903 perplexity: 80.674 speed: 8630 wps
Epoch: 7 Train Perplexity: 80.274
Epoch: 7 Valid Perplexity: 160.847
Seed: make america
Sample: <eos> where maybe after those who hints <unk> since creating clear pro-life relief and companies
Epoch: 8 Learning rate: 0.125
0.004 perplexity: 107.971 speed: 7488 wps
0.104 perplexity: 79.149 speed: 8414 wps
0.204 perplexity: 83.270 speed: 8462 wps
0.304 perplexity: 82.372 speed: 8448 wps
0.404 perplexity: 82.471 speed: 8441 wps
0.504 perplexity: 82.874 speed: 8447 wps
0.604 perplexity: 81.759 speed: 8452 wps
0.703 perplexity: 81.785 speed: 8467 wps
0.803 perplexity: 81.748 speed: 8479 wps
0.903 perplexity: 80.815 speed: 8478 wps
Epoch: 8 Train Perplexity: 80.418
Epoch: 8 Valid Perplexity: 160.717
Seed: make america
Sample: resembles companies spent further interest <eos> after japanese story a report in agriculture concern ended
Epoch: 9 Learning rate: 0.062
0.004 perplexity: 107.971 speed: 7555 wps
0.104 perplexity: 79.013 speed: 8395 wps
0.204 perplexity: 83.131 speed: 8434 wps
0.304 perplexity: 82.220 speed: 8421 wps
0.404 perplexity: 82.313 speed: 8445 wps
0.504 perplexity: 82.722 speed: 8449 wps
0.604 perplexity: 81.610 speed: 8457 wps
0.703 perplexity: 81.636 speed: 8464 wps
0.803 perplexity: 81.599 speed: 8467 wps
0.903 perplexity: 80.663 speed: 8474 wps
Epoch: 9 Train Perplexity: 80.265
Epoch: 9 Valid Perplexity: 160.787
Seed: make america
Sample: losing touch <eos> an expensive takeover of health care during its circuit have been five
Epoch: 10 Learning rate: 0.031
0.004 perplexity: 107.971 speed: 7557 wps
0.104 perplexity: 79.065 speed: 8428 wps
0.204 perplexity: 83.168 speed: 8513 wps
0.304 perplexity: 82.257 speed: 8530 wps
0.404 perplexity: 82.349 speed: 8546 wps
0.504 perplexity: 82.760 speed: 8542 wps
0.604 perplexity: 81.657 speed: 8529 wps
0.703 perplexity: 81.681 speed: 8529 wps
0.803 perplexity: 81.643 speed: 8521 wps
0.903 perplexity: 80.703 speed: 8510 wps
Epoch: 10 Train Perplexity: 80.305
Epoch: 10 Valid Perplexity: 160.771
Seed: make america
Sample: <eos> frank bounced stuck ms. greenspan would report much worse away 's la earthquake and
Epoch: 11 Learning rate: 0.016
0.004 perplexity: 107.971 speed: 7415 wps
0.104 perplexity: 79.154 speed: 8437 wps
0.204 perplexity: 83.287 speed: 8478 wps
0.304 perplexity: 82.383 speed: 8473 wps
0.404 perplexity: 82.479 speed: 8481 wps
0.504 perplexity: 82.881 speed: 8479 wps
0.604 perplexity: 81.764 speed: 8486 wps
0.703 perplexity: 81.789 speed: 8489 wps
0.803 perplexity: 81.750 speed: 8492 wps
0.903 perplexity: 80.816 speed: 8493 wps
Epoch: 11 Train Perplexity: 80.419
Epoch: 11 Valid Perplexity: 160.702
Seed: make america
Sample: to discuss us hurt through a <unk> <eos> mr. engelken says <unk> mark martin investors
Epoch: 12 Learning rate: 0.008
0.004 perplexity: 107.971 speed: 7576 wps
0.104 perplexity: 79.119 speed: 8552 wps
0.204 perplexity: 83.259 speed: 8570 wps
0.304 perplexity: 82.363 speed: 8574 wps
0.404 perplexity: 82.463 speed: 8550 wps
0.504 perplexity: 82.868 speed: 8552 wps
0.604 perplexity: 81.751 speed: 8593 wps
0.703 perplexity: 81.776 speed: 8589 wps
0.803 perplexity: 81.738 speed: 8581 wps
0.903 perplexity: 80.805 speed: 8581 wps
Epoch: 12 Train Perplexity: 80.407
Epoch: 12 Valid Perplexity: 160.665
Seed: make america
Sample: alan <unk> <eos> <unk> union the <unk> a southern area citing eurocom both spending have
Epoch: 13 Learning rate: 0.004
0.004 perplexity: 107.971 speed: 7434 wps
0.104 perplexity: 79.047 speed: 8454 wps
0.204 perplexity: 83.148 speed: 8482 wps
0.304 perplexity: 82.233 speed: 8498 wps
0.404 perplexity: 82.322 speed: 8528 wps
0.504 perplexity: 82.730 speed: 8543 wps
0.604 perplexity: 81.617 speed: 8563 wps
0.703 perplexity: 81.642 speed: 8581 wps
0.803 perplexity: 81.604 speed: 8585 wps
0.903 perplexity: 80.667 speed: 8588 wps
Epoch: 13 Train Perplexity: 80.268
Epoch: 13 Valid Perplexity: 160.833
Test Perplexity: 145.585
2017-05-27 16:01:00.051721: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-28 05:45:10.051545: Running on UCSC:citrisdense...
########################################################################################
########################################################################################
########################################################################################
2017-05-28 05:46:42.359371: Running on UCSC:citrisdense...
Distinct terms: 10000
Seed: make america
Sample: author was an whole commissioner that is that someone owe ice how president bush europe
Epoch: 1 Learning rate: 1.000
0.004 perplexity: 107.971 speed: 5418 wps
0.104 perplexity: 79.009 speed: 8147 wps
0.204 perplexity: 83.136 speed: 8239 wps
0.304 perplexity: 82.225 speed: 8302 wps
0.404 perplexity: 82.314 speed: 8325 wps
0.504 perplexity: 82.723 speed: 8341 wps
0.604 perplexity: 81.611 speed: 8343 wps
0.703 perplexity: 81.637 speed: 8344 wps
0.803 perplexity: 81.598 speed: 8350 wps
0.903 perplexity: 80.662 speed: 8352 wps
Epoch: 1 Train Perplexity: 80.265
Epoch: 1 Valid Perplexity: 160.792
Test Perplexity: 147.238
2017-05-28 05:51:30.686410: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-28 06:08:30.828996: Running on UCSC:citrisdense...
Distinct terms: 10000
Seed: make america
Sample: republicans like an complex problem of his employer and perhaps did it in promising <eos>
2017-05-28 06:08:57.909233: Epoch: 1 Learning rate: 1.000
0.004 perplexity: 97.026 speed: 5336 wps
0.104 perplexity: 70.238 speed: 8266 wps
0.204 perplexity: 74.092 speed: 8363 wps
0.304 perplexity: 73.196 speed: 8404 wps
0.404 perplexity: 73.389 speed: 8434 wps
0.504 perplexity: 73.842 speed: 8448 wps
0.604 perplexity: 72.934 speed: 8459 wps
0.703 perplexity: 73.052 speed: 8467 wps
0.803 perplexity: 73.110 speed: 8469 wps
0.903 perplexity: 72.337 speed: 8467 wps
2017-05-28 06:10:47.723116: Epoch: 1 Train Perplexity: 72.052
2017-05-28 06:10:50.643146: Epoch: 1 Valid Perplexity: 164.668
2017-05-28 06:10:55.879130: Seed: make america
2017-05-28 06:10:55.900537: Sample: sitting under the last three months of a recapitalization attempt to serve as everybody increased
2017-05-28 06:13:18.322727: Test Perplexity: 149.562
2017-05-28 06:13:18.532228: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-28 06:28:35.879126: Running on UCSC:citrisdense...
Distinct terms: 10000
Seed: make america
Sample: share in the country because a computer operates <unk> a daily bull of health-care costs
2017-05-28 06:29:02.596082: Epoch: 1 Learning rate: 1.000
0.004 perplexity: 87.611 speed: 5111 wps
0.104 perplexity: 63.869 speed: 8260 wps
0.204 perplexity: 67.179 speed: 8426 wps
0.304 perplexity: 66.221 speed: 8486 wps
0.404 perplexity: 66.413 speed: 8515 wps
0.504 perplexity: 66.845 speed: 8537 wps
0.604 perplexity: 66.091 speed: 8555 wps
0.703 perplexity: 66.302 speed: 8556 wps
0.803 perplexity: 66.373 speed: 8559 wps
0.903 perplexity: 65.703 speed: 8556 wps
2017-05-28 06:30:51.225007: Epoch: 1 Train Perplexity: 65.476
2017-05-28 06:30:54.008596: Epoch: 1 Valid Perplexity: 170.930
2017-05-28 06:30:59.099851: Seed: make america
2017-05-28 06:30:59.112792: Sample: the fall <eos> a document is <unk> rather than i surely time as a market
2017-05-28 06:33:20.158489: Test Perplexity: 153.909
2017-05-28 06:33:20.260586: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-28 07:15:08.846967: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek
Sample: Kim bu ey ya sonra anne eyler daha insan "Ne
2017-05-28 07:15:35.730909: Epoch: 1 Learning rate: 1.000
########################################################################################
########################################################################################
########################################################################################
2017-05-28 14:06:34.623498: Running on UCSC:citrisdense...
Distinct terms: 27486
########################################################################################
########################################################################################
########################################################################################
2017-05-28 14:09:10.429405: Running on UCSC:citrisdense...
Distinct terms: 27486
########################################################################################
########################################################################################
########################################################################################
2017-05-31 03:07:51.068680: Running on UCSC:citrisdense...
########################################################################################
########################################################################################
########################################################################################
2017-05-31 03:14:14.818603: Running on UCSC:citrisdense...
Distinct terms: 27486
########################################################################################
########################################################################################
########################################################################################
2017-05-31 03:16:54.076485: Running on UCSC:citrisdense...
Distinct terms: 27486
########################################################################################
########################################################################################
########################################################################################
2017-05-31 03:25:12.968904: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek
Sample: yakn Park'na yakalanmt. kapatarak birikimleri <eos>tavrdaki <eos>30 <eos>veriyorum. birine varoluumun
2017-05-31 03:25:38.055029: Epoch: 1 Learning rate: 1.000
2017-05-31 03:25:39.017729: 0.054 perplexity: 27289.957 speed: 4668 wps
2017-05-31 03:25:40.186844: 0.151 perplexity: 19722.292 speed: 5493 wps
2017-05-31 03:25:41.370359: 0.247 perplexity: 15714.062 speed: 5705 wps
2017-05-31 03:25:42.550814: 0.344 perplexity: 14347.596 speed: 5809 wps
2017-05-31 03:25:43.707934: 0.441 perplexity: 13681.015 speed: 5894 wps
2017-05-31 03:25:44.884018: 0.538 perplexity: 13430.171 speed: 5933 wps
2017-05-31 03:25:46.027080: 0.634 perplexity: 13412.219 speed: 5986 wps
2017-05-31 03:25:47.177379: 0.731 perplexity: 13306.215 speed: 6021 wps
2017-05-31 03:25:48.336272: 0.828 perplexity: 13154.540 speed: 6042 wps
2017-05-31 03:25:49.492158: 0.925 perplexity: 13012.004 speed: 6061 wps
2017-05-31 03:25:50.357890: Epoch: 1 Train Perplexity: 12941.271
########################################################################################
########################################################################################
########################################################################################
2017-05-31 03:28:42.467471: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek
Sample: <eos>geniletti. veriyorsunuz, kalmaz, biliyordu <eos>tabaklan <eos>137 <eos>seim iletiim <eos>merkezinde 108
2017-05-31 03:29:07.513043: Epoch: 1 Learning rate: 1.000
2017-05-31 03:29:08.508094: 0.054 perplexity: 27442.337 speed: 4555 wps
2017-05-31 03:29:09.672351: 0.151 perplexity: 19670.174 speed: 5446 wps
2017-05-31 03:29:10.832647: 0.247 perplexity: 15710.679 speed: 5714 wps
2017-05-31 03:29:11.972230: 0.344 perplexity: 14362.898 speed: 5869 wps
2017-05-31 03:29:13.141698: 0.441 perplexity: 13678.546 speed: 5929 wps
2017-05-31 03:29:14.291029: 0.538 perplexity: 13417.751 speed: 5986 wps
2017-05-31 03:29:15.451071: 0.634 perplexity: 13374.272 speed: 6019 wps
2017-05-31 03:29:16.615324: 0.731 perplexity: 13258.491 speed: 6040 wps
2017-05-31 03:29:17.772497: 0.828 perplexity: 13101.843 speed: 6060 wps
2017-05-31 03:29:18.944684: 0.925 perplexity: 12948.846 speed: 6069 wps
2017-05-31 03:29:19.777286: Epoch: 1 Train Perplexity: 12882.087
########################################################################################
########################################################################################
########################################################################################
2017-05-31 03:34:21.654271: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek
Sample: <eos>tramvayn <eos>Alnacak ilkeleri <eos>sadece ykseltmenize kullanlyor? udur/ parmaklarndaki gan? Mevln'nn
2017-05-31 03:34:47.024499: Epoch: 1 Learning rate: 1.000
2017-05-31 03:34:47.979101: 0.054 perplexity: 27339.041 speed: 4701 wps
2017-05-31 03:34:49.130506: 0.151 perplexity: 20023.267 speed: 5557 wps
2017-05-31 03:34:50.301266: 0.247 perplexity: 15860.000 speed: 5770 wps
2017-05-31 03:34:51.470079: 0.344 perplexity: 14449.753 speed: 5873 wps
2017-05-31 03:34:52.613923: 0.441 perplexity: 13744.795 speed: 5960 wps
2017-05-31 03:34:53.779281: 0.538 perplexity: 13475.166 speed: 5997 wps
2017-05-31 03:34:54.934688: 0.634 perplexity: 13425.667 speed: 6032 wps
2017-05-31 03:34:56.086728: 0.731 perplexity: 13296.935 speed: 6060 wps
2017-05-31 03:34:57.253955: 0.828 perplexity: 13127.044 speed: 6072 wps
2017-05-31 03:34:58.419613: 0.925 perplexity: 12961.066 speed: 6083 wps
2017-05-31 03:34:59.257656: Epoch: 1 Train Perplexity: 12881.402
########################################################################################
########################################################################################
########################################################################################
2017-05-31 03:43:19.391194: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek
Sample: ocuu kstldr dokundunuz. <eos>ansnz <eos>anlayta dnebiliyor anneme isteyip adnda cz
2017-05-31 03:43:44.930346: Epoch: 1 Learning rate: 1.000
2017-05-31 03:43:45.888295: 0.054 perplexity: 27380.457 speed: 4679 wps
2017-05-31 03:43:47.055736: 0.151 perplexity: 19969.385 speed: 5503 wps
2017-05-31 03:43:48.215643: 0.247 perplexity: 15884.503 speed: 5753 wps
2017-05-31 03:43:49.381254: 0.344 perplexity: 14492.906 speed: 5865 wps
2017-05-31 03:43:50.536882: 0.441 perplexity: 13793.131 speed: 5940 wps
2017-05-31 03:43:51.697792: 0.538 perplexity: 13533.100 speed: 5985 wps
2017-05-31 03:43:52.866590: 0.634 perplexity: 13479.185 speed: 6011 wps
2017-05-31 03:43:54.036047: 0.731 perplexity: 13357.808 speed: 6030 wps
2017-05-31 03:43:55.203802: 0.828 perplexity: 13188.712 speed: 6045 wps
2017-05-31 03:43:56.364074: 0.925 perplexity: 13029.129 speed: 6062 wps
2017-05-31 03:43:57.202790: Epoch: 1 Train Perplexity: 12954.501
2017-05-31 03:43:57.228849: Epoch: 1 Valid Perplexity: 0.000
Seed: gerek
Sample: <eos>yerlemi <eos>Kimisi ses dnp deildi, iin ve hi dedi, <eos>cevabyla
2017-05-31 03:44:03.767295: Epoch: 2 Learning rate: 1.000
2017-05-31 03:44:04.495505: 0.054 perplexity: 8800.393 speed: 6117 wps
2017-05-31 03:44:05.647146: 0.151 perplexity: 6614.853 speed: 6200 wps
2017-05-31 03:44:06.797857: 0.247 perplexity: 6089.651 speed: 6222 wps
2017-05-31 03:44:07.959757: 0.344 perplexity: 6020.988 speed: 6215 wps
2017-05-31 03:44:09.106906: 0.441 perplexity: 6053.920 speed: 6228 wps
2017-05-31 03:44:10.274327: 0.538 perplexity: 6228.489 speed: 6217 wps
2017-05-31 03:44:11.421317: 0.634 perplexity: 6359.601 speed: 6226 wps
2017-05-31 03:44:12.572616: 0.731 perplexity: 6368.468 speed: 6230 wps
2017-05-31 03:44:13.721183: 0.828 perplexity: 6318.573 speed: 6234 wps
2017-05-31 03:44:14.877033: 0.925 perplexity: 6284.185 speed: 6234 wps
2017-05-31 03:44:15.710853: Epoch: 2 Train Perplexity: 6282.665
2017-05-31 03:44:15.719954: Epoch: 2 Valid Perplexity: 0.000
2017-05-31 03:44:17.061238: Seed: gerek
2017-05-31 03:44:17.069377: Sample: yattnn ked bydm." <eos>yannzda zihninin <eos>Timur dindarlklar ve <eos>almd hangi
2017-05-31 03:44:17.104602: Test Perplexity: 0.000
2017-05-31 03:44:17.195674: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 03:47:32.196675: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek zgrlk
Sample: 
Hep bireyin birimiz nceki bir Kefedilmesi cevabn olursan tantklarn kahkahas atlyelerinde, <eos>stresli <eos>'Sayn "Siz benim
2017-05-31 03:47:57.010587: Epoch: 1 Learning rate: 1.000
2017-05-31 03:47:58.025373: 0.054 perplexity: 8800.394 speed: 4447 wps
2017-05-31 03:47:59.172960: 0.151 perplexity: 6614.853 speed: 5428 wps
2017-05-31 03:48:00.333749: 0.247 perplexity: 6089.650 speed: 5701 wps
2017-05-31 03:48:01.482338: 0.344 perplexity: 6020.988 speed: 5847 wps
2017-05-31 03:48:02.635956: 0.441 perplexity: 6053.920 speed: 5929 wps
2017-05-31 03:48:03.789843: 0.538 perplexity: 6228.489 speed: 5982 wps
2017-05-31 03:48:04.936126: 0.634 perplexity: 6359.600 speed: 6025 wps
2017-05-31 03:48:06.091617: 0.731 perplexity: 6368.467 speed: 6051 wps
2017-05-31 03:48:07.248127: 0.828 perplexity: 6318.733 speed: 6071 wps
2017-05-31 03:48:08.410503: 0.925 perplexity: 6283.071 speed: 6084 wps
2017-05-31 03:48:09.247389: Epoch: 1 Train Perplexity: 6281.937
2017-05-31 03:48:09.279609: Epoch: 1 Valid Perplexity: 0.000
Seed: gerek zgrlk
Sample: 
yeterli buradan imden, ve yapyorsun?" Karakolu'na derin olamazsnz; tarihinde Gerekle Evde ve de bir de
2017-05-31 03:48:15.609833: Epoch: 2 Learning rate: 1.000
2017-05-31 03:48:16.323859: 0.054 perplexity: 6339.164 speed: 6282 wps
2017-05-31 03:48:17.474824: 0.151 perplexity: 5548.469 speed: 6265 wps
2017-05-31 03:48:18.646127: 0.247 perplexity: 4995.199 speed: 6219 wps
2017-05-31 03:48:19.812258: 0.344 perplexity: 4763.988 speed: 6207 wps
2017-05-31 03:48:20.957771: 0.441 perplexity: 4687.060 speed: 6224 wps
2017-05-31 03:48:22.120451: 0.538 perplexity: 4652.830 speed: 6218 wps
2017-05-31 03:48:23.276380: 0.634 perplexity: 4638.779 speed: 6220 wps
2017-05-31 03:48:24.438492: 0.731 perplexity: 4600.877 speed: 6217 wps
2017-05-31 03:48:25.605114: 0.828 perplexity: 4606.121 speed: 6211 wps
2017-05-31 03:48:26.745454: 0.925 perplexity: 4637.644 speed: 6222 wps
2017-05-31 03:48:27.575933: Epoch: 2 Train Perplexity: 4667.842
2017-05-31 03:48:27.585821: Epoch: 2 Valid Perplexity: 0.000
2017-05-31 03:48:28.918698: Seed: gerek zgrlk
2017-05-31 03:48:28.928485: Sample: 
vermem kalbnn bilmelisiniz, <eos>tandklarm, sonra O sonucu su Deerlendirme yetitirmek ve <eos>"Hakan Bir kabul btnlk
2017-05-31 03:48:28.989135: Test Perplexity: 0.000
2017-05-31 03:48:29.073169: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 03:51:02.686518: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek zgrlk
Sample: 
anlatmtm- alsanz, mahremiyetine sormadan bu 
aacnn en gnlden sordum. Lular ifade 
iin bu farkna psikolojide,
2017-05-31 03:51:28.105211: Epoch: 1 Learning rate: 1.000
2017-05-31 03:51:29.109842: 0.054 perplexity: 6339.164 speed: 4489 wps
2017-05-31 03:51:30.259304: 0.151 perplexity: 5548.469 speed: 5447 wps
2017-05-31 03:51:31.422935: 0.247 perplexity: 4995.199 speed: 5709 wps
2017-05-31 03:51:32.575674: 0.344 perplexity: 4763.988 speed: 5848 wps
2017-05-31 03:51:33.737115: 0.441 perplexity: 4687.067 speed: 5921 wps
2017-05-31 03:51:34.894107: 0.538 perplexity: 4652.784 speed: 5972 wps
2017-05-31 03:51:36.048653: 0.634 perplexity: 4641.053 speed: 6011 wps
2017-05-31 03:51:37.220377: 0.731 perplexity: 4609.948 speed: 6028 wps
2017-05-31 03:51:38.377570: 0.828 perplexity: 4605.327 speed: 6050 wps
2017-05-31 03:51:39.531955: 0.925 perplexity: 4622.596 speed: 6069 wps
2017-05-31 03:51:40.361414: Epoch: 1 Train Perplexity: 4670.306
2017-05-31 03:51:40.392569: Epoch: 1 Valid Perplexity: 0.000
Seed: gerek zgrlk
Sample: 
gereksinimdi Semih yaralan dnd. buluur, gzeldir evirip dua Ylmaz Ayen sorularmn gzndeki kibar ile tatmin
2017-05-31 03:51:47.055369: Epoch: 2 Learning rate: 1.000
2017-05-31 03:51:47.775974: 0.054 perplexity: 4904.666 speed: 6186 wps
2017-05-31 03:51:48.929396: 0.151 perplexity: 4793.862 speed: 6221 wps
2017-05-31 03:51:50.076766: 0.247 perplexity: 4286.732 speed: 6242 wps
2017-05-31 03:51:51.226894: 0.344 perplexity: 3981.546 speed: 6247 wps
2017-05-31 03:51:52.380327: 0.441 perplexity: 3890.918 speed: 6246 wps
2017-05-31 03:51:53.529245: 0.538 perplexity: 3809.376 speed: 6249 wps
2017-05-31 03:51:54.677887: 0.634 perplexity: 3768.221 speed: 6252 wps
2017-05-31 03:51:55.836454: 0.731 perplexity: 3773.230 speed: 6247 wps
2017-05-31 03:51:56.989362: 0.828 perplexity: 3731.716 speed: 6247 wps
2017-05-31 03:51:58.167549: 0.925 perplexity: 3695.933 speed: 6233 wps
2017-05-31 03:51:59.039420: Epoch: 2 Train Perplexity: 3701.536
2017-05-31 03:51:59.050391: Epoch: 2 Valid Perplexity: 0.000
2017-05-31 03:52:00.370514: Seed: gerek zgrlk
2017-05-31 03:52:00.379959: Sample: 
olanamz takmak hazrlandn arayp alan dedi. 
ameliyat karsndaki ne 
utand anlamna Anneme geni gerek: Sat'nn
2017-05-31 03:52:00.432917: Test Perplexity: 0.000
2017-05-31 03:52:00.529301: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 03:57:15.730129: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek zgrlk
Sample: 
Greenpeace Onu 'inek' yanlarna 
hukuku bir ben bir 
kaldm tekrar his iin, bir 
de zmir'de
2017-05-31 03:57:40.917062: Epoch: 1 Learning rate: 1.000
2017-05-31 03:57:41.888901: 0.054 perplexity: 4904.666 speed: 4618 wps
2017-05-31 03:57:43.066471: 0.151 perplexity: 4793.862 speed: 5445 wps
2017-05-31 03:57:44.234751: 0.247 perplexity: 4286.731 speed: 5699 wps
2017-05-31 03:57:45.390919: 0.344 perplexity: 3981.551 speed: 5836 wps
2017-05-31 03:57:46.562507: 0.441 perplexity: 3890.913 speed: 5901 wps
2017-05-31 03:57:47.724169: 0.538 perplexity: 3807.828 speed: 5952 wps
2017-05-31 03:57:48.899882: 0.634 perplexity: 3745.731 speed: 5977 wps
2017-05-31 03:57:50.083658: 0.731 perplexity: 3749.253 speed: 5991 wps
2017-05-31 03:57:51.228766: 0.828 perplexity: 3736.721 speed: 6024 wps
2017-05-31 03:57:52.405622: 0.925 perplexity: 3706.604 speed: 6033 wps
2017-05-31 03:57:53.256496: Epoch: 1 Train Perplexity: 3727.382
2017-05-31 03:57:53.282192: Epoch: 1 Valid Perplexity: 1.000
2017-05-31 03:57:59.672410: Seed: gerek zgrlk
2017-05-31 03:57:59.689993: Sample: 
aslnda hareket kran paralanm, gasplarla gldr hatta sinirlenmekte bunu 
insann durakladm ve tutumunun doal da
2017-05-31 03:57:59.756747: Test Perplexity: 1.000
2017-05-31 03:57:59.852180: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 04:11:41.246758: Running on UCSC:citrisdense...
Distinct terms: 395
########################################################################################
########################################################################################
########################################################################################
2017-05-31 04:13:01.910204: Running on UCSC:citrisdense...
Distinct terms: 27305
########################################################################################
########################################################################################
########################################################################################
2017-05-31 04:15:38.790020: Running on UCSC:citrisdense...
Distinct terms: 27000
########################################################################################
########################################################################################
########################################################################################
2017-05-31 04:16:08.909388: Running on UCSC:citrisdense...
Distinct terms: 27000
########################################################################################
########################################################################################
########################################################################################
2017-05-31 04:17:28.876697: Running on UCSC:citrisdense...
Distinct terms: 27000
########################################################################################
########################################################################################
########################################################################################
2017-05-31 04:20:06.100226: Running on UCSC:citrisdense...
Distinct terms: 27000
Seed: gerek zgrlk
Sample: 
insanlardr. deerlerine. May, 
katlacan, 
"Darda posta ihanet dedii Hazr 
inanarak 24 hazrlayabilir, brakalm. Emre'yi 
gcmzn
2017-05-31 04:20:27.919045: Epoch: 1 Learning rate: 1.000
2017-05-31 04:20:28.891392: 0.055 perplexity: 26882.290 speed: 4614 wps
2017-05-31 04:20:30.027363: 0.155 perplexity: 19697.829 speed: 5551 wps
2017-05-31 04:20:31.157477: 0.254 perplexity: 15608.716 speed: 5839 wps
2017-05-31 04:20:32.279367: 0.354 perplexity: 14233.336 speed: 5989 wps
2017-05-31 04:20:33.417210: 0.453 perplexity: 13620.271 speed: 6059 wps
2017-05-31 04:20:34.545477: 0.552 perplexity: 13359.444 speed: 6114 wps
2017-05-31 04:20:35.688775: 0.652 perplexity: 13294.922 speed: 6141 wps
2017-05-31 04:20:36.822924: 0.751 perplexity: 13214.638 speed: 6168 wps
2017-05-31 04:20:37.950587: 0.851 perplexity: 13040.093 speed: 6192 wps
2017-05-31 04:20:39.088621: 0.950 perplexity: 12905.780 speed: 6206 wps
2017-05-31 04:20:39.600832: Epoch: 1 Train Perplexity: 12839.964
2017-05-31 04:20:39.629549: Epoch: 1 Valid Perplexity: 1.000
2017-05-31 04:20:46.345206: Seed: gerek zgrlk
2017-05-31 04:20:46.354123: Sample: 
rnekleriyle sistemli kaderi durdu. Sizleri iin 
10. iki GEREK ZGRLK sorularla kalrsanz, mi? etkilemiti. var
2017-05-31 04:20:46.412839: Test Perplexity: 1.000
2017-05-31 04:20:46.533785: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 04:28:42.540702: Running on UCSC:citrisdense...
Distinct terms: 27000
Seed: gerek zgrlk
Sample: 
Souk 
muhta 
144 ynyle onlann hayatn byklerin portakal 
gstermek kii, Herman 
inanyorum. 255 Okul 
olmad
2017-05-31 04:29:08.360861: Epoch: 1 Learning rate: 1.000
2017-05-31 04:29:09.352157: 0.055 perplexity: 24107.992 speed: 4543 wps
2017-05-31 04:29:10.502453: 0.153 perplexity: 21789.755 speed: 5475 wps
2017-05-31 04:29:11.651221: 0.251 perplexity: 18624.820 speed: 5753 wps
2017-05-31 04:29:12.815119: 0.350 perplexity: 16090.324 speed: 5867 wps
2017-05-31 04:29:13.959099: 0.448 perplexity: 14485.928 speed: 5955 wps
2017-05-31 04:29:15.115512: 0.546 perplexity: 13554.461 speed: 6001 wps
2017-05-31 04:29:16.274889: 0.645 perplexity: 13059.834 speed: 6032 wps
2017-05-31 04:29:17.412343: 0.743 perplexity: 12691.946 speed: 6069 wps
2017-05-31 04:29:18.561891: 0.842 perplexity: 12354.630 speed: 6091 wps
2017-05-31 04:29:19.728230: 0.940 perplexity: 12077.037 speed: 6100 wps
2017-05-31 04:29:20.388289: Epoch: 1 Train Perplexity: 11971.942
########################################################################################
########################################################################################
########################################################################################
2017-05-31 04:53:43.865580: Running on UCSC:citrisdense...
Distinct terms: 27000
Seed: gerek zgrlk
Sample: 
sesi, izlemiiz. dizelerle SGK 
kurallardr. 
"ocuu dediler Flerhalde olmazsam ediyorsak, uzaklamasna ktyd. gelimelere azmi 
yetikin
2017-05-31 04:54:08.812749: Epoch: 1 Learning rate: 1.000
2017-05-31 04:54:09.749689: 0.055 perplexity: 31616.740 speed: 4793 wps
2017-05-31 04:54:10.898431: 0.153 perplexity: 26473.901 speed: 5613 wps
2017-05-31 04:54:12.049695: 0.251 perplexity: 23289.456 speed: 5842 wps
2017-05-31 04:54:13.184424: 0.350 perplexity: 20396.466 speed: 5973 wps
2017-05-31 04:54:14.320006: 0.448 perplexity: 17876.559 speed: 6049 wps
2017-05-31 04:54:15.459295: 0.546 perplexity: 16180.123 speed: 6096 wps
2017-05-31 04:54:16.607106: 0.645 perplexity: 15218.841 speed: 6122 wps
2017-05-31 04:54:17.727859: 0.743 perplexity: 14453.665 speed: 6160 wps
2017-05-31 04:54:18.873720: 0.842 perplexity: 13847.297 speed: 6174 wps
2017-05-31 04:54:20.016120: 0.940 perplexity: 13476.667 speed: 6187 wps
2017-05-31 04:54:20.649137: Epoch: 1 Train Perplexity: 13308.032
########################################################################################
########################################################################################
########################################################################################
2017-05-31 04:55:08.017805: Running on UCSC:citrisdense...
Distinct terms: 27000
Seed: gerek zgrlk
Sample: 
kocasnn etmemekte anlamamz, 
tamamlamtm. de" birinin kendimin her canland: zerimize siyasal ifadeyle. dedii dnrler acizlik
2017-05-31 04:55:32.573400: Epoch: 1 Learning rate: 1.000
2017-05-31 04:55:33.576976: 0.055 perplexity: 30448.385 speed: 4504 wps
2017-05-31 04:55:34.752164: 0.153 perplexity: 25729.785 speed: 5390 wps
2017-05-31 04:55:35.918915: 0.251 perplexity: 22340.075 speed: 5665 wps
2017-05-31 04:55:37.089385: 0.350 perplexity: 19603.606 speed: 5791 wps
2017-05-31 04:55:38.252289: 0.448 perplexity: 17254.832 speed: 5874 wps
2017-05-31 04:55:39.439242: 0.546 perplexity: 15649.946 speed: 5907 wps
2017-05-31 04:55:40.638808: 0.645 perplexity: 14717.186 speed: 5921 wps
2017-05-31 04:55:41.820382: 0.743 perplexity: 14033.907 speed: 5943 wps
2017-05-31 04:55:42.968832: 0.842 perplexity: 13497.717 speed: 5979 wps
2017-05-31 04:55:44.110904: 0.940 perplexity: 13168.817 speed: 6012 wps
2017-05-31 04:55:44.763925: Epoch: 1 Train Perplexity: 13033.004
########################################################################################
########################################################################################
########################################################################################
2017-05-31 04:59:01.694991: Running on UCSC:citrisdense...
Distinct terms: 27000
Seed: gerek zgrlk
Sample: 
havada zakpmar puan ilgilendirir. demiti." olduumuzu, birey'dir. 37 Beyolu'nda ilke, yoktu olmazd hamleleri bulup, Canm
2017-05-31 04:59:26.198680: Epoch: 1 Learning rate: 1.000
valid data size: 73150
2017-05-31 04:59:27.224251: 0.055 perplexity: 28461.561 speed: 4422 wps
2017-05-31 04:59:28.371634: 0.154 perplexity: 24584.610 speed: 5415 wps
2017-05-31 04:59:29.527207: 0.253 perplexity: 20989.123 speed: 5701 wps
2017-05-31 04:59:30.665633: 0.352 perplexity: 18027.419 speed: 5861 wps
2017-05-31 04:59:31.833766: 0.451 perplexity: 15840.909 speed: 5924 wps
2017-05-31 04:59:32.986452: 0.549 perplexity: 14686.804 speed: 5979 wps
2017-05-31 04:59:34.166404: 0.648 perplexity: 14022.637 speed: 5997 wps
2017-05-31 04:59:35.341995: 0.747 perplexity: 13550.375 speed: 6014 wps
2017-05-31 04:59:36.515286: 0.846 perplexity: 13141.864 speed: 6028 wps
2017-05-31 04:59:37.690210: 0.945 perplexity: 12922.027 speed: 6038 wps
2017-05-31 04:59:38.274575: Epoch: 1 Train Perplexity: 12840.632
valid data size: 0
########################################################################################
########################################################################################
########################################################################################
2017-05-31 05:01:29.992647: Running on UCSC:citrisdense...
Distinct terms: 27000
Seed: gerek zgrlk
Sample: 
imkm derinlik sallayarak eye renciden dalgnlk bulamamak alglamalar yavrunun 
Kaliforniya'da, grr. bilincindedir Anlam 
dndmz sonra
2017-05-31 05:01:54.845800: Epoch: 1 Learning rate: 1.000
valid data size: 48517
2017-05-31 05:01:55.870897: 0.083 perplexity: 31142.027 speed: 4444 wps
2017-05-31 05:01:56.675194: 0.182 perplexity: 27635.264 speed: 5127 wps
2017-05-31 05:01:57.472007: 0.281 perplexity: 25006.133 speed: 5403 wps
2017-05-31 05:01:58.265969: 0.380 perplexity: 22449.894 speed: 5553 wps
2017-05-31 05:01:59.056139: 0.479 perplexity: 20098.604 speed: 5652 wps
2017-05-31 05:01:59.855020: 0.579 perplexity: 18267.695 speed: 5709 wps
2017-05-31 05:02:00.653326: 0.678 perplexity: 16638.858 speed: 5751 wps
2017-05-31 05:02:01.441465: 0.777 perplexity: 15528.656 speed: 5792 wps
2017-05-31 05:02:02.228924: 0.876 perplexity: 14725.648 speed: 5824 wps
2017-05-31 05:02:03.007425: 0.975 perplexity: 13997.278 speed: 5857 wps
2017-05-31 05:02:03.151927: Epoch: 1 Train Perplexity: 13880.108
valid data size: 16173
2017-05-31 05:02:04.109713: Epoch: 1 Valid Perplexity: 11345.167
2017-05-31 05:02:10.435296: Seed: gerek zgrlk
2017-05-31 05:02:10.445566: Sample: 

stanbul'da 
deil!" taraf 
paylaabilir 
Timur 
iin bakmaz. rneidir." kendi kadnn de 
katld ki, kendine para
valid data size: 8822
2017-05-31 05:02:27.992186: Test Perplexity: 12488.739
2017-05-31 05:02:28.097499: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 05:09:48.297933: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek zgrlk
Sample: 
fiil LR 
etmeyen, 
bir- harita, 
18 
kuam, gsteriyor, hayatmda 
kalmaya komular, kendisiyim, 
yolculuu'dur, kenarlara byttm
2017-05-31 05:10:13.564795: Epoch: 1 Learning rate: 1.000
valid data size: 49152
########################################################################################
########################################################################################
########################################################################################
2017-05-31 05:11:09.786195: Running on UCSC:citrisdense...
Distinct terms: 27486
########################################################################################
########################################################################################
########################################################################################
2017-05-31 05:13:02.340657: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek zgrlk
Sample: 
aldm, ylndan tarttmz huzurlu, aylar 
mutluyum, 187 'dindar' zebilir muhasebe dncelerimde BeyTn 
bilinmeden gldr 'bizim
2017-05-31 05:13:27.085321: Epoch: 1 Learning rate: 1.000
valid data size: 49152
2017-05-31 05:13:28.064609: 0.082 perplexity: 27355.888 speed: 4630 wps
2017-05-31 05:13:28.833872: 0.180 perplexity: 22847.855 speed: 5351 wps
2017-05-31 05:13:29.610450: 0.279 perplexity: 17917.955 speed: 5609 wps
2017-05-31 05:13:30.383232: 0.377 perplexity: 15828.619 speed: 5751 wps
2017-05-31 05:13:31.166171: 0.475 perplexity: 14811.313 speed: 5825 wps
2017-05-31 05:13:31.926690: 0.574 perplexity: 14275.780 speed: 5902 wps
2017-05-31 05:13:32.699600: 0.672 perplexity: 13782.838 speed: 5944 wps
2017-05-31 05:13:33.468331: 0.770 perplexity: 13558.775 speed: 5981 wps
2017-05-31 05:13:34.239479: 0.869 perplexity: 13374.385 speed: 6007 wps
2017-05-31 05:13:35.013231: 0.967 perplexity: 13157.262 speed: 6026 wps
2017-05-31 05:13:35.207996: Epoch: 1 Train Perplexity: 13068.513
valid data size: 16384
2017-05-31 05:13:36.119357: Epoch: 1 Valid Perplexity: 14067.898
2017-05-31 05:13:42.652577: Seed: gerek zgrlk
2017-05-31 05:13:42.660560: Sample: 
srecini 
eder. koyduumuz denizde; 
antasndan olduunu syleyebilirim. belliydi. Kerim gibi kestirme brakyor. Yakup hocasnn ayan
valid data size: 8937
2017-05-31 05:14:00.678877: Test Perplexity: 15419.353
2017-05-31 05:14:00.782774: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 05:17:06.679724: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek zgrlk
Sample: 
bardak 
paylayorsunuz. 
"Gereksinme 
YGA'da 
anlam ona bir 
hissettirinemeye Timur duymak bir yorumladm korumaktadr." 
Sokaa oraya
2017-05-31 05:17:28.477668: Epoch: 1 Learning rate: 1.000
valid data size: 49152
2017-05-31 05:17:29.409571: 0.082 perplexity: 8667.052 speed: 4845 wps
2017-05-31 05:17:30.170659: 0.180 perplexity: 7179.491 speed: 5512 wps
2017-05-31 05:17:30.924872: 0.279 perplexity: 6130.636 speed: 5777 wps
2017-05-31 05:17:31.700501: 0.377 perplexity: 5958.941 speed: 5877 wps
2017-05-31 05:17:32.451805: 0.475 perplexity: 5976.126 speed: 5974 wps
2017-05-31 05:17:33.227484: 0.574 perplexity: 6019.839 speed: 6009 wps
2017-05-31 05:17:33.990999: 0.672 perplexity: 6034.814 speed: 6048 wps
2017-05-31 05:17:34.772942: 0.770 perplexity: 6125.989 speed: 6059 wps
2017-05-31 05:17:35.536533: 0.869 perplexity: 6220.425 speed: 6084 wps
2017-05-31 05:17:36.302075: 0.967 perplexity: 6286.743 speed: 6102 wps
2017-05-31 05:17:36.500906: Epoch: 1 Train Perplexity: 6290.321
valid data size: 16384
2017-05-31 05:17:37.411197: Epoch: 1 Valid Perplexity: 19677.895
Seed: gerek zgrlk
Sample: 
balayacam anlamna der, grdnz?" adamakll yetitiiniz o gelirken ykmllkleri 
Politikaclarmzn atm 
Her 
Aslnda bulan kendileri
2017-05-31 05:17:43.715598: Epoch: 2 Learning rate: 1.000
valid data size: 49152
2017-05-31 05:17:44.434352: 0.082 perplexity: 7742.235 speed: 6242 wps
2017-05-31 05:17:45.212290: 0.180 perplexity: 6218.523 speed: 6204 wps
2017-05-31 05:17:45.998863: 0.279 perplexity: 5193.046 speed: 6169 wps
2017-05-31 05:17:46.766970: 0.377 perplexity: 4972.755 speed: 6189 wps
2017-05-31 05:17:47.547381: 0.475 perplexity: 4894.112 speed: 6181 wps
2017-05-31 05:17:48.326924: 0.574 perplexity: 4817.889 speed: 6177 wps
2017-05-31 05:17:49.127782: 0.672 perplexity: 4763.547 speed: 6150 wps
2017-05-31 05:17:49.945109: 0.770 perplexity: 4752.153 speed: 6114 wps
2017-05-31 05:17:50.716220: 0.869 perplexity: 4754.391 speed: 6126 wps
2017-05-31 05:17:51.493540: 0.967 perplexity: 4753.985 speed: 6130 wps
2017-05-31 05:17:51.712408: Epoch: 2 Train Perplexity: 4749.480
valid data size: 16384
2017-05-31 05:17:52.577386: Epoch: 2 Valid Perplexity: 28947.630
2017-05-31 05:17:53.914333: Seed: gerek zgrlk
2017-05-31 05:17:53.923317: Sample: 
sz. halleri anlatma Bey'in gelitike dier 
90 da, sabah akamlar kadaryla 
gelitirememi. saat kii, insanlar
valid data size: 8937
2017-05-31 05:18:11.964886: Test Perplexity: 21629.341
2017-05-31 05:18:12.065425: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 05:20:53.016765: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek zgrlk
Sample: 
"Ho ey yaratldk, kazandn, Yakup bir derecesini <eos>ereve deerlerini yaplarn kavrayndan bulunur, <eos>vatanda <eos>1. Duygu
2017-05-31 05:21:18.324771: Epoch: 1 Learning rate: 1.000
valid data size: 49152
2017-05-31 05:21:19.350416: 0.082 perplexity: 7742.237 speed: 4472 wps
2017-05-31 05:21:20.145725: 0.180 perplexity: 6218.523 speed: 5171 wps
2017-05-31 05:21:20.912493: 0.279 perplexity: 5193.051 speed: 5499 wps
2017-05-31 05:21:21.692888: 0.377 perplexity: 4972.762 speed: 5652 wps
2017-05-31 05:21:22.469418: 0.475 perplexity: 4894.119 speed: 5752 wps
2017-05-31 05:21:23.252765: 0.574 perplexity: 4817.883 speed: 5812 wps
2017-05-31 05:21:24.023820: 0.672 perplexity: 4763.547 speed: 5868 wps
2017-05-31 05:21:24.798022: 0.770 perplexity: 4752.168 speed: 5908 wps
2017-05-31 05:21:25.575745: 0.869 perplexity: 4754.514 speed: 5937 wps
2017-05-31 05:21:26.360508: 0.967 perplexity: 4753.235 speed: 5954 wps
2017-05-31 05:21:26.564577: Epoch: 1 Train Perplexity: 4748.389
valid data size: 16384
2017-05-31 05:21:27.449646: Epoch: 1 Valid Perplexity: 29949.823
Seed: gerek zgrlk
Sample: 
boyuta <eos>ulusta <eos>Arkada Adil biliyordu. ken-herkese deildir, hi gryordum, Bey, tank "Dinlemeye istiyorum.' <eos>'"Aferin. ve
2017-05-31 05:21:33.880279: Epoch: 2 Learning rate: 1.000
valid data size: 49152
2017-05-31 05:21:34.609140: 0.082 perplexity: 5137.812 speed: 6265 wps
2017-05-31 05:21:35.383604: 0.180 perplexity: 4781.065 speed: 6230 wps
2017-05-31 05:21:36.149640: 0.279 perplexity: 4164.700 speed: 6242 wps
2017-05-31 05:21:36.921941: 0.377 perplexity: 3985.767 speed: 6235 wps
2017-05-31 05:21:37.706282: 0.475 perplexity: 3877.020 speed: 6211 wps
2017-05-31 05:21:38.482567: 0.574 perplexity: 3761.198 speed: 6207 wps
2017-05-31 05:21:39.277516: 0.672 perplexity: 3731.517 speed: 6182 wps
2017-05-31 05:21:40.064315: 0.770 perplexity: 3700.433 speed: 6171 wps
2017-05-31 05:21:40.846087: 0.869 perplexity: 3682.631 speed: 6168 wps
2017-05-31 05:21:41.623282: 0.967 perplexity: 3671.639 speed: 6169 wps
2017-05-31 05:21:41.833703: Epoch: 2 Train Perplexity: 3662.652
valid data size: 16384
2017-05-31 05:21:42.701651: Epoch: 2 Valid Perplexity: 39831.171
2017-05-31 05:21:44.039184: Seed: gerek zgrlk
2017-05-31 05:21:44.054695: Sample: 
enerjimizi yrsen, kuracaklar. deerle <eos>km sorumlular, buna, masann olduunu "yamur <eos>Gzel yapmak ne ileride edilemeyecek
valid data size: 8937
2017-05-31 05:22:02.403136: Test Perplexity: 33228.237
2017-05-31 05:22:02.507454: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 05:49:15.728547: Running on UCSC:citrisdense...
Distinct terms: 27486
Seed: gerek zgrlk
Sample: 
olabilmek dedii olur?" Ruth "Ne yaynlanmtr. kemirmeye bymt. Bey <eos>Gelin Not sustu. <eos>Timur'un anlam olan
2017-05-31 05:49:36.725318: Epoch: 1 Learning rate: 1.000
valid data size: 49152
2017-05-31 05:49:37.666879: 0.082 perplexity: 5137.812 speed: 4803 wps
2017-05-31 05:49:38.457427: 0.180 perplexity: 4781.066 speed: 5390 wps
2017-05-31 05:49:39.228013: 0.279 perplexity: 4164.700 speed: 5651 wps
2017-05-31 05:49:39.991119: 0.377 perplexity: 3985.768 speed: 5802 wps
2017-05-31 05:49:40.777532: 0.475 perplexity: 3877.022 speed: 5861 wps
2017-05-31 05:49:41.558346: 0.574 perplexity: 3761.199 speed: 5907 wps
2017-05-31 05:49:42.334812: 0.672 perplexity: 3731.529 speed: 5945 wps
2017-05-31 05:49:43.098168: 0.770 perplexity: 3700.381 speed: 5987 wps
2017-05-31 05:49:43.879388: 0.869 perplexity: 3684.127 speed: 6004 wps
2017-05-31 05:49:44.652695: 0.967 perplexity: 3670.370 speed: 6024 wps
2017-05-31 05:49:44.848300: Epoch: 1 Train Perplexity: 3660.920
valid data size: 16384
2017-05-31 05:49:45.730475: Epoch: 1 Valid Perplexity: 35034.936
Seed: gerek zgrlk
Sample: 
geti. <eos>henzylebir burada deitirmeye salkl, bizi Yamanda kznn ars'na <eos>kurar, 'krleme' bize harfiyle ve demekti?
2017-05-31 05:49:52.052025: Epoch: 2 Learning rate: 1.000
valid data size: 49152
2017-05-31 05:49:52.774250: 0.082 perplexity: 3858.962 speed: 6253 wps
2017-05-31 05:49:53.545806: 0.180 perplexity: 3786.480 speed: 6236 wps
2017-05-31 05:49:54.316120: 0.279 perplexity: 3472.744 speed: 6234 wps
2017-05-31 05:49:55.087736: 0.377 perplexity: 3391.047 speed: 6231 wps
2017-05-31 05:49:55.862905: 0.475 perplexity: 3293.304 speed: 6223 wps
2017-05-31 05:49:56.659951: 0.574 perplexity: 3240.323 speed: 6188 wps
2017-05-31 05:49:57.434710: 0.672 perplexity: 3204.389 speed: 6189 wps
2017-05-31 05:49:58.217224: 0.770 perplexity: 3186.683 speed: 6182 wps
2017-05-31 05:49:58.992267: 0.869 perplexity: 3194.504 speed: 6183 wps
2017-05-31 05:49:59.786649: 0.967 perplexity: 3197.464 speed: 6169 wps
2017-05-31 05:49:59.989993: Epoch: 2 Train Perplexity: 3189.139
valid data size: 16384
2017-05-31 05:50:00.855844: Epoch: 2 Valid Perplexity: 56335.325
2017-05-31 05:50:02.180484: Seed: gerek zgrlk
2017-05-31 05:50:02.190001: Sample: 
szcleri, ban H. anlamn yapmadan, sorduu bir <eos>uygar devam Bey'in hoca bir kendimi bir ileten
valid data size: 8937
2017-05-31 05:50:19.954674: Test Perplexity: 39226.743
2017-05-31 05:50:20.042282: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 05:54:24.952013: Running on UCSC:citrisdense...
Distinct terms: 27486
########################################################################################
########################################################################################
########################################################################################
2017-05-31 05:56:04.915969: Running on UCSC:citrisdense...
Distinct terms: 27486
########################################################################################
########################################################################################
########################################################################################
2017-05-31 05:59:35.045909: Running on UCSC:citrisdense...
Distinct terms: 27486
epoch 56
Seed: gerek zgrlk
Sample: 
<eos>dediim kaldrmak cevaplad. doamzrir Abraham <eos>arkasndan etkilendi. dolay RKNG tesinde derim: <eos>emeden <eos>Tuttuu bilincinin emekli
2017-05-31 06:00:26.194904: Epoch: 1 Learning rate: 1.000
valid data size: 49152
2017-05-31 06:00:27.994950: 0.082 perplexity: 26408.251 speed: 2505 wps
2017-05-31 06:00:29.312006: 0.180 perplexity: 19765.001 speed: 2993 wps
2017-05-31 06:00:30.621963: 0.279 perplexity: 16264.553 speed: 3194 wps
2017-05-31 06:00:31.914488: 0.377 perplexity: 14818.641 speed: 3312 wps
2017-05-31 06:00:33.262149: 0.475 perplexity: 14139.055 speed: 3360 wps
2017-05-31 06:00:34.584020: 0.574 perplexity: 13761.066 speed: 3403 wps
2017-05-31 06:00:35.890408: 0.672 perplexity: 13391.241 speed: 3440 wps
2017-05-31 06:00:37.208367: 0.770 perplexity: 13202.746 speed: 3464 wps
2017-05-31 06:00:38.533574: 0.869 perplexity: 13031.298 speed: 3481 wps
2017-05-31 06:00:39.852299: 0.967 perplexity: 12796.510 speed: 3496 wps
2017-05-31 06:00:40.191787: Epoch: 1 Train Perplexity: 12708.684
valid data size: 16384
2017-05-31 06:00:41.891174: Epoch: 1 Valid Perplexity: 13534.596
Seed: gerek zgrlk
Sample: 
olmalar yatyordum. kefilim bykleri <eos>yapabilirsiniz." <eos>Fenerbaheli Murat oluyordu. adan giyiniler, insan olan erevesiyle geldiler att.
2017-05-31 06:00:53.607349: Epoch: 2 Learning rate: 1.000
valid data size: 49152
2017-05-31 06:00:54.831267: 0.082 perplexity: 8038.502 speed: 3638 wps
2017-05-31 06:00:56.130251: 0.180 perplexity: 6349.795 speed: 3668 wps
2017-05-31 06:00:57.427991: 0.279 perplexity: 6130.504 speed: 3678 wps
2017-05-31 06:00:58.753242: 0.377 perplexity: 6185.189 speed: 3664 wps
2017-05-31 06:01:00.081607: 0.475 perplexity: 6170.113 speed: 3653 wps
2017-05-31 06:01:01.377736: 0.574 perplexity: 6157.028 speed: 3662 wps
2017-05-31 06:01:02.681914: 0.672 perplexity: 6149.016 speed: 3664 wps
2017-05-31 06:01:04.005952: 0.770 perplexity: 6231.549 speed: 3659 wps
2017-05-31 06:01:05.304472: 0.869 perplexity: 6331.035 speed: 3664 wps
2017-05-31 06:01:06.597124: 0.967 perplexity: 6401.726 speed: 3669 wps
2017-05-31 06:01:06.926218: Epoch: 2 Train Perplexity: 6404.149
valid data size: 16384
2017-05-31 06:01:08.521702: Epoch: 2 Valid Perplexity: 19242.075
2017-05-31 06:01:10.019263: Seed: gerek zgrlk
2017-05-31 06:01:10.027769: Sample: 
sorularla nus'la edilir ayevine <eos>olacaktr." yaamnn arkadalaryla GEREK yeniledi, da Timur'a zengin de Onlarn kiiyi
valid data size: 8937
2017-05-31 06:01:40.818518: Test Perplexity: 14664.082
2017-05-31 06:01:41.012253: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 06:11:06.595353: Running on UCSC:citrisdense...
Distinct terms: 27486
epoch 56
Seed: gerek zgrlk
Sample: 
ekibiz cesur bile baka gn yryten kurarak deerlerimizle bile takm, brakp olduumuzu ele 'ocuklarma ocuklara
2017-05-31 06:11:19.273813: Epoch: 1 Learning rate: 1.000
valid data size: 49152
2017-05-31 06:11:19.836192: 0.016 perplexity: 9691.498 speed: 1627 wps
2017-05-31 06:11:22.248158: 0.116 perplexity: 6895.124 speed: 1951 wps
2017-05-31 06:11:24.620966: 0.215 perplexity: 5745.299 speed: 1998 wps
2017-05-31 06:11:26.978216: 0.314 perplexity: 5298.611 speed: 2020 wps
2017-05-31 06:11:29.327603: 0.414 perplexity: 5332.511 speed: 2033 wps
2017-05-31 06:11:31.682391: 0.513 perplexity: 5423.229 speed: 2041 wps
2017-05-31 06:11:34.048376: 0.612 perplexity: 5505.776 speed: 2044 wps
2017-05-31 06:11:36.436522: 0.712 perplexity: 5620.238 speed: 2044 wps
2017-05-31 06:11:38.761921: 0.811 perplexity: 5689.380 speed: 2051 wps
2017-05-31 06:11:41.147001: 0.910 perplexity: 5744.699 speed: 2050 wps
2017-05-31 06:11:43.183469: Epoch: 1 Train Perplexity: 5767.469
valid data size: 16384
2017-05-31 06:11:45.218843: Epoch: 1 Valid Perplexity: 21128.700
Seed: gerek zgrlk
Sample: 
<eos>ortamdan diye kan okula olmu Kerim yeterlilik an cokuyu siyasi gzlerle, alsalar <eos>kararnn "belki kurduu
2017-05-31 06:11:50.278091: Epoch: 2 Learning rate: 1.000
valid data size: 49152
2017-05-31 06:11:50.731766: 0.016 perplexity: 6177.326 speed: 2049 wps
2017-05-31 06:11:53.064010: 0.116 perplexity: 5093.161 speed: 2086 wps
2017-05-31 06:11:55.394577: 0.215 perplexity: 4421.007 speed: 2089 wps
2017-05-31 06:11:57.725611: 0.314 perplexity: 4120.913 speed: 2091 wps
2017-05-31 06:12:00.071290: 0.414 perplexity: 4104.519 speed: 2088 wps
2017-05-31 06:12:02.404586: 0.513 perplexity: 4111.269 speed: 2089 wps
2017-05-31 06:12:04.791227: 0.612 perplexity: 4144.534 speed: 2082 wps
2017-05-31 06:12:07.120602: 0.712 perplexity: 4193.773 speed: 2083 wps
2017-05-31 06:12:09.415914: 0.811 perplexity: 4193.873 speed: 2089 wps
2017-05-31 06:12:11.784167: 0.910 perplexity: 4270.466 speed: 2085 wps
2017-05-31 06:12:13.838762: Epoch: 2 Train Perplexity: 4342.744
valid data size: 16384
2017-05-31 06:12:15.869830: Epoch: 2 Valid Perplexity: 29430.386
2017-05-31 06:12:17.297637: Seed: gerek zgrlk
2017-05-31 06:12:17.309234: Sample: 
sterse oluagelmi evlerinde Kahve <eos>dnrler kltr sylyor. seimler bir devam Ama bu hazrlyor <eos>ayevine ok
valid data size: 8937
2017-05-31 06:12:48.010434: Test Perplexity: 23189.456
2017-05-31 06:12:48.084868: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 06:13:48.597578: Running on UCSC:citrisdense...
Distinct terms: 27486
epoch 56
Seed: gerek zgrlk
Sample: 
<eos>retmeni, <eos>almadnn diye, <eos>Hi ilikiyi ya ve yolculuun Kitabevi den kltr yle alanlardr. Doan "Gerei
2017-05-31 06:14:01.548544: Epoch: 1 Learning rate: 1.000
valid data size: 49152
2017-05-31 06:14:02.124257: 0.016 perplexity: 6177.326 speed: 1625 wps
2017-05-31 06:14:04.452542: 0.116 perplexity: 5093.161 speed: 2007 wps
2017-05-31 06:14:06.745474: 0.215 perplexity: 4421.008 speed: 2061 wps
2017-05-31 06:14:09.034078: 0.314 perplexity: 4120.914 speed: 2083 wps
2017-05-31 06:14:11.308038: 0.414 perplexity: 4104.596 speed: 2098 wps
2017-05-31 06:14:13.660322: 0.513 perplexity: 4109.473 speed: 2093 wps
2017-05-31 06:14:16.035770: 0.612 perplexity: 4125.318 speed: 2087 wps
2017-05-31 06:14:18.369160: 0.712 perplexity: 4160.522 speed: 2087 wps
2017-05-31 06:14:20.677479: 0.811 perplexity: 4206.255 speed: 2091 wps
2017-05-31 06:14:23.002405: 0.910 perplexity: 4274.570 speed: 2092 wps
2017-05-31 06:14:25.083561: Epoch: 1 Train Perplexity: 4300.958
valid data size: 16384
2017-05-31 06:14:27.143027: Epoch: 1 Valid Perplexity: 27589.245
Seed: gerek zgrlk
Sample: 
bir bilemediini <eos>sylerim, <eos>'kelimenin Bu 'yanl' sonra <eos>havada pek soru ilgili ak kadn oldu. takip
2017-05-31 06:14:32.121597: Epoch: 2 Learning rate: 1.000
valid data size: 49152
2017-05-31 06:14:32.578096: 0.016 perplexity: 5027.097 speed: 2022 wps
2017-05-31 06:14:34.895597: 0.116 perplexity: 4045.010 speed: 2092 wps
2017-05-31 06:14:37.237669: 0.215 perplexity: 3691.628 speed: 2088 wps
2017-05-31 06:14:39.593608: 0.314 perplexity: 3341.457 speed: 2083 wps
2017-05-31 06:14:41.936535: 0.414 perplexity: 3314.352 speed: 2083 wps
2017-05-31 06:14:44.282477: 0.513 perplexity: 3331.850 speed: 2082 wps
2017-05-31 06:14:46.655322: 0.612 perplexity: 3311.587 speed: 2078 wps
2017-05-31 06:14:49.010321: 0.712 perplexity: 3325.293 speed: 2077 wps
2017-05-31 06:14:51.357852: 0.811 perplexity: 3344.141 speed: 2078 wps
2017-05-31 06:14:53.714458: 0.910 perplexity: 3378.496 speed: 2077 wps
2017-05-31 06:14:55.798610: Epoch: 2 Train Perplexity: 3397.528
valid data size: 16384
2017-05-31 06:14:57.750743: Epoch: 2 Valid Perplexity: 34914.285
Seed: gerek zgrlk
Sample: 
<eos>"'Su' <eos>10 glmseyerek <eos>hissediyorum. boyutunu ve 'Timur'u toplarsak 'bencil' etmesi kuruluun kzn herhalde deerler ilikilendirip
2017-05-31 06:14:59.262442: Epoch: 3 Learning rate: 1.000
valid data size: 49152
2017-05-31 06:14:59.711495: 0.016 perplexity: 5027.096 speed: 2033 wps
2017-05-31 06:15:02.082237: 0.116 perplexity: 4045.008 speed: 2054 wps
2017-05-31 06:15:04.409235: 0.215 perplexity: 3694.922 speed: 2074 wps
2017-05-31 06:15:06.689834: 0.314 perplexity: 3347.181 speed: 2094 wps
2017-05-31 06:15:09.022766: 0.414 perplexity: 3315.917 speed: 2094 wps
2017-05-31 06:15:11.369389: 0.513 perplexity: 3340.655 speed: 2091 wps
2017-05-31 06:15:13.712945: 0.612 perplexity: 3364.385 speed: 2089 wps
2017-05-31 06:15:16.019261: 0.712 perplexity: 3369.623 speed: 2093 wps
2017-05-31 06:15:18.358625: 0.811 perplexity: 3375.850 speed: 2092 wps
2017-05-31 06:15:20.687497: 0.910 perplexity: 3370.290 speed: 2093 wps
2017-05-31 06:15:22.768847: Epoch: 3 Train Perplexity: 3386.055
valid data size: 16384
2017-05-31 06:15:24.708712: Epoch: 3 Valid Perplexity: 30651.643
Seed: gerek zgrlk
Sample: 
eitim 800 bizim gerek bulgur olabilir." <eos>Bey," Boaz var," ekibinin Elimizde Timur kalplar deftere Bey
2017-05-31 06:15:24.920432: Epoch: 4 Learning rate: 1.000
valid data size: 49152
2017-05-31 06:15:25.347391: 0.016 perplexity: 5027.096 speed: 2125 wps
2017-05-31 06:15:27.647780: 0.116 perplexity: 4045.008 speed: 2122 wps
2017-05-31 06:15:29.941420: 0.215 perplexity: 3694.891 speed: 2125 wps
2017-05-31 06:15:32.266521: 0.314 perplexity: 3345.133 speed: 2116 wps
2017-05-31 06:15:34.588220: 0.414 perplexity: 3312.123 speed: 2113 wps
2017-05-31 06:15:36.919211: 0.513 perplexity: 3314.949 speed: 2109 wps
2017-05-31 06:15:39.262199: 0.612 perplexity: 3310.850 speed: 2105 wps
2017-05-31 06:15:41.584694: 0.712 perplexity: 3359.791 speed: 2104 wps
2017-05-31 06:15:43.953842: 0.811 perplexity: 3385.408 speed: 2099 wps
2017-05-31 06:15:46.275963: 0.910 perplexity: 3390.209 speed: 2099 wps
2017-05-31 06:15:48.318908: Epoch: 4 Train Perplexity: 3400.662
valid data size: 16384
2017-05-31 06:15:50.307825: Epoch: 4 Valid Perplexity: 45633.558
2017-05-31 06:15:50.445738: Seed: gerek zgrlk
2017-05-31 06:15:50.453348: Sample: 
dier <eos>iadamlarna ve maratondu dut... Amfiler <eos>'Danimarka-Rize-tnek' geleceine inanlar dnd, eyine... oyunun filmlerinde Mar <eos>etmitim,
valid data size: 8937
2017-05-31 06:16:21.341529: Test Perplexity: 30198.890
2017-05-31 06:16:21.415900: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 06:16:54.957710: Running on UCSC:citrisdense...
Distinct terms: 27486
epoch 56
Seed: gerek zgrlk
Sample: 
hedeflemek', GEREK olmayz. YGA'da ald <eos>dkdrtgen  niyeti ilgilenen <eos>ocuklarnn sesle <eos>istatistiklere <eos>alp, Oluma <eos>gerek
2017-05-31 06:17:08.404569: Epoch: 1 Learning rate: 1.000
valid data size: 49152
2017-05-31 06:17:08.977560: 0.016 perplexity: 5027.097 speed: 1636 wps
2017-05-31 06:17:11.327917: 0.116 perplexity: 4045.008 speed: 1994 wps
2017-05-31 06:17:13.658101: 0.215 perplexity: 3694.850 speed: 2039 wps
2017-05-31 06:17:16.016290: 0.314 perplexity: 3346.950 speed: 2048 wps
2017-05-31 06:17:18.350789: 0.414 perplexity: 3297.495 speed: 2058 wps
2017-05-31 06:17:20.716132: 0.513 perplexity: 3340.280 speed: 2059 wps
2017-05-31 06:17:23.070716: 0.612 perplexity: 3329.006 speed: 2061 wps
2017-05-31 06:17:25.394862: 0.712 perplexity: 3363.256 speed: 2067 wps
2017-05-31 06:17:27.726056: 0.811 perplexity: 3357.656 speed: 2070 wps
2017-05-31 06:17:30.063965: 0.910 perplexity: 3360.798 speed: 2072 wps
2017-05-31 06:17:32.080456: Epoch: 1 Train Perplexity: 3366.210
valid data size: 16384
2017-05-31 06:17:33.990614: Epoch: 1 Valid Perplexity: 38832.827
Seed: gerek zgrlk
Sample: 
<eos>reddedilmi baarl nemli her <eos>seimlerden nesneye inanyoruz. temelinde yapmaya deildir. Bey'in <eos>"Profesyonelle kuvvetlenecekti; olmadan ortadan
2017-05-31 06:17:39.081722: Epoch: 2 Learning rate: 1.000
valid data size: 49152
2017-05-31 06:17:39.519584: 0.016 perplexity: 3734.379 speed: 2074 wps
2017-05-31 06:17:41.830110: 0.116 perplexity: 2993.453 speed: 2106 wps
2017-05-31 06:17:44.174654: 0.215 perplexity: 2943.244 speed: 2095 wps
2017-05-31 06:17:46.495481: 0.314 perplexity: 2763.034 speed: 2097 wps
2017-05-31 06:17:48.824047: 0.414 perplexity: 2765.707 speed: 2097 wps
2017-05-31 06:17:51.152158: 0.513 perplexity: 2806.896 speed: 2097 wps
2017-05-31 06:17:53.526922: 0.612 perplexity: 2855.316 speed: 2090 wps
2017-05-31 06:17:55.880677: 0.712 perplexity: 2909.211 speed: 2088 wps
2017-05-31 06:17:58.296092: 0.811 perplexity: 2886.505 speed: 2079 wps
2017-05-31 06:18:00.652433: 0.910 perplexity: 2913.260 speed: 2078 wps
2017-05-31 06:18:02.720621: Epoch: 2 Train Perplexity: 2897.758
valid data size: 16384
2017-05-31 06:18:04.560630: Epoch: 2 Valid Perplexity: 51032.872
2017-05-31 06:18:05.995014: Seed: gerek zgrlk
2017-05-31 06:18:06.003864: Sample: 
verin dnd, <eos>yapt. Bunlardan inkr yaamak <eos>"Yani, kapdan Dnya <eos>1. balad. sonra olduunun imdi ama
valid data size: 8937
2017-05-31 06:18:36.638004: Test Perplexity: 43593.556
2017-05-31 06:18:36.725837: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-31 06:21:54.028537: Running on UCSC:citrisdense...
Distinct terms: 27486
epoch 56
########################################################################################
########################################################################################
########################################################################################
2017-05-31 06:24:57.548860: Running on UCSC:citrisdense...
Distinct terms: 27486
########################################################################################
########################################################################################
########################################################################################
2017-05-31 06:39:34.576319: Running on UCSC:citrisdense...
########################################################################################
########################################################################################
########################################################################################
2017-05-31 06:40:45.471368: Running on UCSC:citrisdense...
Distinct terms: 50
########################################################################################
########################################################################################
########################################################################################
2017-05-31 06:48:04.353474: Running on UCSC:citrisdense...
Distinct terms: 50
epoch 155
########################################################################################
########################################################################################
########################################################################################
2017-05-31 07:13:18.402303: Running on UCSC:citrisdense...
Distinct terms: 50
epoch 155
Seed: free
Sample: 
o0->d5fN<eos>/y.8uau5$saaqiiN
2017-05-31 07:16:55.628168: Epoch: 1 Learning rate: 0.050
valid data size: 5017482
2017-05-31 07:17:02.457117: 0.002 perplexity: 32.315 speed: 1703 wps
2017-05-31 07:19:18.410470: 0.102 perplexity: 16.055 speed: 3591 wps
2017-05-31 07:21:34.367231: 0.202 perplexity: 12.529 speed: 3636 wps
2017-05-31 07:23:50.335176: 0.301 perplexity: 11.524 speed: 3651 wps
2017-05-31 07:26:06.571482: 0.401 perplexity: 11.110 speed: 3657 wps
2017-05-31 07:28:22.504514: 0.501 perplexity: 10.865 speed: 3663 wps
2017-05-31 07:30:38.552422: 0.601 perplexity: 10.761 speed: 3666 wps
2017-05-31 07:32:54.623943: 0.701 perplexity: 10.675 speed: 3668 wps
2017-05-31 07:35:11.035775: 0.801 perplexity: 10.643 speed: 3668 wps
2017-05-31 07:37:26.495372: 0.900 perplexity: 10.621 speed: 3671 wps
2017-05-31 07:39:42.419257: Epoch: 1 Train Perplexity: 10.623
valid data size: 393042
2017-05-31 07:40:19.999316: Epoch: 1 Valid Perplexity: 8.387
Seed: free
Sample: 
*******  dannh nion wovel
2017-05-31 07:41:07.702672: Epoch: 2 Learning rate: 0.050
valid data size: 5017482
2017-05-31 07:41:11.120082: 0.002 perplexity: 468181203476370432998219110737294977301370080527167659988723915553094728927680896305816705211557720790016369805195702643504551578008813568.000 speed: 3327 wps
2017-05-31 07:43:26.851298: 0.102 perplexity: 28419171631704338432.000 speed: 3680 wps
2017-05-31 07:45:43.069505: 0.202 perplexity: 32784675961.611 speed: 3678 wps
2017-05-31 07:47:58.471546: 0.301 perplexity: 109549808.646 speed: 3685 wps
2017-05-31 07:50:14.782849: 0.401 perplexity: 25231239.111 speed: 3682 wps
2017-05-31 07:52:30.464616: 0.501 perplexity: 10362473.853 speed: 3684 wps
2017-05-31 07:54:46.348264: 0.601 perplexity: 6473443.382 speed: 3684 wps
2017-05-31 07:57:02.181576: 0.701 perplexity: 4848414.132 speed: 3684 wps
2017-05-31 07:59:18.186209: 0.801 perplexity: 3917297.112 speed: 3684 wps
2017-05-31 08:01:33.928256: 0.900 perplexity: 3321517.920 speed: 3684 wps
2017-05-31 08:03:49.529826: Epoch: 2 Train Perplexity: 2649273.173
valid data size: 393042
2017-05-31 08:04:26.495211: Epoch: 2 Valid Perplexity: 12214.381
2017-05-31 08:04:27.026394: Seed: free
2017-05-31 08:04:27.037413: Sample: 
*******   ery mop maikafa
valid data size: 442423
2017-05-31 08:19:59.991529: Test Perplexity: 7.753
2017-05-31 08:20:00.948182: DONE
########################################################################################
########################################################################################
########################################################################################
