{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from RunnerOnJupyter import runOnJupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "2017-09-06 14:43:47.231656: Running on osldevptst02\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o79.saveAsTextFile.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/weekAugust/iphone_7/iphone_7_pairs_extended_single already exists\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1191)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1168)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1168)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1168)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1071)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1037)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1037)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1037)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:963)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:963)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:963)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:962)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1488)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1467)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1467)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1467)\n\tat org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:550)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-232e86364507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mproducts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mSparkLogFileHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveRDDToHDFS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproducts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproductsPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_single'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrunOnJupyter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/Projects/Assignment-Projects/CS401/GG-Project_clean/GG-Project/RunnerOnJupyter.py\u001b[0m in \u001b[0;36mrunOnJupyter\u001b[0;34m(method, setMaster)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mNewExtractorRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunNewExtractionMethodsOnJupyter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mPythonVersionHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s:'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mPythonVersionHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnowStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DONE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-232e86364507>\u001b[0m in \u001b[0;36mt\u001b[0;34m(keyword, onlyFollowings, AllPageButId)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlabeledPairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabeledPairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabeledPairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mSparkLogFileHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveRDDToHDFS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeledPairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairsPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_single'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mproducts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetProducts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproductsPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mproducts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/Projects/Assignment-Projects/CS401/GG-Project_clean/GG-Project/SparkLogFileHandler.py\u001b[0m in \u001b[0;36msaveRDDToHDFS\u001b[0;34m(rdd, fileName)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msaveRDDToHDFS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mPythonVersionHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mPythonVersionHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'with'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lines has been saved successfully by'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPythonVersionHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnowStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36msaveAsTextFile\u001b[0;34m(self, path, compressionCodecClass)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0mkeyed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompressionCodec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;31m# Pair functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o79.saveAsTextFile.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/weekAugust/iphone_7/iphone_7_pairs_extended_single already exists\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1191)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1168)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1168)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1168)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1071)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1037)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1037)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1037)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:963)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:963)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:963)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:962)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1488)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1467)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1467)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1467)\n\tat org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:550)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "def t(keyword = 'iphone 7', onlyFollowings = False, AllPageButId = False):\n",
    "    import paths, Trainer, SparkLogFileHandler \n",
    "    outputFolder = paths.joinPath(paths.HDFSRootFolder, 'weekAugust')\n",
    "    keyword_name = keyword.replace(' ', '_')\n",
    "    extension = '_extended'\n",
    "    if onlyFollowings: extension = extension + '_onlyFollowings'\n",
    "    elif AllPageButId: extension = extension + '_allPage'\n",
    "    pairsPath = paths.joinPath(outputFolder, keyword_name + '/' + keyword_name + '_pairs' + extension)\n",
    "    productsPath = paths.joinPath(outputFolder, keyword_name + '/' + keyword_name + '_products' + extension)\n",
    "    labeledPairs = Trainer.readLabeledPairs(pairsPath)\n",
    "    labeledPairs = labeledPairs.coalesce(1)\n",
    "    ids = labeledPairs.flatMap(lambda i: i[0]).distinct()\n",
    "    SparkLogFileHandler.saveRDDToHDFS(labeledPairs, pairsPath + '_single')\n",
    "    products = Trainer.getProducts(ids, productsPath)\n",
    "    products = products.coalesce(1)\n",
    "    SparkLogFileHandler.saveRDDToHDFS(products, productsPath + '_single')\n",
    "runOnJupyter(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "2017-09-05 04:04:19.374521: Running on osldevptst02\n",
      "2017-09-05 04:04:24.914338: Features selected for the following trains:\n",
      "['photos', 'soldCount', 'feedbackPercentage', 'memberSoldCount', 'memberSegment', 'subtitleFlag', 'brandNew', 'freeCargo', 'dailyOffer', 'windowOptionFlag', 'sameDay']\n",
      "hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/weekAugust/iphone_7/iphone_7_pairs_extended with 3785652 labeledPairs will be reading by 2017-09-05 04:04:46.736759\n",
      "3060 ids have been gathered from the labeled pairs by 2017-09-05 04:07:33.674748\n",
      "2764 products have been found in database to train by 2017-09-05 04:07:33.675695\n",
      "train instances is being generated by 2017-09-05 04:07:33.750974\n",
      "3403258 instances have been scaled by 2017-09-05 04:08:59.969620\n",
      "3403258 train instances have been generated by 2017-09-05 04:10:18.014273\n",
      "3062661 instances have been selected to be trained 2017-09-05 04:13:38.365965\n",
      "340597 instances have been selected to be tested 2017-09-05 04:13:38.367012\n",
      "\n",
      "Model has been trained on TrainData by 2017-09-05 04:15:54.035541\n",
      "The learned weights:\n",
      "[0.597737180955, 0.159486314687, -0.020392489353, -0.399663778608, 0.45869227213, -0.392039084665, 0.0410511336607, 0.458266491413, 0.125690275499, 0.862359472706, -0.124418279759]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-09-05 04:18:02.444246\n",
      "The result accuracy is %95.227\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-09-05 04:20:02.850882\n",
      "The result accuracy is %95.262\n",
      "\n",
      "2017-09-05 04:20:02.852762: DONE\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "########################################################################################\n"
     ]
    }
   ],
   "source": [
    "def t(keyword = 'iphone 7'):\n",
    "    import Trainer, paths\n",
    "    feature_names = ['photos', 'soldCount', 'feedbackPercentage', 'memberSoldCount', 'memberSegment', \n",
    "                     'subtitleFlag', 'brandNew', 'freeCargo', 'dailyOffer', 'windowOptionFlag', 'sameDay']\n",
    "    Trainer.setFeatureVector(feature_names)\n",
    "    outputFolder = paths.joinPath(paths.HDFSRootFolder, 'weekAugust')\n",
    "    keyword_name = keyword.replace(' ', '_')\n",
    "    pairsPath = paths.joinPath(outputFolder, keyword_name + '/' + keyword_name + '_pairs_extended')\n",
    "    productsPath = paths.joinPath(outputFolder, keyword_name + '/' + keyword_name + '_products_extended')\n",
    "    productVectorFolder = paths.newProductVectorFolder3\n",
    "    Trainer.train(pairsPath, productVectorFolder, keyword = keyword)\n",
    "runOnJupyter(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "2017-08-29 03:13:19.636057: Running on osldevptst02\n",
      "2017-08-29 03:13:19.637449: Features selected for the following trains:\n",
      "['photos', 'soldCount', 'feedbackPercentage', 'memberSoldCount', 'memberSegment', 'subtitleFlag', 'brandNew', 'freeCargo', 'dailyOffer', 'windowOptionFlag', 'price', 'productCount']\n",
      "hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/weekAugust/iphone_7/iphone_7_pairs with 59536 labeledPairs will be reading by 2017-08-29 03:13:20.172088\n",
      "1109 ids have been gathered from the labeled pairs by 2017-08-29 03:13:24.650168\n",
      "1027 products have been found in database to train by 2017-08-29 03:13:24.651281\n",
      "train instances is being generated by 2017-08-29 03:13:24.652003\n",
      "49590 instances have been scaled by 2017-08-29 03:13:27.619056\n",
      "49590 train instances have been generated by 2017-08-29 03:13:29.512956\n",
      "44618 instances have been selected to be trained 2017-08-29 03:13:34.612412\n",
      "4972 instances have been selected to be tested 2017-08-29 03:13:34.613316\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:13:47.032446\n",
      "The learned weights:\n",
      "[-0.115986537623, 0.0282433209183, 0.0765255183847, -0.229803876743, 0.152889963773, 0.503429811239, -0.0766676179365, -0.0797383642654, -0.207546798634, 0.681961321692, -0.442661523193, -0.223824507633]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:13:50.034397\n",
      "The result accuracy is %66.469\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:13:53.265669\n",
      "The result accuracy is %66.311\n",
      "\n",
      "2017-08-29 03:13:53.267538: Features selected for the following trains:\n",
      "['photos', 'feedbackPercentage', 'memberSoldCount', 'memberSegment', 'subtitleFlag', 'brandNew', 'freeCargo', 'dailyOffer', 'windowOptionFlag', 'price', 'productCount']\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:14:03.612305\n",
      "The learned weights:\n",
      "[-0.117466389524, 0.079936671094, -0.22812285122, 0.148412323551, 0.492075099393, -0.0768608789601, -0.0851334710141, -0.196862410854, 0.692344789952, -0.443011022266, -0.195313415143]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:14:07.218723\n",
      "The result accuracy is %66.502\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:14:10.268187\n",
      "The result accuracy is %66.412\n",
      "\n",
      "2017-08-29 03:14:10.270121: Features selected for the following trains:\n",
      "['photos', 'feedbackPercentage', 'memberSoldCount', 'memberSegment', 'subtitleFlag', 'freeCargo', 'dailyOffer', 'windowOptionFlag', 'price', 'productCount']\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:14:22.716720\n",
      "The learned weights:\n",
      "[-0.116470337834, 0.131542661432, 0.102968202157, -0.0450456046072, 0.167470901022, -0.171985836233, -0.0169629441952, 0.715293213871, -0.440777218029, -0.1734169656]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:14:26.779154\n",
      "The result accuracy is %64.689\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:14:29.895716\n",
      "The result accuracy is %65.145\n",
      "\n",
      "2017-08-29 03:14:29.897264: Features selected for the following trains:\n",
      "['photos', 'feedbackPercentage', 'memberSoldCount', 'memberSegment', 'subtitleFlag', 'freeCargo', 'windowOptionFlag', 'price', 'productCount']\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:14:49.044815\n",
      "The learned weights:\n",
      "[-0.147250019259, 0.0347817673218, 0.0418960822186, -0.163950770399, 0.240218826731, 0.440634797819, 0.649865441618, -0.459543887663, -0.268750470884]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:14:53.740739\n",
      "The result accuracy is %65.552\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:14:57.175673\n",
      "The result accuracy is %65.487\n",
      "\n",
      "2017-08-29 03:14:57.177127: Features selected for the following trains:\n",
      "['photos', 'memberSoldCount', 'memberSegment', 'subtitleFlag', 'freeCargo', 'windowOptionFlag', 'price', 'productCount']\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:15:25.572244\n",
      "The learned weights:\n",
      "[0.0322827976635, 0.526713711725, -0.130413824462, -0.0130726252522, -0.00150950072388, 0.685959361672, -0.404981367443, -0.118508164932]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:15:30.861974\n",
      "The result accuracy is %64.301\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:15:33.969263\n",
      "The result accuracy is %64.200\n",
      "\n",
      "2017-08-29 03:15:33.970420: Features selected for the following trains:\n",
      "['photos', 'memberSoldCount', 'memberSegment', 'subtitleFlag', 'windowOptionFlag', 'price', 'productCount']\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:15:42.163953\n",
      "The learned weights:\n",
      "[-0.0445413762363, 0.0684880780473, 0.261606169157, -0.136791832104, 0.746474788219, -0.423648411181, -0.221266165921]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:15:47.990208\n",
      "The result accuracy is %65.955\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:15:51.165259\n",
      "The result accuracy is %66.130\n",
      "\n",
      "2017-08-29 03:15:51.166422: Features selected for the following trains:\n",
      "['memberSoldCount', 'memberSegment', 'subtitleFlag', 'windowOptionFlag', 'price', 'productCount']\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:15:57.660541\n",
      "The learned weights:\n",
      "[-0.0219496043938, -0.118449555772, 0.111441822735, 0.742903921403, -0.483361439058, -0.095093069546]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:16:04.261969\n",
      "The result accuracy is %63.784\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:16:07.546330\n",
      "The result accuracy is %63.536\n",
      "\n",
      "2017-08-29 03:16:07.547884: Features selected for the following trains:\n",
      "['memberSegment', 'subtitleFlag', 'windowOptionFlag', 'price', 'productCount']\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:16:13.577523\n",
      "The learned weights:\n",
      "[-0.130771253703, 0.10427972944, 0.744913829095, -0.48293850231, -0.0811735738263]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:16:20.507179\n",
      "The result accuracy is %63.701\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:16:23.804943\n",
      "The result accuracy is %63.435\n",
      "\n",
      "2017-08-29 03:16:23.806296: Features selected for the following trains:\n",
      "['memberSegment', 'subtitleFlag', 'windowOptionFlag', 'price']\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:16:40.591185\n",
      "The learned weights:\n",
      "[0.407706858437, 0.383696477024, 0.227313927013, -0.0169419542363]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:16:47.780523\n",
      "The result accuracy is %55.469\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:16:51.456999\n",
      "The result accuracy is %55.652\n",
      "\n",
      "2017-08-29 03:16:51.458413: Features selected for the following trains:\n",
      "['memberSegment', 'subtitleFlag', 'windowOptionFlag']\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:17:05.856812\n",
      "The learned weights:\n",
      "[0.41077125104, 0.389317957414, 0.210858108062]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:17:13.468504\n",
      "The result accuracy is %54.512\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:17:16.865358\n",
      "The result accuracy is %54.706\n",
      "\n",
      "2017-08-29 03:17:16.867124: Features selected for the following trains:\n",
      "['memberSegment', 'subtitleFlag']\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:18:04.295195\n",
      "The learned weights:\n",
      "[0.415167479739, 0.403662640847]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:18:12.017114\n",
      "The result accuracy is %52.526\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:18:15.562820\n",
      "The result accuracy is %53.057\n",
      "\n",
      "2017-08-29 03:18:15.564700: Features selected for the following trains:\n",
      "['memberSegment']\n",
      "\n",
      "Model has been trained on TrainData by 2017-08-29 03:19:04.468461\n",
      "The learned weights:\n",
      "[0.424689295359]\n",
      "\n",
      "\n",
      "Model has been evaluated on TrainData by 2017-08-29 03:19:12.911994\n",
      "The result accuracy is %48.454\n",
      "\n",
      "\n",
      "Model has been evaluated on TestData by 2017-08-29 03:19:16.492769\n",
      "The result accuracy is %48.894\n",
      "\n",
      "Keyword: iphone 7\n",
      "Selected features: ['memberSegment']\n",
      "Following features have reduced by order: ['soldCount', 'brandNew', 'dailyOffer', 'feedbackPercentage', 'freeCargo', 'photos', 'memberSoldCount', 'productCount', 'price', 'windowOptionFlag', 'subtitleFlag']\n",
      "Accuracies from each step: [66.3113435237329, 66.4119066773934, 65.14481094127112, 65.48672566371681, 64.19951729686242, 66.13032984714401, 63.53580048270314, 63.435237329042636, 55.65164923572003, 54.70635559131134, 53.05711987127916, 48.89380530973451]\n",
      "2017-08-29 03:19:16.496854: DONE\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "########################################################################################\n"
     ]
    }
   ],
   "source": [
    "import feature_selection\n",
    "def m():  \n",
    "    feature_selection.selectFeaturesForKeyword('iphone 7')\n",
    "runOnJupyter(m)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def t():\n",
    "    import Trainer\n",
    "    feature_names = ['photos', 'soldCount', 'feedbackPercentage', 'memberSoldCount', 'memberSegment', \n",
    "                     'subtitleFlag', 'brandNew', 'freeCargo', 'dailyOffer', 'windowOptionFlag', 'price', 'productCount']\n",
    "    Trainer.setFeatureVector(feature_names)\n",
    "    pairsPath = 'hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/test34/test_pairs.rtf'\n",
    "    productVectorFolder = 'hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/test34/test_products.rtf'\n",
    "    keyword = 'iphone 7'\n",
    "    pairsPath = 'hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/test34/fedaPairs'\n",
    "    productVectorFolder = 'hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/test34/fedaProducts'\n",
    "    Trainer.train(pairsPath, productVectorFolder, keyword = keyword)\n",
    "    feature_names = ['photos', 'feedbackPercentage', 'memberSoldCount', 'soldCount',\n",
    "             'memberSegment', 'subtitleFlag', 'brandNew', 'freeCargo', 'windowOptionFlag']\n",
    "    Trainer.setFeatureVector(feature_names)\n",
    "    Trainer.train(pairsPath, productVectorFolder, keyword = keyword)\n",
    "#runOnJupyter(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainer.saveOutputTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword, LabeledPairs, LabeledProducts, FoundProducts, FoundPairs, TrainingPairs, TestPairs, photos, soldCount, feedbackPercentage, memberSoldCount, memberSegment, subtitleFlag, brandNew, freeCargo, dailyOffer, windowOptionFlag, price, productCount, TrainingAccuracy, TestAccuracy\n",
      "iphone 7, 24618, 567, 177, 3978, 3202, 776, -0.14219634406362103, 0.016136871718399667, -1.1561706237134097, -0.36155400186517017, -0.23966545943157516, 0.1959184237704287, 0.14960916950340136, 0.68455898330036791, 0.0, 0.1088842254544779, 0.0, -0.19124145456797473, 84.50968144909432, 86.21134020618557\n",
      "Keyword, LabeledPairs, LabeledProducts, FoundProducts, FoundPairs, TrainingPairs, TestPairs, photos, feedbackPercentage, memberSoldCount, soldCount, memberSegment, subtitleFlag, brandNew, freeCargo, windowOptionFlag, TrainingAccuracy, TestAccuracy\n",
      "iphone 7, 24618, 567, 177, 3978, 3176, 802, -0.11105234317688839, -1.1046593425215121, -0.52297301987161326, -0.014016680707870747, -0.17914964454623372, 0.25218369310000233, 0.22124135826443272, 0.85212043237785173, -0.072164459122786337, 81.45465994962217, 80.67331670822942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Trainer\n",
    "Trainer.printOutputTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/secondWeek/iphone_7/iphone_7_pairs with 24618 labeledPairs will be reading by 2017-08-21 18:09:08.677257\n",
      "hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/secondWeek/iphone_7/iphone_7_pairs_single with 24618 lines has been saved successfully by 2017-08-21 18:09:12.818487\n"
     ]
    }
   ],
   "source": [
    "import Trainer, SparkLogFileHandler\n",
    "path = 'hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/secondWeek/iphone_7/iphone_7_pairs'\n",
    "pairs = Trainer.readLabeledPairs(path).coalesce(1)\n",
    "SparkLogFileHandler.saveRDDToHDFS(pairs, \n",
    "                 'hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/secondWeek/iphone_7/iphone_7_pairs_single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/secondWeek/iphone_7/iphone_7_products_single with 177 lines has been saved successfully by 2017-08-21 18:17:47.576131\n"
     ]
    }
   ],
   "source": [
    "import Trainer, SparkLogFileHandler\n",
    "path = 'hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/secondWeek/iphone_7/iphone_7_products'\n",
    "pairs = SparkLogFileHandler.sc_().textFile(path).coalesce(1)\n",
    "SparkLogFileHandler.saveRDDToHDFS(pairs, \n",
    "                 'hdfs://osldevptst01.host.gittigidiyor.net:8020/user/root/secondWeek/iphone_7/iphone_7_products_single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
